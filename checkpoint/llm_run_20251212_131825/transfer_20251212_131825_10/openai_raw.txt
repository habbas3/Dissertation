{
  "model_name": "cnn_features_1d_sa",
  "self_attention": true,
  "sngp": false,
  "openmax": false,
  "use_unknown_head": false,
  "bottleneck": 256,
  "dropout": 0.35,
  "learning_rate": 0.0005,
  "batch_size": 8,
  "lambda_src": 1.0,
  "warmup_epochs": 10,
  "rationale": "The dataset has 21 channels and short sequence length (32), with label inconsistency and domain shift between source and target cathodes. A CNN with self-attention balances local feature extraction and global context, aiding transfer across chemistries. Moderate bottleneck and dropout prevent overfitting given small batch size and label noise. OpenMax and SNGP are avoided as explicit unknown rejection is not mandatory, and the focus is on transfer adaptation rather than open-set detection."
}