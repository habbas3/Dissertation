{
  "model_name": "cnn_features_1d_sa",
  "self_attention": true,
  "sngp": false,
  "openmax": false,
  "use_unknown_head": false,
  "bottleneck": 256,
  "dropout": 0.35,
  "learning_rate": 0.0005,
  "batch_size": 8,
  "lambda_src": 1.0,
  "warmup_epochs": 10,
  "rationale": "The dataset has 21 channels and short sequence length (32), favoring a CNN with self-attention to capture local and some global dependencies without excessive compute. The domain shift between source and target chemistries suggests benefit from self-attention for adaptation. Dropout at 0.35 balances overfitting risk given label inconsistency. OpenMax or SNGP are less critical since explicit unknown rejection is not emphasized, and the baseline is a deterministic CNN. Moderate bottleneck (256) supports capacity for multi-channel features while maintaining efficiency."
}