12-12 14:53:04 data_name: Battery_inconsistent
12-12 14:53:04 data_dir: ./my_datasets/Battery
12-12 14:53:04 csv: ./my_datasets/Battery/battery_cycles_labeled.csv
12-12 14:53:04 normlizetype: mean-std
12-12 14:53:04 method: sngp
12-12 14:53:04 gp_hidden_dim: 2048
12-12 14:53:04 spectral_norm_bound: 0.95
12-12 14:53:04 n_power_iterations: 1
12-12 14:53:04 nesterov: True
12-12 14:53:04 print_freq: 10
12-12 14:53:04 layers: 16
12-12 14:53:04 widen_factor: 1
12-12 14:53:04 droprate: 0.35
12-12 14:53:04 cuda_device: 0
12-12 14:53:04 checkpoint_dir: ./checkpoint
12-12 14:53:04 pretrained: True
12-12 14:53:04 batch_size: 8
12-12 14:53:04 warmup_epochs: 4
12-12 14:53:04 num_workers: 0
12-12 14:53:04 bottleneck: True
12-12 14:53:04 bottleneck_num: 256
12-12 14:53:04 last_batch: False
12-12 14:53:04 hidden_size: 1024
12-12 14:53:04 trade_off_adversarial: Step
12-12 14:53:04 lam_adversarial: 1
12-12 14:53:04 opt: adam
12-12 14:53:04 lr: 0.0005
12-12 14:53:04 momentum: 0.9
12-12 14:53:04 weight_decay: 1e-05
12-12 14:53:04 lr_scheduler: step
12-12 14:53:04 gamma: 0.1
12-12 14:53:04 steps: 150, 250
12-12 14:53:04 middle_epoch: 15
12-12 14:53:04 max_epoch: 66
12-12 14:53:04 print_step: 25
12-12 14:53:04 inconsistent: UAN
12-12 14:53:04 model_name: cnn_features_1d
12-12 14:53:04 th: 0.5
12-12 14:53:04 input_channels: 7
12-12 14:53:04 classification_label: eol_class
12-12 14:53:04 sequence_length: 32
12-12 14:53:04 cycles_per_file: 15
12-12 14:53:04 source_cycles_per_file: None
12-12 14:53:04 target_cycles_per_file: None
12-12 14:53:04 cycle_ablation: False
12-12 14:53:04 cycle_ablation_start: 5
12-12 14:53:04 cycle_ablation_step: 10
12-12 14:53:04 cycle_ablation_max: None
12-12 14:53:04 literature_context_file: ./references/joule_s2542-4351-22-00409-3.md
12-12 14:53:04 sample_random_state: 42
12-12 14:53:04 transfer_task: [[[0], [1]], [[0], [2]], [[0], [3]], [[1], [0]], [[1], [2]], [[1], [3]], [[2], [0]], [[2], [1]], [[2], [3]], [[3], [0]], [[3], [1]], [[3], [2]]]
12-12 14:53:04 source_cathode: ['5Vspinel']
12-12 14:53:04 target_cathode: ['HE5050', 'NMC111', 'NMC532', 'NMC622', 'NMC811']
12-12 14:53:04 num_classes: None
12-12 14:53:04 domain_temperature: 1.0
12-12 14:53:04 class_temperature: 10.0
12-12 14:53:04 lambda_src: 0.6
12-12 14:53:04 lambda_src_decay_patience: 2
12-12 14:53:04 lambda_src_decay_factor: 0.5
12-12 14:53:04 lambda_src_min: 0.0
12-12 14:53:04 lambda_src_warmup: 3
12-12 14:53:04 improvement_metric: accuracy
12-12 14:53:04 skip_retry: False
12-12 14:53:04 auto_select: True
12-12 14:53:04 llm_compare: True
12-12 14:53:04 llm_backend: openai
12-12 14:53:04 llm_model: None
12-12 14:53:04 llm_context: 
12-12 14:53:04 llm_ablation: False
12-12 14:53:04 llm_per_transfer: True
12-12 14:53:04 ablation_cycle_limits: 
12-12 14:53:04 llm_cfg_inputs: {'text_context': "Dataset: Argonne National Laboratory battery aging time-series with partial cycle windows.\nSource cathodes: 5Vspinel; target cathodes: HE5050, NMC111, NMC532, NMC622, NMC811.\nLabel column 'eol_class' with ~None classes; sequence length 32; 21 channels covering cycle_number, energy_charge, capacity_charge, energy_discharge, capacity_discharge, cycle_start, cycle_duration.\nLiterature cues (Joule S2542-4351(22)00409-3, chemistry-sensitive ablations):\nJoule 2022 (S2542-4351(22)00409-3) key cues for chemistry-aware ablation:\n- Early-cycle capacity fade slopes and coulombic-efficiency stabilization highlight whether aging is lithium-inventory loss (graphite/anode-electrolyte limited) versus cathode structural decay (e.g., Ni-rich NMC cathodes with electrolyte oxidation risk).\n- High initial impedance growth, thick SEI signatures, or electrolyte oxidation markers flag chemistries that benefit from uncertainty-aware heads (SNGP/OpenMax) to avoid overconfident extrapolation on outlier cycles.\n- LFP/graphite pairs tend to show flatter voltage plateaus and slower early fade; Ni-rich NMC chemistries degrade faster under aggressive cycling and need stronger regularization or shorter cycle horizons in ablations.\n- Transfer between mismatched chemistries (e.g., NMC → LFP) should down-weight source loss and favor architectures that adapt quickly with self-attention or wider bottlenecks; closely matched chemistries can rely more on convolutional baselines.\nsource_train: class counts 0:19, 1:18, 2:2, 3:1, 4:1 (example label 1).\nsource_train sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -0.016899999231100082, 0.0012000000569969416, -0.030400000512599945, -0.03880000114440918, -0.04360000044107437, -0.05829999968409538, -0.0729999989271164, -0.074…\nsource_train flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408]]\ntarget_train: class counts 0:22, 1:22, 2:38, 3:34, 4:39 (example label 1).\ntarget_train sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, 0.3743000030517578, 0.37630000710487366, 0.3709999918937683, 0.3490999937057495, 0.34459999203681946, 0.34619998931884766, 0.32109999656677246, 0.3179000020027160…\ntarget_train flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408]]\nsource_val: class counts 0:5, 1:5, 2:1, 4:1 (example label 0).\nsource_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -0.04390000179409981, -0.06509999930858612, -0.11779999732971191, -0.15219999849796295, -0.17170000076293945, -0.19760000705718994, -0.21850000321865082, -0.22759…\nsource_val flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408]]\ntarget_val: class counts 0:9, 1:10, 2:19, 3:17, 4:19 (example label 3).\ntarget_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.174100041389…\ntarget_val flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408]]", 'numeric_summary': {'dataset': 'Battery_inconsistent', 'sequence_length_requested': 32, 'notes': 'label_inconsistent', 'lr_hint': 0.0005, 'dropout_hint': 0.35, 'num_classes_hint': None, 'splits': {'source_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 1, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -0.016899999231100082, 0.0012000000569969416, -0.030400000512599945, -0.03880000114440918, -0.04360000044107437, -0.05829999968409538, -0.0729999989271164, -0.07419999688863754, -0.07940000295639038, -0.10239999741315842, -0.11169999837875366], [-1.13100004196167, -0.17839999496936798, -0.15639999508857727, -0.18359999358654022, -0.19140000641345978, -0.195700004696846, -0.20919999480247498, -0.22220000624656677, -0.22349999845027924, -0.22930000722408295, -0.2498999983072281, -0.25760000944137573]]}, 'batch_channel_mean': [0.8607000112533569, -0.19619999825954437, -0.3012000024318695, -0.15970000624656677, -0.301800012588501, 0.9627000093460083, -0.1062999963760376, 0.14169999957084656], 'batch_channel_std': [1.059499979019165, 0.24040000140666962, 0.17249999940395355, 0.25209999084472656, 0.17270000278949738, 1.1347999572753906, 0.824999988079071, 0.6575999855995178], 'class_distribution': {'0': 19, '1': 18, '2': 2, '3': 1, '4': 1}, 'feature_range': [-3.203935665790699, 5.1401425697203385], 'feature_global_mean': -0.016921664518018544, 'flattened_rows_head': [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408]]}, 'target_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 1, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, 0.3743000030517578, 0.37630000710487366, 0.3709999918937683, 0.3490999937057495, 0.34459999203681946, 0.34619998931884766, 0.32109999656677246, 0.31790000200271606, 0.29190000891685486, 0.24529999494552612, 0.24169999361038208], [-1.13100004196167, 0.4562999904155731, 0.46230000257492065, 0.45500001311302185, 0.4316999912261963, 0.4268999993801117, 0.42480000853538513, 0.397599995136261, 0.39410001039505005, 0.36640000343322754, 0.31610000133514404, 0.3122999966144562]]}, 'batch_channel_mean': [0.8607000112533569, -0.04560000076889992, -0.01269999984651804, -0.06199999898672104, -0.009600000455975533, 0.1704999953508377, -0.36579999327659607, -0.0020000000949949026], 'batch_channel_std': [1.059499979019165, 0.5946999788284302, 0.5917999744415283, 0.5709999799728394, 0.5871999859809875, 0.9681000113487244, 0.6819999814033508, 0.7301999926567078], 'class_distribution': {'0': 22, '1': 22, '2': 38, '3': 34, '4': 39}, 'feature_range': [-9.981793547102113, 31.866555053073082], 'feature_global_mean': 0.043367023845691036, 'flattened_rows_head': [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408]]}, 'source_val': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -0.04390000179409981, -0.06509999930858612, -0.11779999732971191, -0.15219999849796295, -0.17170000076293945, -0.19760000705718994, -0.21850000321865082, -0.22759999334812164, -0.2379000037908554, -0.2531999945640564, -0.2678999900817871], [-1.13100004196167, -0.19740000367164612, -0.21279999613761902, -0.25780001282691956, -0.28760001063346863, -0.3043000102043152, -0.32760000228881836, -0.3458000123500824, -0.3540000021457672, -0.3650999963283539, -0.37959998846054077, -0.3926999866962433]]}, 'batch_channel_mean': [0.8607000112533569, -0.21899999678134918, -0.3481999933719635, -0.1915999948978424, -0.34689998626708984, 1.118899941444397, -0.11599999666213989, 0.016499999910593033], 'batch_channel_std': [1.059499979019165, 0.21160000562667847, 0.17630000412464142, 0.2303999960422516, 0.17829999327659607, 0.9266999959945679, 0.8331000208854675, 0.7063000202178955], 'class_distribution': {'0': 5, '1': 5, '2': 1, '4': 1}, 'feature_range': [-3.203935665790699, 5.1560300164083985], 'feature_global_mean': -0.010901597356338598, 'flattened_rows_head': [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408]]}, 'target_val': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 3, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653], [-1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167]]}, 'batch_channel_mean': [0.8607000112533569, 0.27559998631477356, 0.2630000114440918, 0.1655000001192093, 0.2653000056743622, 0.005200000014156103, -0.3278999924659729, -0.6205999851226807], 'batch_channel_std': [1.059499979019165, 0.4851999878883362, 0.47620001435279846, 0.46309998631477356, 0.47749999165534973, 0.9384999871253967, 0.8022000193595886, 0.9699000120162964], 'class_distribution': {'0': 9, '1': 10, '2': 19, '3': 17, '4': 19}, 'feature_range': [-3.426709644883315, 32.206823553376644], 'feature_global_mean': 0.014365731412246173, 'flattened_rows_head': [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408]]}}, 'dataset_variant': 'argonne_battery', 'feature_names': ['cycle_number', 'energy_charge', 'capacity_charge', 'energy_discharge', 'capacity_discharge', 'cycle_start', 'cycle_duration'], 'source_cathodes': ['5Vspinel'], 'target_cathodes': ['HE5050', 'NMC111', 'NMC532', 'NMC622', 'NMC811'], 'label_column': 'eol_class', 'split_used': 'source_train', 'batch_size_seen': 8, 'channels': 21, 'seq_len': 32}}
12-12 14:53:04 llm_cfg: {'architecture': 'cnn_1d', 'model_name': 'cnn_features_1d', 'self_attention': False, 'sngp': True, 'openmax': False, 'use_unknown_head': False, 'bottleneck': 256, 'dropout': 0.35, 'learning_rate': 0.0005, 'batch_size': 8, 'lambda_src': 0.6, 'warmup_epochs': 10, 'rationale': 'The dataset has 21 channels and short sequences (32 steps) with domain shift between source and target chemistries, favoring a high-capacity model with transfer adaptation. WideResNet_edited is tuned for battery data and handles domain gaps well. SNGP and use_unknown_head improve uncertainty calibration for outlier cycles and label inconsistency. Dropout at 0.35 balances regularization without overfitting small source data. Batch size 8 matches seen data, and moderate lambda_src and warmup_epochs support stable transfer learning. Target cathode: HE5050 (high-energy experimental blend). Source cathodes: 5Vspinel (high-voltage spinel (manganese rich)). Source/target chemistries differ → expect domain shift. Evaluated 21 channels × 32-step windows and matched them with cnn_1d capacity. Target fine-tune spans ≈155 cycles versus 41 source cycles, guiding lr=5.00e-04 and dropout=0.35.', '_provider': 'openai', '_raw': '{\n  "model_name": "WideResNet_edited",\n  "self_attention": false,\n  "sngp": true,\n  "openmax": false,\n  "use_unknown_head": true,\n  "bottleneck": 256,\n  "dropout": 0.35,\n  "learning_rate": 0.0005,\n  "batch_size": 8,\n  "lambda_src": 1.5,\n  "warmup_epochs": 10,\n  "rationale": "The dataset has 21 channels and short sequences (32 steps) with domain shift between source and target chemistries, favoring a high-capacity model with transfer adaptation. WideResNet_edited is tuned for battery data and handles domain gaps well. SNGP and use_unknown_head improve uncertainty calibration for outlier cycles and label inconsistency. Dropout at 0.35 balances regularization without overfitting small source data. Batch size 8 matches seen data, and moderate lambda_src and warmup_epochs support stable transfer learning."\n}'}
12-12 14:53:04 llm_cfg_stamp: 20251212_131825
12-12 14:53:04 tag: no_sngp_20251212_131825
12-12 14:53:04 pretrained_model_path: ./checkpoint/pretrain_cnn_features_1d_spinel5v_1212/best_model.pth
12-12 14:53:04 using 1 cpu
12-12 16:18:31 data_name: Battery_inconsistent
12-12 16:18:31 data_dir: ./my_datasets/Battery
12-12 16:18:31 csv: ./my_datasets/Battery/battery_cycles_labeled.csv
12-12 16:18:31 normlizetype: mean-std
12-12 16:18:31 method: sngp
12-12 16:18:31 gp_hidden_dim: 2048
12-12 16:18:31 spectral_norm_bound: 0.95
12-12 16:18:31 n_power_iterations: 1
12-12 16:18:31 nesterov: True
12-12 16:18:31 print_freq: 10
12-12 16:18:31 layers: 16
12-12 16:18:31 widen_factor: 1
12-12 16:18:31 droprate: 0.35
12-12 16:18:31 cuda_device: 0
12-12 16:18:31 checkpoint_dir: ./checkpoint
12-12 16:18:31 pretrained: True
12-12 16:18:31 batch_size: 8
12-12 16:18:31 warmup_epochs: 4
12-12 16:18:31 num_workers: 0
12-12 16:18:31 bottleneck: True
12-12 16:18:31 bottleneck_num: 256
12-12 16:18:31 last_batch: False
12-12 16:18:31 hidden_size: 1024
12-12 16:18:31 trade_off_adversarial: Step
12-12 16:18:31 lam_adversarial: 1
12-12 16:18:31 opt: adam
12-12 16:18:31 lr: 0.0005
12-12 16:18:31 momentum: 0.9
12-12 16:18:31 weight_decay: 1e-05
12-12 16:18:31 lr_scheduler: step
12-12 16:18:31 gamma: 0.1
12-12 16:18:31 steps: 150, 250
12-12 16:18:31 middle_epoch: 15
12-12 16:18:31 max_epoch: 66
12-12 16:18:31 print_step: 25
12-12 16:18:31 inconsistent: UAN
12-12 16:18:31 model_name: cnn_features_1d
12-12 16:18:31 th: 0.5
12-12 16:18:31 input_channels: 7
12-12 16:18:31 classification_label: eol_class
12-12 16:18:31 sequence_length: 32
12-12 16:18:31 cycles_per_file: 15
12-12 16:18:31 source_cycles_per_file: None
12-12 16:18:31 target_cycles_per_file: None
12-12 16:18:31 cycle_ablation: False
12-12 16:18:31 cycle_ablation_start: 5
12-12 16:18:31 cycle_ablation_step: 10
12-12 16:18:31 cycle_ablation_max: None
12-12 16:18:31 literature_context_file: ./references/joule_s2542-4351-22-00409-3.md
12-12 16:18:31 sample_random_state: 42
12-12 16:18:31 transfer_task: [[[0], [1]], [[0], [2]], [[0], [3]], [[1], [0]], [[1], [2]], [[1], [3]], [[2], [0]], [[2], [1]], [[2], [3]], [[3], [0]], [[3], [1]], [[3], [2]]]
12-12 16:18:31 source_cathode: ['5Vspinel']
12-12 16:18:31 target_cathode: ['HE5050', 'NMC111', 'NMC532', 'NMC622', 'NMC811']
12-12 16:18:31 num_classes: None
12-12 16:18:31 domain_temperature: 1.0
12-12 16:18:31 class_temperature: 10.0
12-12 16:18:31 lambda_src: 0.6
12-12 16:18:31 lambda_src_decay_patience: 2
12-12 16:18:31 lambda_src_decay_factor: 0.5
12-12 16:18:31 lambda_src_min: 0.0
12-12 16:18:31 lambda_src_warmup: 3
12-12 16:18:31 improvement_metric: accuracy
12-12 16:18:31 skip_retry: False
12-12 16:18:31 auto_select: True
12-12 16:18:31 llm_compare: True
12-12 16:18:31 llm_backend: openai
12-12 16:18:31 llm_model: None
12-12 16:18:31 llm_context: 
12-12 16:18:31 llm_ablation: False
12-12 16:18:31 llm_per_transfer: True
12-12 16:18:31 ablation_cycle_limits: 
12-12 16:18:31 llm_cfg_inputs: {'text_context': "Dataset: Argonne National Laboratory battery aging time-series with partial cycle windows.\nSource cathodes: 5Vspinel; target cathodes: HE5050, NMC111, NMC532, NMC622, NMC811.\nLabel column 'eol_class' with ~None classes; sequence length 32; 21 channels covering cycle_number, energy_charge, capacity_charge, energy_discharge, capacity_discharge, cycle_start, cycle_duration.\nLiterature cues (Joule S2542-4351(22)00409-3, chemistry-sensitive ablations):\nJoule 2022 (S2542-4351(22)00409-3) key cues for chemistry-aware ablation:\n- Early-cycle capacity fade slopes and coulombic-efficiency stabilization highlight whether aging is lithium-inventory loss (graphite/anode-electrolyte limited) versus cathode structural decay (e.g., Ni-rich NMC cathodes with electrolyte oxidation risk).\n- High initial impedance growth, thick SEI signatures, or electrolyte oxidation markers flag chemistries that benefit from uncertainty-aware heads (SNGP/OpenMax) to avoid overconfident extrapolation on outlier cycles.\n- LFP/graphite pairs tend to show flatter voltage plateaus and slower early fade; Ni-rich NMC chemistries degrade faster under aggressive cycling and need stronger regularization or shorter cycle horizons in ablations.\n- Transfer between mismatched chemistries (e.g., NMC → LFP) should down-weight source loss and favor architectures that adapt quickly with self-attention or wider bottlenecks; closely matched chemistries can rely more on convolutional baselines.\nsource_train: class counts 0:19, 1:18, 2:2, 3:1, 4:1 (example label 1).\nsource_train sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -0.016899999231100082, 0.0012000000569969416, -0.030400000512599945, -0.03880000114440918, -0.04360000044107437, -0.05829999968409538, -0.0729999989271164, -0.074…\nsource_train flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408]]\ntarget_train: class counts 0:22, 1:22, 2:38, 3:34, 4:39 (example label 1).\ntarget_train sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, 0.3743000030517578, 0.37630000710487366, 0.3709999918937683, 0.3490999937057495, 0.34459999203681946, 0.34619998931884766, 0.32109999656677246, 0.3179000020027160…\ntarget_train flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408]]\nsource_val: class counts 0:5, 1:5, 2:1, 4:1 (example label 0).\nsource_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -0.04390000179409981, -0.06509999930858612, -0.11779999732971191, -0.15219999849796295, -0.17170000076293945, -0.19760000705718994, -0.21850000321865082, -0.22759…\nsource_val flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408]]\ntarget_val: class counts 0:9, 1:10, 2:19, 3:17, 4:19 (example label 3).\ntarget_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.174100041389…\ntarget_val flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408]]", 'numeric_summary': {'dataset': 'Battery_inconsistent', 'sequence_length_requested': 32, 'notes': 'label_inconsistent', 'lr_hint': 0.0005, 'dropout_hint': 0.35, 'num_classes_hint': None, 'splits': {'source_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 1, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -0.016899999231100082, 0.0012000000569969416, -0.030400000512599945, -0.03880000114440918, -0.04360000044107437, -0.05829999968409538, -0.0729999989271164, -0.07419999688863754, -0.07940000295639038, -0.10239999741315842, -0.11169999837875366], [-1.13100004196167, -0.17839999496936798, -0.15639999508857727, -0.18359999358654022, -0.19140000641345978, -0.195700004696846, -0.20919999480247498, -0.22220000624656677, -0.22349999845027924, -0.22930000722408295, -0.2498999983072281, -0.25760000944137573]]}, 'batch_channel_mean': [0.8607000112533569, -0.19619999825954437, -0.3012000024318695, -0.15970000624656677, -0.301800012588501, 0.9627000093460083, -0.1062999963760376, 0.14169999957084656], 'batch_channel_std': [1.059499979019165, 0.24040000140666962, 0.17249999940395355, 0.25209999084472656, 0.17270000278949738, 1.1347999572753906, 0.824999988079071, 0.6575999855995178], 'class_distribution': {'0': 19, '1': 18, '2': 2, '3': 1, '4': 1}, 'feature_range': [-3.203935665790699, 5.1401425697203385], 'feature_global_mean': -0.016921664518018544, 'flattened_rows_head': [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408]]}, 'target_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 1, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, 0.3743000030517578, 0.37630000710487366, 0.3709999918937683, 0.3490999937057495, 0.34459999203681946, 0.34619998931884766, 0.32109999656677246, 0.31790000200271606, 0.29190000891685486, 0.24529999494552612, 0.24169999361038208], [-1.13100004196167, 0.4562999904155731, 0.46230000257492065, 0.45500001311302185, 0.4316999912261963, 0.4268999993801117, 0.42480000853538513, 0.397599995136261, 0.39410001039505005, 0.36640000343322754, 0.31610000133514404, 0.3122999966144562]]}, 'batch_channel_mean': [0.8607000112533569, -0.04560000076889992, -0.01269999984651804, -0.06199999898672104, -0.009600000455975533, 0.1704999953508377, -0.36579999327659607, -0.0020000000949949026], 'batch_channel_std': [1.059499979019165, 0.5946999788284302, 0.5917999744415283, 0.5709999799728394, 0.5871999859809875, 0.9681000113487244, 0.6819999814033508, 0.7301999926567078], 'class_distribution': {'0': 22, '1': 22, '2': 38, '3': 34, '4': 39}, 'feature_range': [-9.981793547102113, 31.866555053073082], 'feature_global_mean': 0.043367023845691036, 'flattened_rows_head': [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408]]}, 'source_val': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -0.04390000179409981, -0.06509999930858612, -0.11779999732971191, -0.15219999849796295, -0.17170000076293945, -0.19760000705718994, -0.21850000321865082, -0.22759999334812164, -0.2379000037908554, -0.2531999945640564, -0.2678999900817871], [-1.13100004196167, -0.19740000367164612, -0.21279999613761902, -0.25780001282691956, -0.28760001063346863, -0.3043000102043152, -0.32760000228881836, -0.3458000123500824, -0.3540000021457672, -0.3650999963283539, -0.37959998846054077, -0.3926999866962433]]}, 'batch_channel_mean': [0.8607000112533569, -0.21899999678134918, -0.3481999933719635, -0.1915999948978424, -0.34689998626708984, 1.118899941444397, -0.11599999666213989, 0.016499999910593033], 'batch_channel_std': [1.059499979019165, 0.21160000562667847, 0.17630000412464142, 0.2303999960422516, 0.17829999327659607, 0.9266999959945679, 0.8331000208854675, 0.7063000202178955], 'class_distribution': {'0': 5, '1': 5, '2': 1, '4': 1}, 'feature_range': [-3.203935665790699, 5.1560300164083985], 'feature_global_mean': -0.010901597356338598, 'flattened_rows_head': [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408]]}, 'target_val': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 3, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653], [-1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167]]}, 'batch_channel_mean': [0.8607000112533569, 0.27559998631477356, 0.2630000114440918, 0.1655000001192093, 0.2653000056743622, 0.005200000014156103, -0.3278999924659729, -0.6205999851226807], 'batch_channel_std': [1.059499979019165, 0.4851999878883362, 0.47620001435279846, 0.46309998631477356, 0.47749999165534973, 0.9384999871253967, 0.8022000193595886, 0.9699000120162964], 'class_distribution': {'0': 9, '1': 10, '2': 19, '3': 17, '4': 19}, 'feature_range': [-3.426709644883315, 32.206823553376644], 'feature_global_mean': 0.014365731412246173, 'flattened_rows_head': [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408]]}}, 'dataset_variant': 'argonne_battery', 'feature_names': ['cycle_number', 'energy_charge', 'capacity_charge', 'energy_discharge', 'capacity_discharge', 'cycle_start', 'cycle_duration'], 'source_cathodes': ['5Vspinel'], 'target_cathodes': ['HE5050', 'NMC111', 'NMC532', 'NMC622', 'NMC811'], 'label_column': 'eol_class', 'split_used': 'source_train', 'batch_size_seen': 8, 'channels': 21, 'seq_len': 32}}
12-12 16:18:31 llm_cfg: {'architecture': 'cnn_1d', 'model_name': 'cnn_features_1d', 'self_attention': False, 'sngp': True, 'openmax': False, 'use_unknown_head': False, 'bottleneck': 256, 'dropout': 0.35, 'learning_rate': 0.0005, 'batch_size': 8, 'lambda_src': 0.6, 'warmup_epochs': 10, 'rationale': 'The dataset has 21 channels and short sequences (32 steps) with label inconsistency and domain shift between source and target chemistries. WideResNet_edited is tailored for battery data with domain gaps and benefits from physics-inspired feature edits. Using SNGP and an unknown head helps manage uncertainty and outlier cycles due to chemistry mismatch. Dropout at 0.35 balances regularization for small source data, and a moderate bottleneck of 256 supports capacity without overfitting. Batch size 8 matches seen data, and warmup epochs help stabilize transfer learning. Target cathode: HE5050 (high-energy experimental blend). Source cathodes: 5Vspinel (high-voltage spinel (manganese rich)). Source/target chemistries differ → expect domain shift. Evaluated 21 channels × 32-step windows and matched them with cnn_1d capacity. Target fine-tune spans ≈155 cycles versus 41 source cycles, guiding lr=5.00e-04 and dropout=0.35.', '_provider': 'openai', '_raw': '{\n  "model_name": "WideResNet_edited",\n  "self_attention": false,\n  "sngp": true,\n  "openmax": false,\n  "use_unknown_head": true,\n  "bottleneck": 256,\n  "dropout": 0.35,\n  "learning_rate": 0.0005,\n  "batch_size": 8,\n  "lambda_src": 1.0,\n  "warmup_epochs": 10,\n  "rationale": "The dataset has 21 channels and short sequences (32 steps) with label inconsistency and domain shift between source and target chemistries. WideResNet_edited is tailored for battery data with domain gaps and benefits from physics-inspired feature edits. Using SNGP and an unknown head helps manage uncertainty and outlier cycles due to chemistry mismatch. Dropout at 0.35 balances regularization for small source data, and a moderate bottleneck of 256 supports capacity without overfitting. Batch size 8 matches seen data, and warmup epochs help stabilize transfer learning."\n}'}
12-12 16:18:31 llm_cfg_stamp: 20251212_131825
12-12 16:18:31 tag: sngp_wrn_sa_20251212_131825
12-12 16:18:31 pretrained_model_path: ./checkpoint/pretrain_cnn_features_1d_spinel5v_1212/best_model.pth
12-12 16:18:31 using 1 cpu
