12-12 14:31:56 data_name: Battery_inconsistent
12-12 14:31:56 data_dir: ./my_datasets/Battery
12-12 14:31:56 csv: ./my_datasets/Battery/battery_cycles_labeled.csv
12-12 14:31:56 normlizetype: mean-std
12-12 14:31:56 method: sngp
12-12 14:31:56 gp_hidden_dim: 2048
12-12 14:31:56 spectral_norm_bound: 0.95
12-12 14:31:56 n_power_iterations: 1
12-12 14:31:56 nesterov: True
12-12 14:31:56 print_freq: 10
12-12 14:31:56 layers: 16
12-12 14:31:56 widen_factor: 1
12-12 14:31:56 droprate: 0.35
12-12 14:31:56 cuda_device: 0
12-12 14:31:56 checkpoint_dir: ./checkpoint
12-12 14:31:56 pretrained: True
12-12 14:31:56 batch_size: 8
12-12 14:31:56 warmup_epochs: 4
12-12 14:31:56 num_workers: 0
12-12 14:31:56 bottleneck: True
12-12 14:31:56 bottleneck_num: 256
12-12 14:31:56 last_batch: False
12-12 14:31:56 hidden_size: 1024
12-12 14:31:56 trade_off_adversarial: Step
12-12 14:31:56 lam_adversarial: 1
12-12 14:31:56 opt: adam
12-12 14:31:56 lr: 5e-05
12-12 14:31:56 momentum: 0.9
12-12 14:31:56 weight_decay: 1e-05
12-12 14:31:56 lr_scheduler: step
12-12 14:31:56 gamma: 0.1
12-12 14:31:56 steps: 150, 250
12-12 14:31:56 middle_epoch: 15
12-12 14:31:56 max_epoch: 82
12-12 14:31:56 print_step: 25
12-12 14:31:56 inconsistent: UAN
12-12 14:31:56 model_name: cnn_features_1d
12-12 14:31:56 th: 0.5
12-12 14:31:56 input_channels: 21
12-12 14:31:56 classification_label: eol_class
12-12 14:31:56 sequence_length: 32
12-12 14:31:56 cycles_per_file: 15
12-12 14:31:56 source_cycles_per_file: None
12-12 14:31:56 target_cycles_per_file: None
12-12 14:31:56 cycle_ablation: False
12-12 14:31:56 cycle_ablation_start: 5
12-12 14:31:56 cycle_ablation_step: 10
12-12 14:31:56 cycle_ablation_max: None
12-12 14:31:56 literature_context_file: ./references/joule_s2542-4351-22-00409-3.md
12-12 14:31:56 sample_random_state: 42
12-12 14:31:56 transfer_task: [[[0], [1]], [[0], [2]], [[0], [3]], [[1], [0]], [[1], [2]], [[1], [3]], [[2], [0]], [[2], [1]], [[2], [3]], [[3], [0]], [[3], [1]], [[3], [2]]]
12-12 14:31:56 source_cathode: ['5Vspinel']
12-12 14:31:56 target_cathode: ['Li1.2Ni0.3Mn0.6O2', 'Li1.35Ni0.33Mn0.67O2.35']
12-12 14:31:56 num_classes: 5
12-12 14:31:56 domain_temperature: 1.0
12-12 14:31:56 class_temperature: 10.0
12-12 14:31:56 lambda_src: 0.6
12-12 14:31:56 lambda_src_decay_patience: 1
12-12 14:31:56 lambda_src_decay_factor: 0.5
12-12 14:31:56 lambda_src_min: 0.0
12-12 14:31:56 lambda_src_warmup: 0
12-12 14:31:56 improvement_metric: accuracy
12-12 14:31:56 skip_retry: False
12-12 14:31:56 auto_select: True
12-12 14:31:56 llm_compare: True
12-12 14:31:56 llm_backend: openai
12-12 14:31:56 llm_model: None
12-12 14:31:56 llm_context: 
12-12 14:31:56 llm_ablation: False
12-12 14:31:56 llm_per_transfer: True
12-12 14:31:56 ablation_cycle_limits: 
12-12 14:31:56 llm_cfg_inputs: {'text_context': "Dataset: Argonne National Laboratory battery aging time-series with partial cycle windows.\nSource cathodes: 5Vspinel; target cathodes: Li1.2Ni0.3Mn0.6O2, Li1.35Ni0.33Mn0.67O2.35.\nLabel column 'eol_class' with ~None classes; sequence length 32; 21 channels covering cycle_number, energy_charge, capacity_charge, energy_discharge, capacity_discharge, cycle_start, cycle_duration.\nLiterature cues (Joule S2542-4351(22)00409-3, chemistry-sensitive ablations):\nJoule 2022 (S2542-4351(22)00409-3) key cues for chemistry-aware ablation:\n- Early-cycle capacity fade slopes and coulombic-efficiency stabilization highlight whether aging is lithium-inventory loss (graphite/anode-electrolyte limited) versus cathode structural decay (e.g., Ni-rich NMC cathodes with electrolyte oxidation risk).\n- High initial impedance growth, thick SEI signatures, or electrolyte oxidation markers flag chemistries that benefit from uncertainty-aware heads (SNGP/OpenMax) to avoid overconfident extrapolation on outlier cycles.\n- LFP/graphite pairs tend to show flatter voltage plateaus and slower early fade; Ni-rich NMC chemistries degrade faster under aggressive cycling and need stronger regularization or shorter cycle horizons in ablations.\n- Transfer between mismatched chemistries (e.g., NMC → LFP) should down-weight source loss and favor architectures that adapt quickly with self-attention or wider bottlenecks; closely matched chemistries can rely more on convolutional baselines.\nsource_train: class counts 0:19, 1:18, 2:2, 3:1, 4:1 (example label 0).\nsource_train sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.5073000192642212, 0.29750001430511475, 0.1597999930381775, 0.11580000072717667, 0.06870000064373016, -0.0215000007301569, -0.06700000166893005, -0.0939000025391…\nsource_train flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]\ntarget_train: class counts 0:6 (example label 0).\ntarget_train sample window (first 3 ch × 12 steps): [[-1.896399974822998, -1.9917000532150269, -1.5246000289916992, 0.0, -0.8306000232696533, 0.0, -0.16660000383853912, 0.0, 0.17499999701976776, 0.2815000116825104, 0.4404999911785126, 0.287200003862381], [-2.2899999618530273, 2.789099931716919, 3.0618999004364014, 0.0, 2.724100112915039, 0.0, 1.9648000001907349, 0.0, 0.5493000149726868, 0.6560999751091003, -2.791300058364868, 2.6998000144958496], [-2.7012999057769775,…\ntarget_train flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]\nsource_val: class counts 0:5, 1:5, 2:1, 4:1 (example label 0).\nsource_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.3109000027179718, 0.25519999861717224, 0.11729999631643295, 0.027000000700354576, -0.023900000378489494, -0.09200000017881393, -0.14669999480247498, -0.17059999…\nsource_val flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]\ntarget_val: class counts 0:4 (example label 0).\ntarget_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 2.1417999267578125, 2.015700101852417, 1.9608999490737915, 2.140199899673462, 1.8382999897003174, 1.805999994277954, 3.2121999263763428, 1.5262000560760498, 1.592…\ntarget_val flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]", 'numeric_summary': {'dataset': 'Battery_inconsistent', 'sequence_length_requested': 32, 'notes': 'label_inconsistent', 'lr_hint': 0.0005, 'dropout_hint': 0.35, 'num_classes_hint': None, 'splits': {'source_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.5073000192642212, 0.29750001430511475, 0.1597999930381775, 0.11580000072717667, 0.06870000064373016, -0.0215000007301569, -0.06700000166893005, -0.09390000253915787, -0.14229999482631683, -0.26440000534057617, -0.26820001006126404], [-2.4202001094818115, 0.3971000015735626, 0.20489999651908875, 0.07859999686479568, 0.03830000013113022, -0.0044999998062849045, -0.0908999964594841, -0.1347000002861023, -0.15940000116825104, -0.20960000157356262, -0.3246999979019165, -0.32820001244544983]]}, 'batch_channel_mean': [0.8607000112533569, -0.1421000063419342, -0.2084999978542328, -0.07079999893903732, -0.16120000183582306, 0.534600019454956, -0.3154999911785126, 0.24279999732971191], 'batch_channel_std': [1.059499979019165, 0.5717999935150146, 0.5095999836921692, 0.6176000237464905, 0.5239999890327454, 0.9284999966621399, 0.7612000107765198, 0.8140000104904175], 'class_distribution': {'0': 19, '1': 18, '2': 2, '3': 1, '4': 1}, 'feature_range': [-2.9057923445856524, 5.202832943374929], 'feature_global_mean': -0.008143604364574682, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]}, 'target_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.896399974822998, -1.9917000532150269, -1.5246000289916992, 0.0, -0.8306000232696533, 0.0, -0.16660000383853912, 0.0, 0.17499999701976776, 0.2815000116825104, 0.4404999911785126, 0.287200003862381], [-2.2899999618530273, 2.789099931716919, 3.0618999004364014, 0.0, 2.724100112915039, 0.0, 1.9648000001907349, 0.0, 0.5493000149726868, 0.6560999751091003, -2.791300058364868, 2.6998000144958496], [-2.7012999057769775, 1.3554999828338623, 1.62090003490448, 0.0, 1.8700000047683716, 0.0, 1.3710999488830566, 0.0, 0.1671999990940094, 0.0502999983727932, -2.187700033187866, 0.9710999727249146]]}, 'batch_channel_mean': [0.7294999957084656, 0.8521999716758728, 1.1779999732971191, 0.9107999801635742, 1.1938999891281128, -0.11500000208616257, -0.24160000681877136, -0.2093999981880188], 'batch_channel_std': [1.037600040435791, 1.1383999586105347, 1.261199951171875, 1.3704999685287476, 1.382200002670288, 1.318600058555603, 1.0240000486373901, 1.1060999631881714], 'class_distribution': {'0': 6}, 'feature_range': [-3.6390493997246667, 19.875169049014566], 'feature_global_mean': 0.4374359295879304, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]}, 'source_val': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.3109000027179718, 0.25519999861717224, 0.11729999631643295, 0.027000000700354576, -0.023900000378489494, -0.09200000017881393, -0.14669999480247498, -0.17059999704360962, -0.19750000536441803, -0.23759999871253967, -0.2761000096797943], [-2.4202001094818115, 0.210999995470047, 0.16750000417232513, 0.040699999779462814, -0.04349999874830246, -0.09049999713897705, -0.15610000491142273, -0.20749999582767487, -0.2303999960422516, -0.26170000433921814, -0.3025999963283539, -0.33959999680519104]]}, 'batch_channel_mean': [0.8607000112533569, -0.14800000190734863, -0.21410000324249268, -0.1005999967455864, -0.1704999953508377, 0.7595000267028809, -0.25529998540878296, 0.00139999995008111], 'batch_channel_std': [1.059499979019165, 0.5544999837875366, 0.4968999922275543, 0.6308000087738037, 0.5254999995231628, 0.8083000183105469, 0.7978000044822693, 0.6376000046730042], 'class_distribution': {'0': 5, '1': 5, '2': 1, '4': 1}, 'feature_range': [-2.9057923445856524, 5.219029621397489], 'feature_global_mean': -0.004320963409587972, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]}, 'target_val': {'batch_shape': [4, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 2.1417999267578125, 2.015700101852417, 1.9608999490737915, 2.140199899673462, 1.8382999897003174, 1.805999994277954, 3.2121999263763428, 1.5262000560760498, 1.5922000408172607, 2.4560999870300293, 0.5361999869346619], [-2.4202001094818115, 2.6226999759674072, 2.5090999603271484, 2.4544999599456787, 2.5053000450134277, 2.200200080871582, 2.1552000045776367, 3.31030011177063, 1.7338000535964966, 1.7655999660491943, 2.470400094985962, 0.6173999905586243]]}, 'batch_channel_mean': [0.8607000112533569, 0.8479999899864197, 1.1744999885559082, 0.14030000567436218, 0.7558000087738037, -0.8087999820709229, -0.2743000090122223, -0.7925999760627747], 'batch_channel_std': [1.059499979019165, 1.2324999570846558, 1.3095999956130981, 1.6520999670028687, 1.822100043296814, 0.26759999990463257, 0.8853999972343445, 1.1957999467849731], 'class_distribution': {'0': 4}, 'feature_range': [-3.571829448600409, 19.622460716154905], 'feature_global_mean': 0.28418790425941914, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]}}, 'dataset_variant': 'argonne_battery', 'feature_names': ['cycle_number', 'energy_charge', 'capacity_charge', 'energy_discharge', 'capacity_discharge', 'cycle_start', 'cycle_duration'], 'source_cathodes': ['5Vspinel'], 'target_cathodes': ['Li1.2Ni0.3Mn0.6O2', 'Li1.35Ni0.33Mn0.67O2.35'], 'label_column': 'eol_class', 'split_used': 'source_train', 'batch_size_seen': 8, 'channels': 21, 'seq_len': 32}}
12-12 14:31:56 llm_cfg: {'architecture': 'cnn_1d', 'model_name': 'cnn_features_1d', 'self_attention': False, 'sngp': True, 'openmax': False, 'use_unknown_head': False, 'bottleneck': 256, 'dropout': 0.35, 'learning_rate': 0.0005, 'batch_size': 8, 'lambda_src': 1.5, 'warmup_epochs': 10, 'rationale': 'The dataset has 21 channels and a short sequence length (32), with domain shift between source and target chemistries. WideResNet_edited is tailored for battery data and transfer tasks with chemistry mismatch, providing strong representation power. Enabling SNGP and use_unknown_head helps manage uncertainty and avoid overconfident extrapolation on outlier cycles, important given label inconsistency and domain gap. Dropout at 0.35 balances regularization, and batch size 8 matches seen data. Moderate bottleneck (256) supports capacity without overfitting, and warmup_epochs 10 stabilizes training. Target cathode: Li1.2Ni0.3Mn0.6O2. Source cathodes: 5Vspinel (high-voltage spinel (manganese rich)). Source/target chemistries differ → expect domain shift. Evaluated 21 channels × 32-step windows and matched them with cnn_1d capacity. Target fine-tune spans ≈6 cycles versus 41 source cycles, guiding lr=5.00e-04 and dropout=0.35.', '_provider': 'openai', '_raw': '{\n  "model_name": "WideResNet_edited",\n  "self_attention": false,\n  "sngp": true,\n  "openmax": false,\n  "use_unknown_head": true,\n  "bottleneck": 256,\n  "dropout": 0.35,\n  "learning_rate": 0.0005,\n  "batch_size": 8,\n  "lambda_src": 1.0,\n  "warmup_epochs": 10,\n  "rationale": "The dataset has 21 channels and a short sequence length (32), with domain shift between source and target chemistries. WideResNet_edited is tailored for battery data and transfer tasks with chemistry mismatch, providing strong representation power. Enabling SNGP and use_unknown_head helps manage uncertainty and avoid overconfident extrapolation on outlier cycles, important given label inconsistency and domain gap. Dropout at 0.35 balances regularization, and batch size 8 matches seen data. Moderate bottleneck (256) supports capacity without overfitting, and warmup_epochs 10 stabilizes training."\n}'}
12-12 14:31:56 llm_cfg_stamp: 20251212_131825
12-12 14:31:56 tag: no_sa_20251212_131825
12-12 14:31:56 pretrained_model_path: ./checkpoint/transfer_cnn_features_1d_spinel5v_to_lirich_1212/best_model.pth
12-12 14:31:56 dataset_cycle_stats: {'source_train_cycles': 615, 'source_val_cycles': 180, 'source_val_has_holdout': True, 'source_cycle_limit': 15, 'target_train_cycles': 90, 'target_val_cycles': 60, 'target_val_has_holdout': True, 'target_cycle_limit': 15, 'source_train_sequences': 41, 'source_val_sequences': 12, 'target_train_sequences': 6, 'target_val_sequences': 4, 'source_train_cells': 5, 'source_val_cells': 2, 'target_train_cells': 5, 'target_val_cells': 3, 'cycles_per_cell_per_cathode': {'source_train': {'5Vspinel': [{'filename': 'batch_B11B_cell_4.h5', 'cycles': 15, 'total_cycles': 216}, {'filename': 'batch_B26U_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26V_cell_3.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26V_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26V_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26W_cell_1.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26W_cell_3.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26W_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26W_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26X_cell_1.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26X_cell_3.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26X_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26Y_cell_3.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26Y_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26Y_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26Z_cell_1.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26Z_cell_3.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B5A_cell_1.h5', 'cycles': 15, 'total_cycles': 846}, {'filename': 'batch_B5A_cell_5.h5', 'cycles': 15, 'total_cycles': 855}, {'filename': 'batch_B26V_cell_1.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26T_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26AA_cell_1.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26T_cell_4.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26AA_cell_4.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26K_cell_1.h5', 'cycles': 15, 'total_cycles': 221}, {'filename': 'batch_B26L_cell_1.h5', 'cycles': 15, 'total_cycles': 2028}, {'filename': 'batch_B26N_cell_1.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26O_cell_1.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26O_cell_4.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26O_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26P_cell_3.h5', 'cycles': 15, 'total_cycles': 421}, {'filename': 'batch_B26P_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26Q_cell_3.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26Q_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26R_cell_1.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26R_cell_3.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26R_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26S_cell_3.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26S_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26S_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B5A_cell_7.h5', 'cycles': 15, 'total_cycles': 687}]}, 'source_val': {'5Vspinel': [{'filename': 'batch_B26K_cell_2.h5', 'cycles': 15, 'total_cycles': 221}, {'filename': 'batch_B26L_cell_2.h5', 'cycles': 15, 'total_cycles': 2028}, {'filename': 'batch_B26M_cell_2.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26P_cell_2.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26P_cell_6.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26R_cell_2.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26T_cell_2.h5', 'cycles': 15, 'total_cycles': 220}, {'filename': 'batch_B26V_cell_2.h5', 'cycles': 15, 'total_cycles': 421}, {'filename': 'batch_B26X_cell_2.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26Y_cell_2.h5', 'cycles': 15, 'total_cycles': 421}, {'filename': 'batch_B26Z_cell_2.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B5A_cell_2.h5', 'cycles': 15, 'total_cycles': 820}]}, 'target_train': {'Li1.2Ni0.3Mn0.6O2': [{'filename': 'batch_B3A_cell_4.h5', 'cycles': 15, 'total_cycles': 181}, {'filename': 'batch_B3B_cell_2.h5', 'cycles': 15, 'total_cycles': 181}, {'filename': 'batch_B3B_cell_3.h5', 'cycles': 15, 'total_cycles': 180}, {'filename': 'batch_B3B_cell_7.h5', 'cycles': 15, 'total_cycles': 180}], 'Li1.35Ni0.33Mn0.67O2.35': [{'filename': 'batch_B13A_cell_4.h5', 'cycles': 15, 'total_cycles': 169}, {'filename': 'batch_B13A_cell_8.h5', 'cycles': 15, 'total_cycles': 218}]}, 'target_val': {'Li1.2Ni0.3Mn0.6O2': [{'filename': 'batch_B3B_cell_1.h5', 'cycles': 15, 'total_cycles': 181}, {'filename': 'batch_B3B_cell_5.h5', 'cycles': 15, 'total_cycles': 180}], 'Li1.35Ni0.33Mn0.67O2.35': [{'filename': 'batch_B13A_cell_13.h5', 'cycles': 15, 'total_cycles': 218}, {'filename': 'batch_B8A_cell_1.h5', 'cycles': 15, 'total_cycles': 214}]}}, 'feature_columns': ('cycle_number', 'energy_charge', 'capacity_charge', 'energy_discharge', 'capacity_discharge', 'cycle_start', 'cycle_duration', 'capacity_retention', 'energy_retention', 'delta_capacity_discharge', 'delta_energy_discharge', 'delta_cycle_duration', 'rolling_capacity_mean', 'rolling_capacity_std', 'rolling_energy_mean', 'rolling_energy_std', 'rolling_duration_mean', 'duration_ratio', 'coulombic_efficiency', 'energy_efficiency', 'time_per_capacity'), 'chemistry_by_cathode': {'5Vspinel': {'cathode': '5Vspinel', 'anode': 'LTO', 'electrolyte': 'R&D', 'dataset': 'Argonne'}, 'FCG': {'cathode': 'FCG', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'HE5050': {'cathode': 'HE5050', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'Li1.2Ni0.3Mn0.6O2': {'cathode': 'Li1.2Ni0.3Mn0.6O2', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'Li1.35Ni0.33Mn0.67O2.35': {'cathode': 'Li1.35Ni0.33Mn0.67O2.35', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'NMC111': {'cathode': 'NMC111', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'NMC532': {'cathode': 'NMC532', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'NMC622': {'cathode': 'NMC622', 'anode': 'C_Si', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'NMC811': {'cathode': 'NMC811', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}}, 'chemistry_context': {'source': {'5Vspinel': {'cathode': '5Vspinel', 'anode': 'LTO', 'electrolyte': 'R&D', 'dataset': 'Argonne'}}, 'target': {'Li1.2Ni0.3Mn0.6O2': {'cathode': 'Li1.2Ni0.3Mn0.6O2', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'Li1.35Ni0.33Mn0.67O2.35': {'cathode': 'Li1.35Ni0.33Mn0.67O2.35', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}}, 'dataset_names': ['Argonne']}}
12-12 14:31:56 input_size: 32
12-12 14:31:56 reinit_head: False
12-12 14:31:56 using 1 cpu
12-12 14:31:56 Reducing learning rate to 5e-05 for 6 target samples
12-12 14:31:56 Freezing early layers of backbone for 6 target samples
12-12 15:32:50 data_name: Battery_inconsistent
12-12 15:32:50 data_dir: ./my_datasets/Battery
12-12 15:32:50 csv: ./my_datasets/Battery/battery_cycles_labeled.csv
12-12 15:32:50 normlizetype: mean-std
12-12 15:32:50 method: sngp
12-12 15:32:50 gp_hidden_dim: 2048
12-12 15:32:50 spectral_norm_bound: 0.95
12-12 15:32:50 n_power_iterations: 1
12-12 15:32:50 nesterov: True
12-12 15:32:50 print_freq: 10
12-12 15:32:50 layers: 16
12-12 15:32:50 widen_factor: 1
12-12 15:32:50 droprate: 0.35
12-12 15:32:50 cuda_device: 0
12-12 15:32:50 checkpoint_dir: ./checkpoint
12-12 15:32:50 pretrained: True
12-12 15:32:50 batch_size: 8
12-12 15:32:50 warmup_epochs: 4
12-12 15:32:50 num_workers: 0
12-12 15:32:50 bottleneck: True
12-12 15:32:50 bottleneck_num: 256
12-12 15:32:50 last_batch: False
12-12 15:32:50 hidden_size: 1024
12-12 15:32:50 trade_off_adversarial: Step
12-12 15:32:50 lam_adversarial: 1
12-12 15:32:50 opt: adam
12-12 15:32:50 lr: 5e-05
12-12 15:32:50 momentum: 0.9
12-12 15:32:50 weight_decay: 1e-05
12-12 15:32:50 lr_scheduler: step
12-12 15:32:50 gamma: 0.1
12-12 15:32:50 steps: 150, 250
12-12 15:32:50 middle_epoch: 15
12-12 15:32:50 max_epoch: 82
12-12 15:32:50 print_step: 25
12-12 15:32:50 inconsistent: UAN
12-12 15:32:50 model_name: cnn_features_1d
12-12 15:32:50 th: 0.5
12-12 15:32:50 input_channels: 21
12-12 15:32:50 classification_label: eol_class
12-12 15:32:50 sequence_length: 32
12-12 15:32:50 cycles_per_file: 15
12-12 15:32:50 source_cycles_per_file: None
12-12 15:32:50 target_cycles_per_file: None
12-12 15:32:50 cycle_ablation: False
12-12 15:32:50 cycle_ablation_start: 5
12-12 15:32:50 cycle_ablation_step: 10
12-12 15:32:50 cycle_ablation_max: None
12-12 15:32:50 literature_context_file: ./references/joule_s2542-4351-22-00409-3.md
12-12 15:32:50 sample_random_state: 42
12-12 15:32:50 transfer_task: [[[0], [1]], [[0], [2]], [[0], [3]], [[1], [0]], [[1], [2]], [[1], [3]], [[2], [0]], [[2], [1]], [[2], [3]], [[3], [0]], [[3], [1]], [[3], [2]]]
12-12 15:32:50 source_cathode: ['5Vspinel']
12-12 15:32:50 target_cathode: ['Li1.2Ni0.3Mn0.6O2', 'Li1.35Ni0.33Mn0.67O2.35']
12-12 15:32:50 num_classes: 5
12-12 15:32:50 domain_temperature: 1.0
12-12 15:32:50 class_temperature: 10.0
12-12 15:32:50 lambda_src: 0.6
12-12 15:32:50 lambda_src_decay_patience: 1
12-12 15:32:50 lambda_src_decay_factor: 0.5
12-12 15:32:50 lambda_src_min: 0.0
12-12 15:32:50 lambda_src_warmup: 0
12-12 15:32:50 improvement_metric: accuracy
12-12 15:32:50 skip_retry: False
12-12 15:32:50 auto_select: True
12-12 15:32:50 llm_compare: True
12-12 15:32:50 llm_backend: openai
12-12 15:32:50 llm_model: None
12-12 15:32:50 llm_context: 
12-12 15:32:50 llm_ablation: False
12-12 15:32:50 llm_per_transfer: True
12-12 15:32:50 ablation_cycle_limits: 
12-12 15:32:50 llm_cfg_inputs: {'text_context': "Dataset: Argonne National Laboratory battery aging time-series with partial cycle windows.\nSource cathodes: 5Vspinel; target cathodes: Li1.2Ni0.3Mn0.6O2, Li1.35Ni0.33Mn0.67O2.35.\nLabel column 'eol_class' with ~None classes; sequence length 32; 21 channels covering cycle_number, energy_charge, capacity_charge, energy_discharge, capacity_discharge, cycle_start, cycle_duration.\nLiterature cues (Joule S2542-4351(22)00409-3, chemistry-sensitive ablations):\nJoule 2022 (S2542-4351(22)00409-3) key cues for chemistry-aware ablation:\n- Early-cycle capacity fade slopes and coulombic-efficiency stabilization highlight whether aging is lithium-inventory loss (graphite/anode-electrolyte limited) versus cathode structural decay (e.g., Ni-rich NMC cathodes with electrolyte oxidation risk).\n- High initial impedance growth, thick SEI signatures, or electrolyte oxidation markers flag chemistries that benefit from uncertainty-aware heads (SNGP/OpenMax) to avoid overconfident extrapolation on outlier cycles.\n- LFP/graphite pairs tend to show flatter voltage plateaus and slower early fade; Ni-rich NMC chemistries degrade faster under aggressive cycling and need stronger regularization or shorter cycle horizons in ablations.\n- Transfer between mismatched chemistries (e.g., NMC → LFP) should down-weight source loss and favor architectures that adapt quickly with self-attention or wider bottlenecks; closely matched chemistries can rely more on convolutional baselines.\nsource_train: class counts 0:19, 1:18, 2:2, 3:1, 4:1 (example label 0).\nsource_train sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.5073000192642212, 0.29750001430511475, 0.1597999930381775, 0.11580000072717667, 0.06870000064373016, -0.0215000007301569, -0.06700000166893005, -0.0939000025391…\nsource_train flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]\ntarget_train: class counts 0:6 (example label 0).\ntarget_train sample window (first 3 ch × 12 steps): [[-1.896399974822998, -1.9917000532150269, -1.5246000289916992, 0.0, -0.8306000232696533, 0.0, -0.16660000383853912, 0.0, 0.17499999701976776, 0.2815000116825104, 0.4404999911785126, 0.287200003862381], [-2.2899999618530273, 2.789099931716919, 3.0618999004364014, 0.0, 2.724100112915039, 0.0, 1.9648000001907349, 0.0, 0.5493000149726868, 0.6560999751091003, -2.791300058364868, 2.6998000144958496], [-2.7012999057769775,…\ntarget_train flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]\nsource_val: class counts 0:5, 1:5, 2:1, 4:1 (example label 0).\nsource_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.3109000027179718, 0.25519999861717224, 0.11729999631643295, 0.027000000700354576, -0.023900000378489494, -0.09200000017881393, -0.14669999480247498, -0.17059999…\nsource_val flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]\ntarget_val: class counts 0:4 (example label 0).\ntarget_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 2.1417999267578125, 2.015700101852417, 1.9608999490737915, 2.140199899673462, 1.8382999897003174, 1.805999994277954, 3.2121999263763428, 1.5262000560760498, 1.592…\ntarget_val flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]", 'numeric_summary': {'dataset': 'Battery_inconsistent', 'sequence_length_requested': 32, 'notes': 'label_inconsistent', 'lr_hint': 0.0005, 'dropout_hint': 0.35, 'num_classes_hint': None, 'splits': {'source_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.5073000192642212, 0.29750001430511475, 0.1597999930381775, 0.11580000072717667, 0.06870000064373016, -0.0215000007301569, -0.06700000166893005, -0.09390000253915787, -0.14229999482631683, -0.26440000534057617, -0.26820001006126404], [-2.4202001094818115, 0.3971000015735626, 0.20489999651908875, 0.07859999686479568, 0.03830000013113022, -0.0044999998062849045, -0.0908999964594841, -0.1347000002861023, -0.15940000116825104, -0.20960000157356262, -0.3246999979019165, -0.32820001244544983]]}, 'batch_channel_mean': [0.8607000112533569, -0.1421000063419342, -0.2084999978542328, -0.07079999893903732, -0.16120000183582306, 0.534600019454956, -0.3154999911785126, 0.24279999732971191], 'batch_channel_std': [1.059499979019165, 0.5717999935150146, 0.5095999836921692, 0.6176000237464905, 0.5239999890327454, 0.9284999966621399, 0.7612000107765198, 0.8140000104904175], 'class_distribution': {'0': 19, '1': 18, '2': 2, '3': 1, '4': 1}, 'feature_range': [-2.9057923445856524, 5.202832943374929], 'feature_global_mean': -0.008143604364574682, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]}, 'target_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.896399974822998, -1.9917000532150269, -1.5246000289916992, 0.0, -0.8306000232696533, 0.0, -0.16660000383853912, 0.0, 0.17499999701976776, 0.2815000116825104, 0.4404999911785126, 0.287200003862381], [-2.2899999618530273, 2.789099931716919, 3.0618999004364014, 0.0, 2.724100112915039, 0.0, 1.9648000001907349, 0.0, 0.5493000149726868, 0.6560999751091003, -2.791300058364868, 2.6998000144958496], [-2.7012999057769775, 1.3554999828338623, 1.62090003490448, 0.0, 1.8700000047683716, 0.0, 1.3710999488830566, 0.0, 0.1671999990940094, 0.0502999983727932, -2.187700033187866, 0.9710999727249146]]}, 'batch_channel_mean': [0.7294999957084656, 0.8521999716758728, 1.1779999732971191, 0.9107999801635742, 1.1938999891281128, -0.11500000208616257, -0.24160000681877136, -0.2093999981880188], 'batch_channel_std': [1.037600040435791, 1.1383999586105347, 1.261199951171875, 1.3704999685287476, 1.382200002670288, 1.318600058555603, 1.0240000486373901, 1.1060999631881714], 'class_distribution': {'0': 6}, 'feature_range': [-3.6390493997246667, 19.875169049014566], 'feature_global_mean': 0.4374359295879304, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]}, 'source_val': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.3109000027179718, 0.25519999861717224, 0.11729999631643295, 0.027000000700354576, -0.023900000378489494, -0.09200000017881393, -0.14669999480247498, -0.17059999704360962, -0.19750000536441803, -0.23759999871253967, -0.2761000096797943], [-2.4202001094818115, 0.210999995470047, 0.16750000417232513, 0.040699999779462814, -0.04349999874830246, -0.09049999713897705, -0.15610000491142273, -0.20749999582767487, -0.2303999960422516, -0.26170000433921814, -0.3025999963283539, -0.33959999680519104]]}, 'batch_channel_mean': [0.8607000112533569, -0.14800000190734863, -0.21410000324249268, -0.1005999967455864, -0.1704999953508377, 0.7595000267028809, -0.25529998540878296, 0.00139999995008111], 'batch_channel_std': [1.059499979019165, 0.5544999837875366, 0.4968999922275543, 0.6308000087738037, 0.5254999995231628, 0.8083000183105469, 0.7978000044822693, 0.6376000046730042], 'class_distribution': {'0': 5, '1': 5, '2': 1, '4': 1}, 'feature_range': [-2.9057923445856524, 5.219029621397489], 'feature_global_mean': -0.004320963409587972, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]}, 'target_val': {'batch_shape': [4, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 2.1417999267578125, 2.015700101852417, 1.9608999490737915, 2.140199899673462, 1.8382999897003174, 1.805999994277954, 3.2121999263763428, 1.5262000560760498, 1.5922000408172607, 2.4560999870300293, 0.5361999869346619], [-2.4202001094818115, 2.6226999759674072, 2.5090999603271484, 2.4544999599456787, 2.5053000450134277, 2.200200080871582, 2.1552000045776367, 3.31030011177063, 1.7338000535964966, 1.7655999660491943, 2.470400094985962, 0.6173999905586243]]}, 'batch_channel_mean': [0.8607000112533569, 0.8479999899864197, 1.1744999885559082, 0.14030000567436218, 0.7558000087738037, -0.8087999820709229, -0.2743000090122223, -0.7925999760627747], 'batch_channel_std': [1.059499979019165, 1.2324999570846558, 1.3095999956130981, 1.6520999670028687, 1.822100043296814, 0.26759999990463257, 0.8853999972343445, 1.1957999467849731], 'class_distribution': {'0': 4}, 'feature_range': [-3.571829448600409, 19.622460716154905], 'feature_global_mean': 0.28418790425941914, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]}}, 'dataset_variant': 'argonne_battery', 'feature_names': ['cycle_number', 'energy_charge', 'capacity_charge', 'energy_discharge', 'capacity_discharge', 'cycle_start', 'cycle_duration'], 'source_cathodes': ['5Vspinel'], 'target_cathodes': ['Li1.2Ni0.3Mn0.6O2', 'Li1.35Ni0.33Mn0.67O2.35'], 'label_column': 'eol_class', 'split_used': 'source_train', 'batch_size_seen': 8, 'channels': 21, 'seq_len': 32}}
12-12 15:32:50 llm_cfg: {'architecture': 'cnn_1d', 'model_name': 'cnn_features_1d', 'self_attention': False, 'sngp': True, 'openmax': False, 'use_unknown_head': False, 'bottleneck': 256, 'dropout': 0.35, 'learning_rate': 0.0005, 'batch_size': 8, 'lambda_src': 1.5, 'warmup_epochs': 10, 'rationale': 'The dataset has 21 channels and short sequences (32 steps) with label inconsistency and domain shift between source and target cathodes. WideResNet_edited is tuned for battery data and handles domain gaps well. Using SNGP and an unknown head helps manage uncertainty and avoid overconfident extrapolation on outlier cycles. A moderate bottleneck (256) balances capacity and regularization, with dropout at 0.35 to prevent overfitting. Batch size 8 matches seen data, learning rate 0.0005 is stable, and warmup_epochs 10 aids smooth adaptation. Target cathode: Li1.2Ni0.3Mn0.6O2. Source cathodes: 5Vspinel (high-voltage spinel (manganese rich)). Source/target chemistries differ → expect domain shift. Evaluated 21 channels × 32-step windows and matched them with cnn_1d capacity. Target fine-tune spans ≈6 cycles versus 41 source cycles, guiding lr=5.00e-04 and dropout=0.35.', '_provider': 'openai', '_raw': '{\n  "model_name": "WideResNet_edited",\n  "self_attention": false,\n  "sngp": true,\n  "openmax": false,\n  "use_unknown_head": true,\n  "bottleneck": 256,\n  "dropout": 0.35,\n  "learning_rate": 0.0005,\n  "batch_size": 8,\n  "lambda_src": 1.0,\n  "warmup_epochs": 10,\n  "rationale": "The dataset has 21 channels and short sequences (32 steps) with label inconsistency and domain shift between source and target cathodes. WideResNet_edited is tuned for battery data and handles domain gaps well. Using SNGP and an unknown head helps manage uncertainty and avoid overconfident extrapolation on outlier cycles. A moderate bottleneck (256) balances capacity and regularization, with dropout at 0.35 to prevent overfitting. Batch size 8 matches seen data, learning rate 0.0005 is stable, and warmup_epochs 10 aids smooth adaptation."\n}'}
12-12 15:32:50 llm_cfg_stamp: 20251212_131825
12-12 15:32:50 tag: detcnn_20251212_131825
12-12 15:32:50 pretrained_model_path: ./checkpoint/transfer_cnn_features_1d_spinel5v_to_lirich_1212/best_model.pth
12-12 15:32:50 dataset_cycle_stats: {'source_train_cycles': 615, 'source_val_cycles': 180, 'source_val_has_holdout': True, 'source_cycle_limit': 15, 'target_train_cycles': 90, 'target_val_cycles': 60, 'target_val_has_holdout': True, 'target_cycle_limit': 15, 'source_train_sequences': 41, 'source_val_sequences': 12, 'target_train_sequences': 6, 'target_val_sequences': 4, 'source_train_cells': 5, 'source_val_cells': 2, 'target_train_cells': 5, 'target_val_cells': 3, 'cycles_per_cell_per_cathode': {'source_train': {'5Vspinel': [{'filename': 'batch_B11B_cell_4.h5', 'cycles': 15, 'total_cycles': 216}, {'filename': 'batch_B26U_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26V_cell_3.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26V_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26V_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26W_cell_1.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26W_cell_3.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26W_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26W_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26X_cell_1.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26X_cell_3.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26X_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26Y_cell_3.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26Y_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26Y_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26Z_cell_1.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26Z_cell_3.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B5A_cell_1.h5', 'cycles': 15, 'total_cycles': 846}, {'filename': 'batch_B5A_cell_5.h5', 'cycles': 15, 'total_cycles': 855}, {'filename': 'batch_B26V_cell_1.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26T_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26AA_cell_1.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26T_cell_4.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26AA_cell_4.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26K_cell_1.h5', 'cycles': 15, 'total_cycles': 221}, {'filename': 'batch_B26L_cell_1.h5', 'cycles': 15, 'total_cycles': 2028}, {'filename': 'batch_B26N_cell_1.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26O_cell_1.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26O_cell_4.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26O_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26P_cell_3.h5', 'cycles': 15, 'total_cycles': 421}, {'filename': 'batch_B26P_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26Q_cell_3.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26Q_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26R_cell_1.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26R_cell_3.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26R_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26S_cell_3.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26S_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26S_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B5A_cell_7.h5', 'cycles': 15, 'total_cycles': 687}]}, 'source_val': {'5Vspinel': [{'filename': 'batch_B26K_cell_2.h5', 'cycles': 15, 'total_cycles': 221}, {'filename': 'batch_B26L_cell_2.h5', 'cycles': 15, 'total_cycles': 2028}, {'filename': 'batch_B26M_cell_2.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26P_cell_2.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26P_cell_6.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26R_cell_2.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26T_cell_2.h5', 'cycles': 15, 'total_cycles': 220}, {'filename': 'batch_B26V_cell_2.h5', 'cycles': 15, 'total_cycles': 421}, {'filename': 'batch_B26X_cell_2.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26Y_cell_2.h5', 'cycles': 15, 'total_cycles': 421}, {'filename': 'batch_B26Z_cell_2.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B5A_cell_2.h5', 'cycles': 15, 'total_cycles': 820}]}, 'target_train': {'Li1.2Ni0.3Mn0.6O2': [{'filename': 'batch_B3A_cell_4.h5', 'cycles': 15, 'total_cycles': 181}, {'filename': 'batch_B3B_cell_2.h5', 'cycles': 15, 'total_cycles': 181}, {'filename': 'batch_B3B_cell_3.h5', 'cycles': 15, 'total_cycles': 180}, {'filename': 'batch_B3B_cell_7.h5', 'cycles': 15, 'total_cycles': 180}], 'Li1.35Ni0.33Mn0.67O2.35': [{'filename': 'batch_B13A_cell_4.h5', 'cycles': 15, 'total_cycles': 169}, {'filename': 'batch_B13A_cell_8.h5', 'cycles': 15, 'total_cycles': 218}]}, 'target_val': {'Li1.2Ni0.3Mn0.6O2': [{'filename': 'batch_B3B_cell_1.h5', 'cycles': 15, 'total_cycles': 181}, {'filename': 'batch_B3B_cell_5.h5', 'cycles': 15, 'total_cycles': 180}], 'Li1.35Ni0.33Mn0.67O2.35': [{'filename': 'batch_B13A_cell_13.h5', 'cycles': 15, 'total_cycles': 218}, {'filename': 'batch_B8A_cell_1.h5', 'cycles': 15, 'total_cycles': 214}]}}, 'feature_columns': ('cycle_number', 'energy_charge', 'capacity_charge', 'energy_discharge', 'capacity_discharge', 'cycle_start', 'cycle_duration', 'capacity_retention', 'energy_retention', 'delta_capacity_discharge', 'delta_energy_discharge', 'delta_cycle_duration', 'rolling_capacity_mean', 'rolling_capacity_std', 'rolling_energy_mean', 'rolling_energy_std', 'rolling_duration_mean', 'duration_ratio', 'coulombic_efficiency', 'energy_efficiency', 'time_per_capacity'), 'chemistry_by_cathode': {'5Vspinel': {'cathode': '5Vspinel', 'anode': 'LTO', 'electrolyte': 'R&D', 'dataset': 'Argonne'}, 'FCG': {'cathode': 'FCG', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'HE5050': {'cathode': 'HE5050', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'Li1.2Ni0.3Mn0.6O2': {'cathode': 'Li1.2Ni0.3Mn0.6O2', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'Li1.35Ni0.33Mn0.67O2.35': {'cathode': 'Li1.35Ni0.33Mn0.67O2.35', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'NMC111': {'cathode': 'NMC111', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'NMC532': {'cathode': 'NMC532', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'NMC622': {'cathode': 'NMC622', 'anode': 'C_Si', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'NMC811': {'cathode': 'NMC811', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}}, 'chemistry_context': {'source': {'5Vspinel': {'cathode': '5Vspinel', 'anode': 'LTO', 'electrolyte': 'R&D', 'dataset': 'Argonne'}}, 'target': {'Li1.2Ni0.3Mn0.6O2': {'cathode': 'Li1.2Ni0.3Mn0.6O2', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'Li1.35Ni0.33Mn0.67O2.35': {'cathode': 'Li1.35Ni0.33Mn0.67O2.35', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}}, 'dataset_names': ['Argonne']}}
12-12 15:32:50 input_size: 32
12-12 15:32:50 reinit_head: False
12-12 15:32:50 using 1 cpu
12-12 15:32:50 Reducing learning rate to 5e-05 for 6 target samples
12-12 15:32:50 Freezing early layers of backbone for 6 target samples
12-12 16:44:53 data_name: Battery_inconsistent
12-12 16:44:53 data_dir: ./my_datasets/Battery
12-12 16:44:53 csv: ./my_datasets/Battery/battery_cycles_labeled.csv
12-12 16:44:53 normlizetype: mean-std
12-12 16:44:53 method: sngp
12-12 16:44:53 gp_hidden_dim: 2048
12-12 16:44:53 spectral_norm_bound: 0.95
12-12 16:44:53 n_power_iterations: 1
12-12 16:44:53 nesterov: True
12-12 16:44:53 print_freq: 10
12-12 16:44:53 layers: 16
12-12 16:44:53 widen_factor: 1
12-12 16:44:53 droprate: 0.35
12-12 16:44:53 cuda_device: 0
12-12 16:44:53 checkpoint_dir: ./checkpoint
12-12 16:44:53 pretrained: True
12-12 16:44:53 batch_size: 8
12-12 16:44:53 warmup_epochs: 4
12-12 16:44:53 num_workers: 0
12-12 16:44:53 bottleneck: True
12-12 16:44:53 bottleneck_num: 256
12-12 16:44:53 last_batch: False
12-12 16:44:53 hidden_size: 1024
12-12 16:44:53 trade_off_adversarial: Step
12-12 16:44:53 lam_adversarial: 1
12-12 16:44:53 opt: adam
12-12 16:44:53 lr: 5e-05
12-12 16:44:53 momentum: 0.9
12-12 16:44:53 weight_decay: 1e-05
12-12 16:44:53 lr_scheduler: step
12-12 16:44:53 gamma: 0.1
12-12 16:44:53 steps: 150, 250
12-12 16:44:53 middle_epoch: 15
12-12 16:44:53 max_epoch: 82
12-12 16:44:53 print_step: 25
12-12 16:44:53 inconsistent: UAN
12-12 16:44:53 model_name: cnn_features_1d
12-12 16:44:53 th: 0.5
12-12 16:44:53 input_channels: 21
12-12 16:44:53 classification_label: eol_class
12-12 16:44:53 sequence_length: 32
12-12 16:44:53 cycles_per_file: 15
12-12 16:44:53 source_cycles_per_file: None
12-12 16:44:53 target_cycles_per_file: None
12-12 16:44:53 cycle_ablation: False
12-12 16:44:53 cycle_ablation_start: 5
12-12 16:44:53 cycle_ablation_step: 10
12-12 16:44:53 cycle_ablation_max: None
12-12 16:44:53 literature_context_file: ./references/joule_s2542-4351-22-00409-3.md
12-12 16:44:53 sample_random_state: 42
12-12 16:44:53 transfer_task: [[[0], [1]], [[0], [2]], [[0], [3]], [[1], [0]], [[1], [2]], [[1], [3]], [[2], [0]], [[2], [1]], [[2], [3]], [[3], [0]], [[3], [1]], [[3], [2]]]
12-12 16:44:53 source_cathode: ['5Vspinel']
12-12 16:44:53 target_cathode: ['Li1.2Ni0.3Mn0.6O2', 'Li1.35Ni0.33Mn0.67O2.35']
12-12 16:44:53 num_classes: 5
12-12 16:44:53 domain_temperature: 1.0
12-12 16:44:53 class_temperature: 10.0
12-12 16:44:53 lambda_src: 0.6
12-12 16:44:53 lambda_src_decay_patience: 1
12-12 16:44:53 lambda_src_decay_factor: 0.5
12-12 16:44:53 lambda_src_min: 0.0
12-12 16:44:53 lambda_src_warmup: 0
12-12 16:44:53 improvement_metric: accuracy
12-12 16:44:53 skip_retry: False
12-12 16:44:53 auto_select: True
12-12 16:44:53 llm_compare: True
12-12 16:44:53 llm_backend: openai
12-12 16:44:53 llm_model: None
12-12 16:44:53 llm_context: 
12-12 16:44:53 llm_ablation: False
12-12 16:44:53 llm_per_transfer: True
12-12 16:44:53 ablation_cycle_limits: 
12-12 16:44:53 llm_cfg_inputs: {'text_context': "Dataset: Argonne National Laboratory battery aging time-series with partial cycle windows.\nSource cathodes: 5Vspinel; target cathodes: Li1.2Ni0.3Mn0.6O2, Li1.35Ni0.33Mn0.67O2.35.\nLabel column 'eol_class' with ~None classes; sequence length 32; 21 channels covering cycle_number, energy_charge, capacity_charge, energy_discharge, capacity_discharge, cycle_start, cycle_duration.\nLiterature cues (Joule S2542-4351(22)00409-3, chemistry-sensitive ablations):\nJoule 2022 (S2542-4351(22)00409-3) key cues for chemistry-aware ablation:\n- Early-cycle capacity fade slopes and coulombic-efficiency stabilization highlight whether aging is lithium-inventory loss (graphite/anode-electrolyte limited) versus cathode structural decay (e.g., Ni-rich NMC cathodes with electrolyte oxidation risk).\n- High initial impedance growth, thick SEI signatures, or electrolyte oxidation markers flag chemistries that benefit from uncertainty-aware heads (SNGP/OpenMax) to avoid overconfident extrapolation on outlier cycles.\n- LFP/graphite pairs tend to show flatter voltage plateaus and slower early fade; Ni-rich NMC chemistries degrade faster under aggressive cycling and need stronger regularization or shorter cycle horizons in ablations.\n- Transfer between mismatched chemistries (e.g., NMC → LFP) should down-weight source loss and favor architectures that adapt quickly with self-attention or wider bottlenecks; closely matched chemistries can rely more on convolutional baselines.\nsource_train: class counts 0:19, 1:18, 2:2, 3:1, 4:1 (example label 2).\nsource_train sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.14630000293254852, 0.07519999891519547, -2.6510000228881836, 0.012799999676644802, -0.2791000008583069, -0.01119999960064888, -0.011500000022351742, 0.001200000…\nsource_train flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]\ntarget_train: class counts 0:6 (example label 0).\ntarget_train sample window (first 3 ch × 12 steps): [[-1.896399974822998, -2.010499954223633, -1.5264999866485596, 0.0, -0.8173999786376953, 0.0, -0.06809999793767929, 0.0, 0.2856000065803528, 0.34790000319480896, 0.5138000249862671, 0.696399986743927], [-2.2899999618530273, 3.247299909591675, 3.219599962234497, 0.0, 2.822499990463257, 0.0, 1.9033000469207764, 0.0, 1.7319999933242798, 1.4701999425888062, 1.604599952697754, -0.8252999782562256], [-2.7012999057769775, 1…\ntarget_train flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]\nsource_val: class counts 0:5, 1:5, 2:1, 4:1 (example label 0).\nsource_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.3109000027179718, 0.25519999861717224, 0.11729999631643295, 0.027000000700354576, -0.023900000378489494, -0.09200000017881393, -0.14669999480247498, -0.17059999…\nsource_val flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]\ntarget_val: class counts 0:4 (example label 0).\ntarget_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 2.1417999267578125, 2.015700101852417, 1.9608999490737915, 2.140199899673462, 1.8382999897003174, 1.805999994277954, 3.2121999263763428, 1.5262000560760498, 1.592…\ntarget_val flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]", 'numeric_summary': {'dataset': 'Battery_inconsistent', 'sequence_length_requested': 32, 'notes': 'label_inconsistent', 'lr_hint': 0.0005, 'dropout_hint': 0.35, 'num_classes_hint': None, 'splits': {'source_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 2, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.14630000293254852, 0.07519999891519547, -2.6510000228881836, 0.012799999676644802, -0.2791000008583069, -0.01119999960064888, -0.011500000022351742, 0.0012000000569969416, 0.0003000000142492354, -0.008899999782443047, -0.018300000578165054], [-2.4202001094818115, 0.0414000004529953, -0.011800000444054604, -2.420099973678589, -0.094200000166893, -0.3474000096321106, -0.09600000083446503, -0.09610000252723694, -0.0843999981880188, -0.0851999968290329, -0.09309999644756317, -0.10279999673366547]]}, 'batch_channel_mean': [0.8607000112533569, -0.10819999873638153, -0.17669999599456787, -0.01860000006854534, -0.12030000239610672, 0.5947999954223633, -0.29600000381469727, 0.32420000433921814], 'batch_channel_std': [1.059499979019165, 0.5400000214576721, 0.4787999987602234, 0.5626999735832214, 0.483599990606308, 0.9283000230789185, 0.7759000062942505, 0.7864000201225281], 'class_distribution': {'0': 19, '1': 18, '2': 2, '3': 1, '4': 1}, 'feature_range': [-2.9057923445856524, 5.202832943374929], 'feature_global_mean': -0.008143604364574682, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]}, 'target_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.896399974822998, -2.010499954223633, -1.5264999866485596, 0.0, -0.8173999786376953, 0.0, -0.06809999793767929, 0.0, 0.2856000065803528, 0.34790000319480896, 0.5138000249862671, 0.696399986743927], [-2.2899999618530273, 3.247299909591675, 3.219599962234497, 0.0, 2.822499990463257, 0.0, 1.9033000469207764, 0.0, 1.7319999933242798, 1.4701999425888062, 1.604599952697754, -0.8252999782562256], [-2.7012999057769775, 1.7355999946594238, 1.8173999786376953, 0.0, 2.0676000118255615, 0.0, 1.989300012588501, 0.0, 1.4453999996185303, 0.8960999846458435, 0.3228999972343445, -1.125100016593933]]}, 'batch_channel_mean': [0.707099974155426, 0.8895000219345093, 1.1301000118255615, 0.8313000202178955, 1.0865999460220337, -0.09960000216960907, -0.017400000244379044, -0.5198000073432922], 'batch_channel_std': [1.030500054359436, 1.198199987411499, 1.2407000064849854, 1.3655999898910522, 1.382200002670288, 1.2339999675750732, 1.2590999603271484, 0.8029000163078308], 'class_distribution': {'0': 6}, 'feature_range': [-3.6390493997246667, 19.875169049014566], 'feature_global_mean': 0.4374359295879304, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]}, 'source_val': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.3109000027179718, 0.25519999861717224, 0.11729999631643295, 0.027000000700354576, -0.023900000378489494, -0.09200000017881393, -0.14669999480247498, -0.17059999704360962, -0.19750000536441803, -0.23759999871253967, -0.2761000096797943], [-2.4202001094818115, 0.210999995470047, 0.16750000417232513, 0.040699999779462814, -0.04349999874830246, -0.09049999713897705, -0.15610000491142273, -0.20749999582767487, -0.2303999960422516, -0.26170000433921814, -0.3025999963283539, -0.33959999680519104]]}, 'batch_channel_mean': [0.8607000112533569, -0.14800000190734863, -0.21410000324249268, -0.1005999967455864, -0.1704999953508377, 0.7595000267028809, -0.25529998540878296, 0.00139999995008111], 'batch_channel_std': [1.059499979019165, 0.5544999837875366, 0.4968999922275543, 0.6308000087738037, 0.5254999995231628, 0.8083000183105469, 0.7978000044822693, 0.6376000046730042], 'class_distribution': {'0': 5, '1': 5, '2': 1, '4': 1}, 'feature_range': [-2.9057923445856524, 5.219029621397489], 'feature_global_mean': -0.004320963409587972, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]}, 'target_val': {'batch_shape': [4, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 2.1417999267578125, 2.015700101852417, 1.9608999490737915, 2.140199899673462, 1.8382999897003174, 1.805999994277954, 3.2121999263763428, 1.5262000560760498, 1.5922000408172607, 2.4560999870300293, 0.5361999869346619], [-2.4202001094818115, 2.6226999759674072, 2.5090999603271484, 2.4544999599456787, 2.5053000450134277, 2.200200080871582, 2.1552000045776367, 3.31030011177063, 1.7338000535964966, 1.7655999660491943, 2.470400094985962, 0.6173999905586243]]}, 'batch_channel_mean': [0.8607000112533569, 0.8479999899864197, 1.1744999885559082, 0.14030000567436218, 0.7558000087738037, -0.8087999820709229, -0.2743000090122223, -0.7925999760627747], 'batch_channel_std': [1.059499979019165, 1.2324999570846558, 1.3095999956130981, 1.6520999670028687, 1.822100043296814, 0.26759999990463257, 0.8853999972343445, 1.1957999467849731], 'class_distribution': {'0': 4}, 'feature_range': [-3.571829448600409, 19.622460716154905], 'feature_global_mean': 0.28418790425941914, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]}}, 'dataset_variant': 'argonne_battery', 'feature_names': ['cycle_number', 'energy_charge', 'capacity_charge', 'energy_discharge', 'capacity_discharge', 'cycle_start', 'cycle_duration'], 'source_cathodes': ['5Vspinel'], 'target_cathodes': ['Li1.2Ni0.3Mn0.6O2', 'Li1.35Ni0.33Mn0.67O2.35'], 'label_column': 'eol_class', 'split_used': 'source_train', 'batch_size_seen': 8, 'channels': 21, 'seq_len': 32}}
12-12 16:44:53 llm_cfg: {'architecture': 'cnn_1d', 'model_name': 'cnn_features_1d', 'self_attention': False, 'sngp': True, 'openmax': False, 'use_unknown_head': False, 'bottleneck': 256, 'dropout': 0.35, 'learning_rate': 0.0005, 'batch_size': 8, 'lambda_src': 1.5, 'warmup_epochs': 10, 'rationale': 'The dataset has 21 channels and short sequence length (32), with significant domain shift between source and target chemistries. WideResNet_edited is tailored for Argonne battery data with physics-inspired feature edits, making it well suited for transfer learning across chemistries. The bottleneck of 256 balances capacity and regularization, while dropout at 0.35 mitigates overfitting given label inconsistency. Self-attention is avoided to reduce overfitting risk on a small source domain, and openmax/SNGP are not prioritized since the label inconsistency is moderate and unknown rejection is less critical than transfer adaptation. Target cathode: Li1.2Ni0.3Mn0.6O2. Source cathodes: 5Vspinel (high-voltage spinel (manganese rich)). Source/target chemistries differ → expect domain shift. Evaluated 21 channels × 32-step windows and matched them with cnn_1d capacity. Target fine-tune spans ≈6 cycles versus 41 source cycles, guiding lr=5.00e-04 and dropout=0.35.', '_provider': 'openai', '_raw': '{\n  "model_name": "WideResNet_edited",\n  "self_attention": false,\n  "sngp": false,\n  "openmax": false,\n  "use_unknown_head": false,\n  "bottleneck": 256,\n  "dropout": 0.35,\n  "learning_rate": 0.0005,\n  "batch_size": 8,\n  "lambda_src": 1.0,\n  "warmup_epochs": 10,\n  "rationale": "The dataset has 21 channels and short sequence length (32), with significant domain shift between source and target chemistries. WideResNet_edited is tailored for Argonne battery data with physics-inspired feature edits, making it well suited for transfer learning across chemistries. The bottleneck of 256 balances capacity and regularization, while dropout at 0.35 mitigates overfitting given label inconsistency. Self-attention is avoided to reduce overfitting risk on a small source domain, and openmax/SNGP are not prioritized since the label inconsistency is moderate and unknown rejection is less critical than transfer adaptation."\n}'}
12-12 16:44:53 llm_cfg_stamp: 20251212_131825
12-12 16:44:53 tag: sngp_wrn_sa_20251212_131825
12-12 16:44:53 pretrained_model_path: ./checkpoint/transfer_cnn_features_1d_spinel5v_to_lirich_1212/best_model.pth
12-12 16:44:53 dataset_cycle_stats: {'source_train_cycles': 615, 'source_val_cycles': 180, 'source_val_has_holdout': True, 'source_cycle_limit': 15, 'target_train_cycles': 90, 'target_val_cycles': 60, 'target_val_has_holdout': True, 'target_cycle_limit': 15, 'source_train_sequences': 41, 'source_val_sequences': 12, 'target_train_sequences': 6, 'target_val_sequences': 4, 'source_train_cells': 5, 'source_val_cells': 2, 'target_train_cells': 5, 'target_val_cells': 3, 'cycles_per_cell_per_cathode': {'source_train': {'5Vspinel': [{'filename': 'batch_B11B_cell_4.h5', 'cycles': 15, 'total_cycles': 216}, {'filename': 'batch_B26U_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26V_cell_3.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26V_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26V_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26W_cell_1.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26W_cell_3.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26W_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26W_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26X_cell_1.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26X_cell_3.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26X_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26Y_cell_3.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26Y_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26Y_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26Z_cell_1.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26Z_cell_3.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B5A_cell_1.h5', 'cycles': 15, 'total_cycles': 846}, {'filename': 'batch_B5A_cell_5.h5', 'cycles': 15, 'total_cycles': 855}, {'filename': 'batch_B26V_cell_1.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26T_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26AA_cell_1.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26T_cell_4.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26AA_cell_4.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26K_cell_1.h5', 'cycles': 15, 'total_cycles': 221}, {'filename': 'batch_B26L_cell_1.h5', 'cycles': 15, 'total_cycles': 2028}, {'filename': 'batch_B26N_cell_1.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26O_cell_1.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26O_cell_4.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26O_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26P_cell_3.h5', 'cycles': 15, 'total_cycles': 421}, {'filename': 'batch_B26P_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26Q_cell_3.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26Q_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26R_cell_1.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26R_cell_3.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26R_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26S_cell_3.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26S_cell_4.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26S_cell_5.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B5A_cell_7.h5', 'cycles': 15, 'total_cycles': 687}]}, 'source_val': {'5Vspinel': [{'filename': 'batch_B26K_cell_2.h5', 'cycles': 15, 'total_cycles': 221}, {'filename': 'batch_B26L_cell_2.h5', 'cycles': 15, 'total_cycles': 2028}, {'filename': 'batch_B26M_cell_2.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26P_cell_2.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26P_cell_6.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B26R_cell_2.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26T_cell_2.h5', 'cycles': 15, 'total_cycles': 220}, {'filename': 'batch_B26V_cell_2.h5', 'cycles': 15, 'total_cycles': 421}, {'filename': 'batch_B26X_cell_2.h5', 'cycles': 15, 'total_cycles': 420}, {'filename': 'batch_B26Y_cell_2.h5', 'cycles': 15, 'total_cycles': 421}, {'filename': 'batch_B26Z_cell_2.h5', 'cycles': 15, 'total_cycles': 219}, {'filename': 'batch_B5A_cell_2.h5', 'cycles': 15, 'total_cycles': 820}]}, 'target_train': {'Li1.2Ni0.3Mn0.6O2': [{'filename': 'batch_B3A_cell_4.h5', 'cycles': 15, 'total_cycles': 181}, {'filename': 'batch_B3B_cell_2.h5', 'cycles': 15, 'total_cycles': 181}, {'filename': 'batch_B3B_cell_3.h5', 'cycles': 15, 'total_cycles': 180}, {'filename': 'batch_B3B_cell_7.h5', 'cycles': 15, 'total_cycles': 180}], 'Li1.35Ni0.33Mn0.67O2.35': [{'filename': 'batch_B13A_cell_4.h5', 'cycles': 15, 'total_cycles': 169}, {'filename': 'batch_B13A_cell_8.h5', 'cycles': 15, 'total_cycles': 218}]}, 'target_val': {'Li1.2Ni0.3Mn0.6O2': [{'filename': 'batch_B3B_cell_1.h5', 'cycles': 15, 'total_cycles': 181}, {'filename': 'batch_B3B_cell_5.h5', 'cycles': 15, 'total_cycles': 180}], 'Li1.35Ni0.33Mn0.67O2.35': [{'filename': 'batch_B13A_cell_13.h5', 'cycles': 15, 'total_cycles': 218}, {'filename': 'batch_B8A_cell_1.h5', 'cycles': 15, 'total_cycles': 214}]}}, 'feature_columns': ('cycle_number', 'energy_charge', 'capacity_charge', 'energy_discharge', 'capacity_discharge', 'cycle_start', 'cycle_duration', 'capacity_retention', 'energy_retention', 'delta_capacity_discharge', 'delta_energy_discharge', 'delta_cycle_duration', 'rolling_capacity_mean', 'rolling_capacity_std', 'rolling_energy_mean', 'rolling_energy_std', 'rolling_duration_mean', 'duration_ratio', 'coulombic_efficiency', 'energy_efficiency', 'time_per_capacity'), 'chemistry_by_cathode': {'5Vspinel': {'cathode': '5Vspinel', 'anode': 'LTO', 'electrolyte': 'R&D', 'dataset': 'Argonne'}, 'FCG': {'cathode': 'FCG', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'HE5050': {'cathode': 'HE5050', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'Li1.2Ni0.3Mn0.6O2': {'cathode': 'Li1.2Ni0.3Mn0.6O2', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'Li1.35Ni0.33Mn0.67O2.35': {'cathode': 'Li1.35Ni0.33Mn0.67O2.35', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'NMC111': {'cathode': 'NMC111', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'NMC532': {'cathode': 'NMC532', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'NMC622': {'cathode': 'NMC622', 'anode': 'C_Si', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'NMC811': {'cathode': 'NMC811', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}}, 'chemistry_context': {'source': {'5Vspinel': {'cathode': '5Vspinel', 'anode': 'LTO', 'electrolyte': 'R&D', 'dataset': 'Argonne'}}, 'target': {'Li1.2Ni0.3Mn0.6O2': {'cathode': 'Li1.2Ni0.3Mn0.6O2', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}, 'Li1.35Ni0.33Mn0.67O2.35': {'cathode': 'Li1.35Ni0.33Mn0.67O2.35', 'anode': 'C', 'electrolyte': 'Gen 2', 'dataset': 'Argonne'}}, 'dataset_names': ['Argonne']}}
12-12 16:44:53 input_size: 32
12-12 16:44:53 reinit_head: False
12-12 16:44:53 using 1 cpu
12-12 16:44:53 Reducing learning rate to 5e-05 for 6 target samples
12-12 16:44:53 Freezing early layers of backbone for 6 target samples
