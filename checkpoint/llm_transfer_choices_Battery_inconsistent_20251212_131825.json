[
  {
    "dataset": "Battery_inconsistent",
    "source_cathodes": [
      "HE5050",
      "NMC111",
      "NMC532",
      "NMC622",
      "NMC811"
    ],
    "target_cathodes": [
      "5Vspinel"
    ],
    "llm_cfg": {
      "architecture": "cnn_1d",
      "model_name": "cnn_features_1d",
      "self_attention": false,
      "sngp": true,
      "openmax": false,
      "use_unknown_head": false,
      "bottleneck": 256,
      "dropout": 0.35,
      "learning_rate": 0.0005,
      "batch_size": 32,
      "lambda_src": 1.5,
      "warmup_epochs": 10,
      "rationale": "The dataset has 21 channels and short sequences (32 steps) with label inconsistency and domain shift between source and target cathodes. WideResNet_edited is tailored for battery data with physics-inspired features and handles transfer gaps well. Enabling SNGP and an unknown head helps manage uncertainty and out-of-distribution cycles due to chemistry differences. Dropout at 0.3 balances regularization against overfitting, and a bottleneck of 256 provides sufficient capacity without excessive compute. Batch size 64 matches seen data, and moderate warmup stabilizes training. Target cathode: 5Vspinel (high-voltage spinel (manganese rich)). Source cathodes: HE5050 (high-energy experimental blend), NMC111 (low-Ni NMC (stable, slower fade)), NMC532 (mid-Ni NMC (balanced energy vs. stability)), NMC622 (higher-Ni NMC (stronger energy, more fragile)), NMC811 (high-Ni NMC (highest energy, OOD vs low-Ni)). Source/target chemistries differ \u2192 expect domain shift. Evaluated 21 channels \u00d7 32-step windows and matched them with cnn_1d capacity. Target fine-tune spans \u224841 cycles versus 165 source cycles, guiding lr=5.00e-04 and dropout=0.35.",
      "_provider": "openai",
      "_raw": "{\n  \"model_name\": \"WideResNet_edited\",\n  \"self_attention\": false,\n  \"sngp\": true,\n  \"openmax\": false,\n  \"use_unknown_head\": true,\n  \"bottleneck\": 256,\n  \"dropout\": 0.3,\n  \"learning_rate\": 0.001,\n  \"batch_size\": 64,\n  \"lambda_src\": 1.0,\n  \"warmup_epochs\": 10,\n  \"rationale\": \"The dataset has 21 channels and short sequences (32 steps) with label inconsistency and domain shift between source and target cathodes. WideResNet_edited is tailored for battery data with physics-inspired features and handles transfer gaps well. Enabling SNGP and an unknown head helps manage uncertainty and out-of-distribution cycles due to chemistry differences. Dropout at 0.3 balances regularization against overfitting, and a bottleneck of 256 provides sufficient capacity without excessive compute. Batch size 64 matches seen data, and moderate warmup stabilizes training.\"\n}"
    },
    "numeric_summary": {
      "dataset": "Battery_inconsistent",
      "sequence_length_requested": 32,
      "notes": "label_inconsistent",
      "lr_hint": 0.001,
      "dropout_hint": 0.3,
      "num_classes_hint": null,
      "splits": {
        "source_train": {
          "batch_shape": [
            64,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 0,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -1.1878000497817993,
                0.29330000281333923,
                0.49129998683929443,
                0.4677000045776367,
                0.4731999933719635,
                0.23250000178813934,
                0.20350000262260437,
                0.2328999936580658,
                0.07029999792575836,
                0.08560000360012054,
                -1.1878000497817993,
                0.2483000010251999
              ],
              [
                -1.1461000442504883,
                0.2549000084400177,
                0.4860999882221222,
                0.4666999876499176,
                0.4471000134944916,
                0.20579999685287476,
                0.17980000376701355,
                0.18889999389648438,
                0.02930000051856041,
                0.04729999974370003,
                -1.1461000442504883,
                0.22660000622272491
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            0.09480000287294388,
            0.1200999990105629,
            0.07810000330209732,
            0.12549999356269836,
            0.23360000550746918,
            -0.24879999458789825,
            -0.026399999856948853
          ],
          "batch_channel_std": [
            1.059499979019165,
            1.031000018119812,
            1.0256999731063843,
            1.0378999710083008,
            1.0286999940872192,
            0.9093000292778015,
            0.84579998254776,
            0.7364000082015991
          ],
          "class_distribution": {
            "0": 23,
            "1": 22,
            "2": 41,
            "3": 37,
            "4": 42
          },
          "feature_range": [
            -10.071363881104789,
            26.962179689668158
          ],
          "feature_global_mean": 0.04733296260867068,
          "flattened_rows_head": [
            [
              -1.6202,
              -1.1878,
              -1.1461,
              -1.1625,
              -1.1386,
              -1.4633,
              -0.8297,
              -3.2104,
              -3.18,
              -0.14
            ],
            [
              -1.6202,
              -1.1878,
              -1.1461,
              -1.1625,
              -1.1386,
              -1.4633,
              -0.8297,
              -3.2104,
              -3.18,
              -0.14
            ],
            [
              -1.6202,
              -1.1878,
              -1.1461,
              -1.1625,
              -1.1386,
              -1.4633,
              -0.8297,
              -3.2104,
              -3.18,
              -0.14
            ]
          ]
        },
        "target_train": {
          "batch_shape": [
            64,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 2,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.7590999603271484,
                -1.7496000528335571,
                -1.2950999736785889,
                0.0,
                -0.6873999834060669,
                0.0,
                -0.13369999825954437,
                0.0,
                0.29809999465942383,
                0.40389999747276306,
                0.7049000263214111,
                0.8859000205993652
              ],
              [
                -0.8561999797821045,
                0.2721000015735626,
                0.1282999962568283,
                0.0,
                -0.1234000027179718,
                0.0,
                -0.4253000020980835,
                0.0,
                -0.30059999227523804,
                -0.11559999734163284,
                -0.3513000011444092,
                -0.2500999867916107
              ],
              [
                -1.3759000301361084,
                -0.5414999723434448,
                -0.6427000164985657,
                0.0,
                -0.3366999924182892,
                0.0,
                -0.25200000405311584,
                0.0,
                -0.11649999767541885,
                -0.1907999962568283,
                -0.2045000046491623,
                -0.18799999356269836
              ]
            ]
          },
          "batch_channel_mean": [
            0.44929999113082886,
            -0.0017000000225380063,
            -0.09690000116825104,
            -0.1582999974489212,
            -0.24130000174045563,
            -0.2190999984741211,
            -0.11270000040531158,
            0.05249999836087227
          ],
          "batch_channel_std": [
            1.0054999589920044,
            0.7505999803543091,
            0.7032999992370605,
            0.5990999937057495,
            0.6212999820709229,
            0.7793999910354614,
            0.7333999872207642,
            0.843500018119812
          ],
          "class_distribution": {
            "0": 19,
            "1": 18,
            "2": 2,
            "3": 1,
            "4": 1
          },
          "feature_range": [
            -3.210442631672878,
            5.194240374920385
          ],
          "feature_global_mean": -0.014805951466635246,
          "flattened_rows_head": [
            [
              -1.6202,
              -1.1878,
              -1.1461,
              -1.1625,
              -1.1386,
              -1.4633,
              -0.8297,
              -3.2104,
              -3.18,
              -0.14
            ],
            [
              -1.6202,
              -1.1878,
              -1.1461,
              -1.1625,
              -1.1386,
              -1.4633,
              -0.8309,
              -3.2104,
              -3.18,
              -0.14
            ],
            [
              -1.6202,
              -1.1878,
              -1.1461,
              -1.1625,
              -1.1386,
              -1.4633,
              -0.8309,
              -3.2104,
              -3.18,
              -0.14
            ]
          ]
        },
        "source_val": {
          "batch_shape": [
            64,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 3,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -1.1878000497817993,
                -1.1878000497817993,
                -1.1878000497817993,
                -1.1878000497817993,
                -1.1878000497817993,
                -1.1878000497817993,
                -1.1878000497817993,
                -1.1878000497817993,
                -1.1878000497817993,
                -1.1878000497817993,
                -1.1878000497817993,
                -1.1878000497817993
              ],
              [
                -1.1461000442504883,
                -1.1461000442504883,
                -1.1461000442504883,
                -1.1461000442504883,
                -1.1461000442504883,
                -1.1461000442504883,
                -1.1461000442504883,
                -1.1461000442504883,
                -1.1461000442504883,
                -1.1461000442504883,
                -1.1461000442504883,
                -1.1461000442504883
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            -0.018699999898672104,
            0.009499999694526196,
            -0.03319999948143959,
            0.014999999664723873,
            0.3003000020980835,
            -0.2304999977350235,
            -0.04769999906420708
          ],
          "batch_channel_std": [
            1.059499979019165,
            0.9320999979972839,
            0.9289000034332275,
            0.9254999756813049,
            0.9318000078201294,
            0.9613000154495239,
            0.8551999926567078,
            0.7867000102996826
          ],
          "class_distribution": {
            "0": 8,
            "1": 10,
            "2": 16,
            "3": 14,
            "4": 16
          },
          "feature_range": [
            -8.001291013303879,
            34.61519108755281
          ],
          "feature_global_mean": 0.03577341473527325,
          "flattened_rows_head": [
            [
              -1.6202,
              -1.1878,
              -1.1461,
              -1.1625,
              -1.1386,
              -1.4633,
              -0.8297,
              -3.2104,
              -3.18,
              -0.14
            ],
            [
              -1.6202,
              -1.1878,
              -1.1461,
              -1.1625,
              -1.1386,
              -1.4633,
              -0.8297,
              -3.2104,
              -3.18,
              -0.14
            ],
            [
              -1.6202,
              -1.1878,
              -1.1461,
              -1.1625,
              -1.1386,
              -1.4633,
              -0.8297,
              -3.2104,
              -3.18,
              -0.14
            ]
          ]
        },
        "target_val": {
          "batch_shape": [
            12,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 0,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -1.1878000497817993,
                -0.04089999943971634,
                -0.0625,
                -0.11590000241994858,
                -0.15080000460147858,
                -0.17059999704360962,
                -0.19689999520778656,
                -0.21809999644756317,
                -0.2273000031709671,
                -0.2378000020980835,
                -0.2533000111579895,
                -0.26820001006126404
              ],
              [
                -1.1461000442504883,
                -0.19830000400543213,
                -0.21389999985694885,
                -0.2596000134944916,
                -0.28999999165534973,
                -0.3068999946117401,
                -0.3305000066757202,
                -0.3490000069141388,
                -0.3573000133037567,
                -0.3684999942779541,
                -0.3833000063896179,
                -0.39660000801086426
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            -0.20559999346733093,
            -0.3409999907016754,
            -0.17790000140666962,
            -0.34299999475479126,
            1.0033999681472778,
            -0.10570000112056732,
            0.1467999964952469
          ],
          "batch_channel_std": [
            1.059499979019165,
            0.22210000455379486,
            0.18440000712871552,
            0.23589999973773956,
            0.1843000054359436,
            1.0601999759674072,
            0.8259000182151794,
            0.8374999761581421
          ],
          "class_distribution": {
            "0": 5,
            "1": 5,
            "2": 1,
            "4": 1
          },
          "feature_range": [
            -3.210442631672878,
            5.210269059855464
          ],
          "feature_global_mean": -0.008767313127343879,
          "flattened_rows_head": [
            [
              -1.6202,
              -1.1878,
              -1.1461,
              -1.1625,
              -1.1386,
              -1.4633,
              -0.8309,
              -3.2104,
              -3.18,
              -0.14
            ],
            [
              -1.6202,
              -1.1878,
              -1.1461,
              -1.1625,
              -1.1386,
              -1.4633,
              -0.8309,
              -3.2104,
              -3.18,
              -0.14
            ],
            [
              -1.6202,
              -1.1878,
              -1.1461,
              -1.1625,
              -1.1386,
              -1.4633,
              -0.8309,
              -3.2104,
              -3.18,
              -0.14
            ]
          ]
        }
      },
      "dataset_variant": "argonne_battery",
      "feature_names": [
        "cycle_number",
        "energy_charge",
        "capacity_charge",
        "energy_discharge",
        "capacity_discharge",
        "cycle_start",
        "cycle_duration"
      ],
      "source_cathodes": [
        "HE5050",
        "NMC111",
        "NMC532",
        "NMC622",
        "NMC811"
      ],
      "target_cathodes": [
        "5Vspinel"
      ],
      "label_column": "eol_class",
      "split_used": "source_train",
      "batch_size_seen": 64,
      "channels": 21,
      "seq_len": 32
    },
    "text_context": "Dataset: Argonne National Laboratory battery aging time-series with partial cycle windows.\nSource cathodes: HE5050, NMC111, NMC532, NMC622, NMC811; target cathodes: 5Vspinel.\nLabel column 'eol_class' with ~None classes; sequence length 32; 21 channels covering cycle_number, energy_charge, capacity_charge, energy_discharge, capacity_discharge, cycle_start, cycle_duration.\nLiterature cues (Joule S2542-4351(22)00409-3, chemistry-sensitive ablations):\nJoule 2022 (S2542-4351(22)00409-3) key cues for chemistry-aware ablation:\n- Early-cycle capacity fade slopes and coulombic-efficiency stabilization highlight whether aging is lithium-inventory loss (graphite/anode-electrolyte limited) versus cathode structural decay (e.g., Ni-rich NMC cathodes with electrolyte oxidation risk).\n- High initial impedance growth, thick SEI signatures, or electrolyte oxidation markers flag chemistries that benefit from uncertainty-aware heads (SNGP/OpenMax) to avoid overconfident extrapolation on outlier cycles.\n- LFP/graphite pairs tend to show flatter voltage plateaus and slower early fade; Ni-rich NMC chemistries degrade faster under aggressive cycling and need stronger regularization or shorter cycle horizons in ablations.\n- Transfer between mismatched chemistries (e.g., NMC \u2192 LFP) should down-weight source loss and favor architectures that adapt quickly with self-attention or wider bottlenecks; closely matched chemistries can rely more on convolutional baselines.\nsource_train: class counts 0:23, 1:22, 2:41, 3:37, 4:42 (example label 0).\nsource_train sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1878000497817993, 0.29330000281333923, 0.49129998683929443, 0.4677000045776367, 0.4731999933719635, 0.23250000178813934, 0.20350000262260437, 0.2328999936580658, 0.0702999979257583\u2026\nsource_train flattened row glimpses: [[-1.6202, -1.1878, -1.1461, -1.1625, -1.1386, -1.4633, -0.8297, -3.2104, -3.18, -0.14], [-1.6202, -1.1878, -1.1461, -1.1625, -1.1386, -1.4633, -0.8297, -3.2104, -3.18, -0.14], [-1.6202, -1.1878, -1.1461, -1.1625, -1.1386, -1.4633, -0.8297, -3.2104, -3.18, -0.14]]\ntarget_train: class counts 0:19, 1:18, 2:2, 3:1, 4:1 (example label 2).\ntarget_train sample window (first 3 ch \u00d7 12 steps): [[-1.7590999603271484, -1.7496000528335571, -1.2950999736785889, 0.0, -0.6873999834060669, 0.0, -0.13369999825954437, 0.0, 0.29809999465942383, 0.40389999747276306, 0.7049000263214111, 0.8859000205993652], [-0.8561999797821045, 0.2721000015735626, 0.1282999962568283, 0.0, -0.1234000027179718, 0.0, -0.4253000020980835, 0.0, -0.30059999227523804, -0.11559999734163284, -0.3513000011444092, -0.2500999867916107], [-1.3759\u2026\ntarget_train flattened row glimpses: [[-1.6202, -1.1878, -1.1461, -1.1625, -1.1386, -1.4633, -0.8297, -3.2104, -3.18, -0.14], [-1.6202, -1.1878, -1.1461, -1.1625, -1.1386, -1.4633, -0.8309, -3.2104, -3.18, -0.14], [-1.6202, -1.1878, -1.1461, -1.1625, -1.1386, -1.4633, -0.8309, -3.2104, -3.18, -0.14]]\nsource_val: class counts 0:8, 1:10, 2:16, 3:14, 4:16 (example label 3).\nsource_val sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1878000497817993, -1.1878000497817993, -1.1878000497817993, -1.1878000497817993, -1.1878000497817993, -1.1878000497817993, -1.1878000497817993, -1.1878000497817993, -1.187800049781\u2026\nsource_val flattened row glimpses: [[-1.6202, -1.1878, -1.1461, -1.1625, -1.1386, -1.4633, -0.8297, -3.2104, -3.18, -0.14], [-1.6202, -1.1878, -1.1461, -1.1625, -1.1386, -1.4633, -0.8297, -3.2104, -3.18, -0.14], [-1.6202, -1.1878, -1.1461, -1.1625, -1.1386, -1.4633, -0.8297, -3.2104, -3.18, -0.14]]\ntarget_val: class counts 0:5, 1:5, 2:1, 4:1 (example label 0).\ntarget_val sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1878000497817993, -0.04089999943971634, -0.0625, -0.11590000241994858, -0.15080000460147858, -0.17059999704360962, -0.19689999520778656, -0.21809999644756317, -0.2273000031709671, \u2026\ntarget_val flattened row glimpses: [[-1.6202, -1.1878, -1.1461, -1.1625, -1.1386, -1.4633, -0.8309, -3.2104, -3.18, -0.14], [-1.6202, -1.1878, -1.1461, -1.1625, -1.1386, -1.4633, -0.8309, -3.2104, -3.18, -0.14], [-1.6202, -1.1878, -1.1461, -1.1625, -1.1386, -1.4633, -0.8309, -3.2104, -3.18, -0.14]]",
    "ablation": []
  },
  {
    "dataset": "Battery_inconsistent",
    "source_cathodes": [
      "HE5050",
      "NMC111",
      "NMC532",
      "NMC622",
      "NMC811"
    ],
    "target_cathodes": [
      "FCG"
    ],
    "llm_cfg": {
      "architecture": "cnn_1d",
      "model_name": "cnn_features_1d",
      "self_attention": false,
      "sngp": true,
      "openmax": false,
      "use_unknown_head": false,
      "bottleneck": 256,
      "dropout": 0.35,
      "learning_rate": 0.0005,
      "batch_size": 8,
      "lambda_src": 1.5,
      "warmup_epochs": 10,
      "rationale": "The dataset has 21 channels and a short sequence length (32), with label inconsistency and domain shift between cathode chemistries. WideResNet_edited is tuned for battery data and handles domain gaps well. Using SNGP and an unknown head helps manage uncertainty and out-of-distribution risks from chemistry mismatch. A moderate bottleneck (256) balances capacity and regularization, dropout at 0.35 prevents overfitting, and a learning rate of 0.0005 aligns with dataset hints. Batch size 32 fits memory and training stability, and warmup epochs help stabilize transfer learning. Target cathode: FCG (graphite focused). Source cathodes: HE5050 (high-energy experimental blend), NMC111 (low-Ni NMC (stable, slower fade)), NMC532 (mid-Ni NMC (balanced energy vs. stability)), NMC622 (higher-Ni NMC (stronger energy, more fragile)), NMC811 (high-Ni NMC (highest energy, OOD vs low-Ni)). Source/target chemistries differ \u2192 expect domain shift. Evaluated 21 channels \u00d7 32-step windows and matched them with cnn_1d capacity. Target fine-tune spans \u22485 cycles versus 165 source cycles, guiding lr=5.00e-04 and dropout=0.35.",
      "_provider": "openai",
      "_raw": "{\n  \"model_name\": \"WideResNet_edited\",\n  \"self_attention\": false,\n  \"sngp\": true,\n  \"openmax\": false,\n  \"use_unknown_head\": true,\n  \"bottleneck\": 256,\n  \"dropout\": 0.35,\n  \"learning_rate\": 0.0005,\n  \"batch_size\": 32,\n  \"lambda_src\": 1.0,\n  \"warmup_epochs\": 10,\n  \"rationale\": \"The dataset has 21 channels and a short sequence length (32), with label inconsistency and domain shift between cathode chemistries. WideResNet_edited is tuned for battery data and handles domain gaps well. Using SNGP and an unknown head helps manage uncertainty and out-of-distribution risks from chemistry mismatch. A moderate bottleneck (256) balances capacity and regularization, dropout at 0.35 prevents overfitting, and a learning rate of 0.0005 aligns with dataset hints. Batch size 32 fits memory and training stability, and warmup epochs help stabilize transfer learning.\"\n}"
    },
    "numeric_summary": {
      "dataset": "Battery_inconsistent",
      "sequence_length_requested": 32,
      "notes": "label_inconsistent",
      "lr_hint": 0.0005,
      "dropout_hint": 0.35,
      "num_classes_hint": null,
      "splits": {
        "source_train": {
          "batch_shape": [
            32,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 2,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -1.1497000455856323,
                -1.069200038909912,
                -1.06850004196167,
                -1.0688999891281128,
                -1.069200038909912,
                -1.0693000555038452,
                -1.0693999528884888,
                -1.0700000524520874,
                -1.0699000358581543,
                -1.0707000494003296,
                -1.0716999769210815,
                -1.0720000267028809
              ],
              [
                -1.1467000246047974,
                -1.065999984741211,
                -1.0650999546051025,
                -1.065500020980835,
                -1.0658999681472778,
                -1.065999984741211,
                -1.0662000179290771,
                -1.0667999982833862,
                -1.0667999982833862,
                -1.0676000118255615,
                -1.0687999725341797,
                -1.069000005722046
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            -0.03959999978542328,
            -0.04749999940395355,
            -0.06019999831914902,
            -0.04349999874830246,
            0.31150001287460327,
            -0.27959999442100525,
            0.002300000051036477
          ],
          "batch_channel_std": [
            1.059499979019165,
            0.571399986743927,
            0.5670999884605408,
            0.5446000099182129,
            0.5651000142097473,
            0.9983999729156494,
            0.7039999961853027,
            0.7347000241279602
          ],
          "class_distribution": {
            "0": 23,
            "1": 22,
            "2": 41,
            "3": 37,
            "4": 42
          },
          "feature_range": [
            -9.340057149377733,
            24.48976442541202
          ],
          "feature_global_mean": 0.03334999911755919,
          "flattened_rows_head": [
            [
              -1.6202,
              -1.1497,
              -1.1467,
              -1.1167,
              -1.1408,
              -1.4623,
              -0.8017,
              -3.217,
              -3.1854,
              -0.1393
            ],
            [
              -1.6202,
              -1.1497,
              -1.1467,
              -1.1167,
              -1.1408,
              -1.4623,
              -0.8017,
              -3.217,
              -3.1854,
              -0.1393
            ],
            [
              -1.6202,
              -1.1497,
              -1.1467,
              -1.1167,
              -1.1408,
              -1.4623,
              -0.8017,
              -3.217,
              -3.1854,
              -0.1393
            ]
          ]
        },
        "target_train": {
          "batch_shape": [
            32,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 3,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.1812000274658203,
                0.6226000189781189,
                0.76419997215271,
                0.6739000082015991,
                0.5033000111579895,
                0.6583999991416931,
                0.7738000154495239,
                0.5705999732017517,
                0.5372999906539917,
                0.6003000140190125,
                0.4481000006198883,
                0.6021000146865845
              ],
              [
                -1.1704000234603882,
                0.8004999756813049,
                1.0563000440597534,
                0.7498999834060669,
                0.5728999972343445,
                0.7458000183105469,
                0.9312000274658203,
                0.6460999846458435,
                0.7479000091552734,
                0.6114000082015991,
                0.5293999910354614,
                0.5958999991416931
              ],
              [
                -1.21589994430542,
                0.6287999749183655,
                0.8202000260353088,
                0.6837000250816345,
                0.41609999537467957,
                0.5907999873161316,
                0.7229999899864197,
                0.5824000239372253,
                0.7289000153541565,
                0.5625,
                0.5306000113487244,
                0.5719000101089478
              ]
            ]
          },
          "batch_channel_mean": [
            0.6520000100135803,
            0.5450000166893005,
            0.48500001430511475,
            0.5221999883651733,
            0.4316999912261963,
            0.49000000953674316,
            0.0892999991774559,
            0.17839999496936798
          ],
          "batch_channel_std": [
            0.8503000140190125,
            0.5555999875068665,
            0.6100999712944031,
            0.5429999828338623,
            0.6194000244140625,
            0.7124999761581421,
            0.7207000255584717,
            0.7523999810218811
          ],
          "class_distribution": {
            "3": 5
          },
          "feature_range": [
            -3.217041018868009,
            3.557174404293754
          ],
          "feature_global_mean": 0.2029450803873774,
          "flattened_rows_head": [
            [
              -1.6202,
              -1.1497,
              -1.1467,
              -1.1167,
              -1.1408,
              -1.4623,
              -0.8017,
              -3.217,
              -3.1854,
              -0.1393
            ],
            [
              -1.6202,
              -1.1497,
              -1.1467,
              -1.1167,
              -1.1408,
              -1.4623,
              -0.8017,
              -3.217,
              -3.1854,
              -0.1393
            ],
            [
              -1.6202,
              -1.1497,
              -1.1467,
              -1.1167,
              -1.1408,
              -1.4623,
              -0.8017,
              -3.217,
              -3.1854,
              -0.1393
            ]
          ]
        },
        "source_val": {
          "batch_shape": [
            32,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 3,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -1.1497000455856323,
                -1.1497000455856323,
                -1.1497000455856323,
                -1.1497000455856323,
                -1.1497000455856323,
                -1.1497000455856323,
                -1.1497000455856323,
                -1.1497000455856323,
                -1.1497000455856323,
                -1.1497000455856323,
                -1.1497000455856323,
                -1.1497000455856323
              ],
              [
                -1.1467000246047974,
                -1.1467000246047974,
                -1.1467000246047974,
                -1.1467000246047974,
                -1.1467000246047974,
                -1.1467000246047974,
                -1.1467000246047974,
                -1.1467000246047974,
                -1.1467000246047974,
                -1.1467000246047974,
                -1.1467000246047974,
                -1.1467000246047974
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            0.22120000422000885,
            0.21780000627040863,
            0.20819999277591705,
            0.22139999270439148,
            0.5842000246047974,
            -0.25760000944137573,
            -0.12439999729394913
          ],
          "batch_channel_std": [
            1.059499979019165,
            0.9200000166893005,
            0.9273999929428101,
            0.9363999962806702,
            0.9348000288009644,
            0.9352999925613403,
            0.7980999946594238,
            0.8086000084877014
          ],
          "class_distribution": {
            "0": 8,
            "1": 10,
            "2": 16,
            "3": 14,
            "4": 16
          },
          "feature_range": [
            -8.146578193100947,
            31.445766758688194
          ],
          "feature_global_mean": 0.02218752736282119,
          "flattened_rows_head": [
            [
              -1.6202,
              -1.1497,
              -1.1467,
              -1.1167,
              -1.1408,
              -1.4623,
              -0.8017,
              -3.217,
              -3.1854,
              -0.1393
            ],
            [
              -1.6202,
              -1.1497,
              -1.1467,
              -1.1167,
              -1.1408,
              -1.4623,
              -0.8017,
              -3.217,
              -3.1854,
              -0.1393
            ],
            [
              -1.6202,
              -1.1497,
              -1.1467,
              -1.1167,
              -1.1408,
              -1.4623,
              -0.8017,
              -3.217,
              -3.1854,
              -0.1393
            ]
          ]
        },
        "target_val": {
          "batch_shape": [
            3,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 3,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -1.1497000455856323,
                0.6460999846458435,
                0.6833000183105469,
                0.6733999848365784,
                0.6600000262260437,
                0.656000018119812,
                0.6380000114440918,
                0.6252999901771545,
                0.6244999766349792,
                0.6079000234603882,
                0.5766000151634216,
                0.5720000267028809
              ],
              [
                -1.1467000246047974,
                0.6575000286102295,
                0.7050999999046326,
                0.6924999952316284,
                0.6775000095367432,
                0.6729000210762024,
                0.6516000032424927,
                0.6365000009536743,
                0.6363000273704529,
                0.6157000064849854,
                0.5791000127792358,
                0.5751000046730042
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            0.5012999773025513,
            0.503600001335144,
            0.5620999932289124,
            0.5212000012397766,
            0.8549000024795532,
            -0.19470000267028809,
            0.21549999713897705
          ],
          "batch_channel_std": [
            1.059499979019165,
            0.3012000024318695,
            0.30250000953674316,
            0.31189998984336853,
            0.30480000376701355,
            0.7975999712944031,
            0.7246999740600586,
            0.6290000081062317
          ],
          "class_distribution": {
            "3": 3
          },
          "feature_range": [
            -3.217041018868009,
            3.5438761846653035
          ],
          "feature_global_mean": 0.20443169799369906,
          "flattened_rows_head": [
            [
              -1.6202,
              -1.1497,
              -1.1467,
              -1.1167,
              -1.1408,
              -1.4623,
              -0.8017,
              -3.217,
              -3.1854,
              -0.1393
            ],
            [
              -1.6202,
              -1.1497,
              -1.1467,
              -1.1167,
              -1.1408,
              -1.4623,
              -0.8017,
              -3.217,
              -3.1854,
              -0.1393
            ],
            [
              -1.6202,
              -1.1497,
              -1.1467,
              -1.1167,
              -1.1408,
              -1.4623,
              -0.8017,
              -3.217,
              -3.1854,
              -0.1393
            ]
          ]
        }
      },
      "dataset_variant": "argonne_battery",
      "feature_names": [
        "cycle_number",
        "energy_charge",
        "capacity_charge",
        "energy_discharge",
        "capacity_discharge",
        "cycle_start",
        "cycle_duration"
      ],
      "source_cathodes": [
        "HE5050",
        "NMC111",
        "NMC532",
        "NMC622",
        "NMC811"
      ],
      "target_cathodes": [
        "FCG"
      ],
      "label_column": "eol_class",
      "split_used": "source_train",
      "batch_size_seen": 32,
      "channels": 21,
      "seq_len": 32
    },
    "text_context": "Dataset: Argonne National Laboratory battery aging time-series with partial cycle windows.\nSource cathodes: HE5050, NMC111, NMC532, NMC622, NMC811; target cathodes: FCG.\nLabel column 'eol_class' with ~None classes; sequence length 32; 21 channels covering cycle_number, energy_charge, capacity_charge, energy_discharge, capacity_discharge, cycle_start, cycle_duration.\nLiterature cues (Joule S2542-4351(22)00409-3, chemistry-sensitive ablations):\nJoule 2022 (S2542-4351(22)00409-3) key cues for chemistry-aware ablation:\n- Early-cycle capacity fade slopes and coulombic-efficiency stabilization highlight whether aging is lithium-inventory loss (graphite/anode-electrolyte limited) versus cathode structural decay (e.g., Ni-rich NMC cathodes with electrolyte oxidation risk).\n- High initial impedance growth, thick SEI signatures, or electrolyte oxidation markers flag chemistries that benefit from uncertainty-aware heads (SNGP/OpenMax) to avoid overconfident extrapolation on outlier cycles.\n- LFP/graphite pairs tend to show flatter voltage plateaus and slower early fade; Ni-rich NMC chemistries degrade faster under aggressive cycling and need stronger regularization or shorter cycle horizons in ablations.\n- Transfer between mismatched chemistries (e.g., NMC \u2192 LFP) should down-weight source loss and favor architectures that adapt quickly with self-attention or wider bottlenecks; closely matched chemistries can rely more on convolutional baselines.\nsource_train: class counts 0:23, 1:22, 2:41, 3:37, 4:42 (example label 2).\nsource_train sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1497000455856323, -1.069200038909912, -1.06850004196167, -1.0688999891281128, -1.069200038909912, -1.0693000555038452, -1.0693999528884888, -1.0700000524520874, -1.0699000358581543\u2026\nsource_train flattened row glimpses: [[-1.6202, -1.1497, -1.1467, -1.1167, -1.1408, -1.4623, -0.8017, -3.217, -3.1854, -0.1393], [-1.6202, -1.1497, -1.1467, -1.1167, -1.1408, -1.4623, -0.8017, -3.217, -3.1854, -0.1393], [-1.6202, -1.1497, -1.1467, -1.1167, -1.1408, -1.4623, -0.8017, -3.217, -3.1854, -0.1393]]\ntarget_train: class counts 3:5 (example label 3).\ntarget_train sample window (first 3 ch \u00d7 12 steps): [[-1.1812000274658203, 0.6226000189781189, 0.76419997215271, 0.6739000082015991, 0.5033000111579895, 0.6583999991416931, 0.7738000154495239, 0.5705999732017517, 0.5372999906539917, 0.6003000140190125, 0.4481000006198883, 0.6021000146865845], [-1.1704000234603882, 0.8004999756813049, 1.0563000440597534, 0.7498999834060669, 0.5728999972343445, 0.7458000183105469, 0.9312000274658203, 0.6460999846458435, 0.74790000915527\u2026\ntarget_train flattened row glimpses: [[-1.6202, -1.1497, -1.1467, -1.1167, -1.1408, -1.4623, -0.8017, -3.217, -3.1854, -0.1393], [-1.6202, -1.1497, -1.1467, -1.1167, -1.1408, -1.4623, -0.8017, -3.217, -3.1854, -0.1393], [-1.6202, -1.1497, -1.1467, -1.1167, -1.1408, -1.4623, -0.8017, -3.217, -3.1854, -0.1393]]\nsource_val: class counts 0:8, 1:10, 2:16, 3:14, 4:16 (example label 3).\nsource_val sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1497000455856323, -1.1497000455856323, -1.1497000455856323, -1.1497000455856323, -1.1497000455856323, -1.1497000455856323, -1.1497000455856323, -1.1497000455856323, -1.149700045585\u2026\nsource_val flattened row glimpses: [[-1.6202, -1.1497, -1.1467, -1.1167, -1.1408, -1.4623, -0.8017, -3.217, -3.1854, -0.1393], [-1.6202, -1.1497, -1.1467, -1.1167, -1.1408, -1.4623, -0.8017, -3.217, -3.1854, -0.1393], [-1.6202, -1.1497, -1.1467, -1.1167, -1.1408, -1.4623, -0.8017, -3.217, -3.1854, -0.1393]]\ntarget_val: class counts 3:3 (example label 3).\ntarget_val sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1497000455856323, 0.6460999846458435, 0.6833000183105469, 0.6733999848365784, 0.6600000262260437, 0.656000018119812, 0.6380000114440918, 0.6252999901771545, 0.6244999766349792, 0.6\u2026\ntarget_val flattened row glimpses: [[-1.6202, -1.1497, -1.1467, -1.1167, -1.1408, -1.4623, -0.8017, -3.217, -3.1854, -0.1393], [-1.6202, -1.1497, -1.1467, -1.1167, -1.1408, -1.4623, -0.8017, -3.217, -3.1854, -0.1393], [-1.6202, -1.1497, -1.1467, -1.1167, -1.1408, -1.4623, -0.8017, -3.217, -3.1854, -0.1393]]",
    "ablation": []
  },
  {
    "dataset": "Battery_inconsistent",
    "source_cathodes": [
      "Li1.2Ni0.3Mn0.6O2",
      "Li1.35Ni0.33Mn0.67O2.35"
    ],
    "target_cathodes": [
      "5Vspinel"
    ],
    "llm_cfg": {
      "architecture": "cnn_1d",
      "model_name": "cnn_features_1d",
      "self_attention": false,
      "sngp": true,
      "openmax": false,
      "use_unknown_head": false,
      "bottleneck": 256,
      "dropout": 0.35,
      "learning_rate": 0.0005,
      "batch_size": 8,
      "lambda_src": 0.6,
      "warmup_epochs": 10,
      "rationale": "The dataset has 21 channels and short sequences (32 steps) with domain shift between source and target chemistries, favoring a high-capacity model with transfer adaptation. WideResNet_edited is tuned for battery data and handles domain gaps well. SNGP and use_unknown_head add uncertainty awareness to mitigate overconfident extrapolation on outlier cycles due to chemistry mismatch. Dropout at 0.35 balances overfitting risk given label inconsistency, and batch size 8 matches observed data. Warmup epochs and moderate lambda_src support stable transfer learning. Target cathode: 5Vspinel (high-voltage spinel (manganese rich)). Source cathodes: Li1.2Ni0.3Mn0.6O2, Li1.35Ni0.33Mn0.67O2.35. Source/target chemistries differ \u2192 expect domain shift. Evaluated 21 channels \u00d7 32-step windows and matched them with cnn_1d capacity. Target fine-tune spans \u224841 cycles versus 8 source cycles, guiding lr=5.00e-04 and dropout=0.35.",
      "_provider": "openai",
      "_raw": "{\n  \"model_name\": \"WideResNet_edited\",\n  \"self_attention\": false,\n  \"sngp\": true,\n  \"openmax\": false,\n  \"use_unknown_head\": true,\n  \"bottleneck\": 256,\n  \"dropout\": 0.35,\n  \"learning_rate\": 0.0005,\n  \"batch_size\": 8,\n  \"lambda_src\": 1.0,\n  \"warmup_epochs\": 10,\n  \"rationale\": \"The dataset has 21 channels and short sequences (32 steps) with domain shift between source and target chemistries, favoring a high-capacity model with transfer adaptation. WideResNet_edited is tuned for battery data and handles domain gaps well. SNGP and use_unknown_head add uncertainty awareness to mitigate overconfident extrapolation on outlier cycles due to chemistry mismatch. Dropout at 0.35 balances overfitting risk given label inconsistency, and batch size 8 matches observed data. Warmup epochs and moderate lambda_src support stable transfer learning.\"\n}"
    },
    "numeric_summary": {
      "dataset": "Battery_inconsistent",
      "sequence_length_requested": 32,
      "notes": "label_inconsistent",
      "lr_hint": 0.0005,
      "dropout_hint": 0.35,
      "num_classes_hint": null,
      "splits": {
        "source_train": {
          "batch_shape": [
            8,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 0,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -2.5485999584198,
                1.8157999515533447,
                2.098900079727173,
                2.071899890899658,
                2.1366000175476074,
                1.937000036239624,
                1.7940000295639038,
                2.146199941635132,
                1.013100028038025,
                0.6575999855995178,
                -2.5485999584198,
                1.615399956703186
              ],
              [
                -2.3153998851776123,
                2.138200044631958,
                2.5343000888824463,
                2.51419997215271,
                2.5234999656677246,
                2.301800012588501,
                2.1270999908447266,
                2.3406999111175537,
                1.1469000577926636,
                0.7870000004768372,
                -2.3153998851776123,
                1.8602999448776245
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            0.8467000126838684,
            1.1711000204086304,
            0.39980000257492065,
            0.9800000190734863,
            -0.7667999863624573,
            -0.22689999639987946,
            -0.5727999806404114
          ],
          "batch_channel_std": [
            1.059499979019165,
            1.1875,
            1.2611000537872314,
            1.4859000444412231,
            1.61489999294281,
            0.2676999866962433,
            0.9251000285148621,
            1.0648000240325928
          ],
          "class_distribution": {
            "0": 8
          },
          "feature_range": [
            -3.432067627140479,
            20.29255512940135
          ],
          "feature_global_mean": 0.32511764565584705,
          "flattened_rows_head": [
            [
              -1.6202,
              -2.5486,
              -2.3154,
              -2.6171,
              -2.3523,
              -1.4445,
              -0.9278,
              -2.7927,
              -2.7563,
              -0.1669
            ],
            [
              -1.6202,
              -2.5486,
              -2.3154,
              -2.6171,
              -2.3523,
              -1.4445,
              -0.9278,
              -2.7927,
              -2.7563,
              -0.1669
            ],
            [
              -1.6202,
              -2.5486,
              -2.3154,
              -2.6171,
              -2.3523,
              -1.4445,
              -0.9278,
              -2.7927,
              -2.7563,
              -0.1669
            ]
          ]
        },
        "target_train": {
          "batch_shape": [
            8,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 2,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -2.3357999324798584,
                0.08229999989271164,
                -1.2043999433517456,
                -3.007200002670288,
                -0.804099977016449,
                -0.47119998931884766,
                -0.06120000034570694,
                0.05609999969601631,
                0.2508000135421753,
                0.4797999858856201,
                0.00279999990016222,
                0.04820000007748604
              ],
              [
                -2.2785000801086426,
                -0.051500000059604645,
                -0.03319999948143959,
                -2.8132998943328857,
                -0.050599999725818634,
                -0.3149000108242035,
                -0.1687999963760376,
                -0.19210000336170197,
                0.04699999839067459,
                0.01269999984651804,
                -0.13189999759197235,
                -0.1428000032901764
              ],
              [
                -2.236799955368042,
                0.2696000039577484,
                -0.010099999606609344,
                -2.52810001373291,
                -0.09860000014305115,
                -0.30550000071525574,
                0.02410000003874302,
                0.15000000596046448,
                -0.18559999763965607,
                -0.17299999296665192,
                0.07680000364780426,
                0.1882999986410141
              ]
            ]
          },
          "batch_channel_mean": [
            0.5909000039100647,
            -0.038100000470876694,
            -0.16189999878406525,
            -0.03500000014901161,
            -0.4336000084877014,
            -0.17659999430179596,
            -0.3098999857902527,
            0.03790000081062317
          ],
          "batch_channel_std": [
            1.1368000507354736,
            0.8503999710083008,
            0.8884000182151794,
            0.847100019454956,
            0.5453000068664551,
            0.7129999995231628,
            0.7519000172615051,
            0.9624000191688538
          ],
          "class_distribution": {
            "0": 19,
            "1": 18,
            "2": 2,
            "3": 1,
            "4": 1
          },
          "feature_range": [
            -2.7926971979313016,
            5.075003596678456
          ],
          "feature_global_mean": -0.008008378447412336,
          "flattened_rows_head": [
            [
              -1.6202,
              -2.5486,
              -2.3154,
              -2.6171,
              -2.3523,
              -1.4445,
              -0.9278,
              -2.7927,
              -2.7563,
              -0.1669
            ],
            [
              -1.6202,
              -2.5486,
              -2.3154,
              -2.6171,
              -2.3523,
              -1.4445,
              -0.9289,
              -2.7927,
              -2.7563,
              -0.1669
            ],
            [
              -1.6202,
              -2.5486,
              -2.3154,
              -2.6171,
              -2.3523,
              -1.4445,
              -0.9289,
              -2.7927,
              -2.7563,
              -0.1669
            ]
          ]
        },
        "source_val": {
          "batch_shape": [
            2,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 0,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -2.5485999584198,
                2.015199899673462,
                1.8950999975204468,
                1.842900037765503,
                2.0136001110076904,
                1.726099967956543,
                1.6953999996185303,
                3.03439998626709,
                1.4289000034332275,
                1.4917999505996704,
                2.3143999576568604,
                0.486299991607666
              ],
              [
                -2.3153998851776123,
                2.438699960708618,
                2.3315999507904053,
                2.2799999713897705,
                2.328000068664551,
                2.0404000282287598,
                1.9979000091552734,
                3.086899995803833,
                1.6007000207901,
                1.6305999755859375,
                2.295099973678589,
                0.5482000112533569
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            1.027899980545044,
            1.3753999471664429,
            0.7906000018119812,
            1.3944000005722046,
            -0.7581999897956848,
            0.11789999902248383,
            -0.25429999828338623
          ],
          "batch_channel_std": [
            1.059499979019165,
            1.0750999450683594,
            1.1239999532699585,
            1.0830999612808228,
            1.1535999774932861,
            0.26489999890327454,
            1.1318000555038452,
            0.7797999978065491
          ],
          "class_distribution": {
            "0": 2
          },
          "feature_range": [
            -3.3686442182639165,
            20.03274975093728
          ],
          "feature_global_mean": 0.45589823830616993,
          "flattened_rows_head": [
            [
              -1.6202,
              -2.5486,
              -2.3154,
              -2.6171,
              -2.3523,
              -1.4445,
              -0.9278,
              -2.7927,
              -2.7563,
              -0.1669
            ],
            [
              -1.6202,
              -2.5486,
              -2.3154,
              -2.6171,
              -2.3523,
              -1.4445,
              -0.9278,
              -2.7927,
              -2.7563,
              -0.1669
            ]
          ]
        },
        "target_val": {
          "batch_shape": [
            8,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 0,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -2.5485999584198,
                0.271699994802475,
                0.21860000491142273,
                0.08739999681711197,
                0.00139999995008111,
                -0.0471000000834465,
                -0.11190000176429749,
                -0.164000004529953,
                -0.1867000013589859,
                -0.21240000426769257,
                -0.25060001015663147,
                -0.2872999906539917
              ],
              [
                -2.3153998851776123,
                0.16500000655651093,
                0.12409999966621399,
                0.0044999998062849045,
                -0.07479999959468842,
                -0.11919999867677689,
                -0.1809999942779541,
                -0.22949999570846558,
                -0.25099998712539673,
                -0.28049999475479126,
                -0.3192000091075897,
                -0.3540000021457672
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            -0.16519999504089355,
            -0.23569999635219574,
            -0.09189999848604202,
            -0.18160000443458557,
            0.8001999855041504,
            -0.23420000076293945,
            0.03779999911785126
          ],
          "batch_channel_std": [
            1.059499979019165,
            0.527999997138977,
            0.4684000015258789,
            0.6075000166893005,
            0.498199999332428,
            0.8069000244140625,
            0.8075000047683716,
            0.6208000183105469
          ],
          "class_distribution": {
            "0": 5,
            "1": 5,
            "2": 1,
            "4": 1
          },
          "feature_range": [
            -2.7926971979313016,
            5.090831033573637
          ],
          "feature_global_mean": -0.004082282100038045,
          "flattened_rows_head": [
            [
              -1.6202,
              -2.5486,
              -2.3154,
              -2.6171,
              -2.3523,
              -1.4445,
              -0.9289,
              -2.7927,
              -2.7563,
              -0.1669
            ],
            [
              -1.6202,
              -2.5486,
              -2.3154,
              -2.6171,
              -2.3523,
              -1.4445,
              -0.9289,
              -2.7927,
              -2.7563,
              -0.1669
            ],
            [
              -1.6202,
              -2.5486,
              -2.3154,
              -2.6171,
              -2.3523,
              -1.4445,
              -0.9289,
              -2.7927,
              -2.7563,
              -0.1669
            ]
          ]
        }
      },
      "dataset_variant": "argonne_battery",
      "feature_names": [
        "cycle_number",
        "energy_charge",
        "capacity_charge",
        "energy_discharge",
        "capacity_discharge",
        "cycle_start",
        "cycle_duration"
      ],
      "source_cathodes": [
        "Li1.2Ni0.3Mn0.6O2",
        "Li1.35Ni0.33Mn0.67O2.35"
      ],
      "target_cathodes": [
        "5Vspinel"
      ],
      "label_column": "eol_class",
      "split_used": "source_train",
      "batch_size_seen": 8,
      "channels": 21,
      "seq_len": 32
    },
    "text_context": "Dataset: Argonne National Laboratory battery aging time-series with partial cycle windows.\nSource cathodes: Li1.2Ni0.3Mn0.6O2, Li1.35Ni0.33Mn0.67O2.35; target cathodes: 5Vspinel.\nLabel column 'eol_class' with ~None classes; sequence length 32; 21 channels covering cycle_number, energy_charge, capacity_charge, energy_discharge, capacity_discharge, cycle_start, cycle_duration.\nLiterature cues (Joule S2542-4351(22)00409-3, chemistry-sensitive ablations):\nJoule 2022 (S2542-4351(22)00409-3) key cues for chemistry-aware ablation:\n- Early-cycle capacity fade slopes and coulombic-efficiency stabilization highlight whether aging is lithium-inventory loss (graphite/anode-electrolyte limited) versus cathode structural decay (e.g., Ni-rich NMC cathodes with electrolyte oxidation risk).\n- High initial impedance growth, thick SEI signatures, or electrolyte oxidation markers flag chemistries that benefit from uncertainty-aware heads (SNGP/OpenMax) to avoid overconfident extrapolation on outlier cycles.\n- LFP/graphite pairs tend to show flatter voltage plateaus and slower early fade; Ni-rich NMC chemistries degrade faster under aggressive cycling and need stronger regularization or shorter cycle horizons in ablations.\n- Transfer between mismatched chemistries (e.g., NMC \u2192 LFP) should down-weight source loss and favor architectures that adapt quickly with self-attention or wider bottlenecks; closely matched chemistries can rely more on convolutional baselines.\nsource_train: class counts 0:8 (example label 0).\nsource_train sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.5485999584198, 1.8157999515533447, 2.098900079727173, 2.071899890899658, 2.1366000175476074, 1.937000036239624, 1.7940000295639038, 2.146199941635132, 1.013100028038025, 0.65759998\u2026\nsource_train flattened row glimpses: [[-1.6202, -2.5486, -2.3154, -2.6171, -2.3523, -1.4445, -0.9278, -2.7927, -2.7563, -0.1669], [-1.6202, -2.5486, -2.3154, -2.6171, -2.3523, -1.4445, -0.9278, -2.7927, -2.7563, -0.1669], [-1.6202, -2.5486, -2.3154, -2.6171, -2.3523, -1.4445, -0.9278, -2.7927, -2.7563, -0.1669]]\ntarget_train: class counts 0:19, 1:18, 2:2, 3:1, 4:1 (example label 2).\ntarget_train sample window (first 3 ch \u00d7 12 steps): [[-2.3357999324798584, 0.08229999989271164, -1.2043999433517456, -3.007200002670288, -0.804099977016449, -0.47119998931884766, -0.06120000034570694, 0.05609999969601631, 0.2508000135421753, 0.4797999858856201, 0.00279999990016222, 0.04820000007748604], [-2.2785000801086426, -0.051500000059604645, -0.03319999948143959, -2.8132998943328857, -0.050599999725818634, -0.3149000108242035, -0.1687999963760376, -0.19210000336\u2026\ntarget_train flattened row glimpses: [[-1.6202, -2.5486, -2.3154, -2.6171, -2.3523, -1.4445, -0.9278, -2.7927, -2.7563, -0.1669], [-1.6202, -2.5486, -2.3154, -2.6171, -2.3523, -1.4445, -0.9289, -2.7927, -2.7563, -0.1669], [-1.6202, -2.5486, -2.3154, -2.6171, -2.3523, -1.4445, -0.9289, -2.7927, -2.7563, -0.1669]]\nsource_val: class counts 0:2 (example label 0).\nsource_val sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.5485999584198, 2.015199899673462, 1.8950999975204468, 1.842900037765503, 2.0136001110076904, 1.726099967956543, 1.6953999996185303, 3.03439998626709, 1.4289000034332275, 1.49179995\u2026\nsource_val flattened row glimpses: [[-1.6202, -2.5486, -2.3154, -2.6171, -2.3523, -1.4445, -0.9278, -2.7927, -2.7563, -0.1669], [-1.6202, -2.5486, -2.3154, -2.6171, -2.3523, -1.4445, -0.9278, -2.7927, -2.7563, -0.1669]]\ntarget_val: class counts 0:5, 1:5, 2:1, 4:1 (example label 0).\ntarget_val sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.5485999584198, 0.271699994802475, 0.21860000491142273, 0.08739999681711197, 0.00139999995008111, -0.0471000000834465, -0.11190000176429749, -0.164000004529953, -0.1867000013589859,\u2026\ntarget_val flattened row glimpses: [[-1.6202, -2.5486, -2.3154, -2.6171, -2.3523, -1.4445, -0.9289, -2.7927, -2.7563, -0.1669], [-1.6202, -2.5486, -2.3154, -2.6171, -2.3523, -1.4445, -0.9289, -2.7927, -2.7563, -0.1669], [-1.6202, -2.5486, -2.3154, -2.6171, -2.3523, -1.4445, -0.9289, -2.7927, -2.7563, -0.1669]]",
    "ablation": []
  },
  {
    "dataset": "Battery_inconsistent",
    "source_cathodes": [
      "5Vspinel"
    ],
    "target_cathodes": [
      "HE5050",
      "NMC111",
      "NMC532",
      "NMC622",
      "NMC811"
    ],
    "llm_cfg": {
      "architecture": "cnn_1d",
      "model_name": "cnn_features_1d",
      "self_attention": false,
      "sngp": true,
      "openmax": false,
      "use_unknown_head": false,
      "bottleneck": 256,
      "dropout": 0.35,
      "learning_rate": 0.0005,
      "batch_size": 8,
      "lambda_src": 0.6,
      "warmup_epochs": 10,
      "rationale": "The dataset has 21 channels and short sequences (32 steps) with label inconsistency and domain shift between source and target chemistries. WideResNet_edited is tailored for battery data with domain gaps and benefits from physics-inspired feature edits. Using SNGP and an unknown head helps manage uncertainty and outlier cycles due to chemistry mismatch. Dropout at 0.35 balances regularization for small source data, and a moderate bottleneck of 256 supports capacity without overfitting. Batch size 8 matches seen data, and warmup epochs help stabilize transfer learning. Target cathode: HE5050 (high-energy experimental blend). Source cathodes: 5Vspinel (high-voltage spinel (manganese rich)). Source/target chemistries differ \u2192 expect domain shift. Evaluated 21 channels \u00d7 32-step windows and matched them with cnn_1d capacity. Target fine-tune spans \u2248155 cycles versus 41 source cycles, guiding lr=5.00e-04 and dropout=0.35.",
      "_provider": "openai",
      "_raw": "{\n  \"model_name\": \"WideResNet_edited\",\n  \"self_attention\": false,\n  \"sngp\": true,\n  \"openmax\": false,\n  \"use_unknown_head\": true,\n  \"bottleneck\": 256,\n  \"dropout\": 0.35,\n  \"learning_rate\": 0.0005,\n  \"batch_size\": 8,\n  \"lambda_src\": 1.0,\n  \"warmup_epochs\": 10,\n  \"rationale\": \"The dataset has 21 channels and short sequences (32 steps) with label inconsistency and domain shift between source and target chemistries. WideResNet_edited is tailored for battery data with domain gaps and benefits from physics-inspired feature edits. Using SNGP and an unknown head helps manage uncertainty and outlier cycles due to chemistry mismatch. Dropout at 0.35 balances regularization for small source data, and a moderate bottleneck of 256 supports capacity without overfitting. Batch size 8 matches seen data, and warmup epochs help stabilize transfer learning.\"\n}"
    },
    "numeric_summary": {
      "dataset": "Battery_inconsistent",
      "sequence_length_requested": 32,
      "notes": "label_inconsistent",
      "lr_hint": 0.0005,
      "dropout_hint": 0.35,
      "num_classes_hint": null,
      "splits": {
        "source_train": {
          "batch_shape": [
            8,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 1,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -1.1741000413894653,
                -0.016899999231100082,
                0.0012000000569969416,
                -0.030400000512599945,
                -0.03880000114440918,
                -0.04360000044107437,
                -0.05829999968409538,
                -0.0729999989271164,
                -0.07419999688863754,
                -0.07940000295639038,
                -0.10239999741315842,
                -0.11169999837875366
              ],
              [
                -1.13100004196167,
                -0.17839999496936798,
                -0.15639999508857727,
                -0.18359999358654022,
                -0.19140000641345978,
                -0.195700004696846,
                -0.20919999480247498,
                -0.22220000624656677,
                -0.22349999845027924,
                -0.22930000722408295,
                -0.2498999983072281,
                -0.25760000944137573
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            -0.19619999825954437,
            -0.3012000024318695,
            -0.15970000624656677,
            -0.301800012588501,
            0.9627000093460083,
            -0.1062999963760376,
            0.14169999957084656
          ],
          "batch_channel_std": [
            1.059499979019165,
            0.24040000140666962,
            0.17249999940395355,
            0.25209999084472656,
            0.17270000278949738,
            1.1347999572753906,
            0.824999988079071,
            0.6575999855995178
          ],
          "class_distribution": {
            "0": 19,
            "1": 18,
            "2": 2,
            "3": 1,
            "4": 1
          },
          "feature_range": [
            -3.203935665790699,
            5.1401425697203385
          ],
          "feature_global_mean": -0.016921664518018544,
          "flattened_rows_head": [
            [
              -1.6202,
              -1.1741,
              -1.131,
              -1.1495,
              -1.1239,
              -1.459,
              -0.8317,
              -3.2039,
              -3.1735,
              -0.1408
            ],
            [
              -1.6202,
              -1.1741,
              -1.131,
              -1.1495,
              -1.1239,
              -1.459,
              -0.8328,
              -3.2039,
              -3.1735,
              -0.1408
            ],
            [
              -1.6202,
              -1.1741,
              -1.131,
              -1.1495,
              -1.1239,
              -1.459,
              -0.8328,
              -3.2039,
              -3.1735,
              -0.1408
            ]
          ]
        },
        "target_train": {
          "batch_shape": [
            8,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 1,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -1.1741000413894653,
                0.3743000030517578,
                0.37630000710487366,
                0.3709999918937683,
                0.3490999937057495,
                0.34459999203681946,
                0.34619998931884766,
                0.32109999656677246,
                0.31790000200271606,
                0.29190000891685486,
                0.24529999494552612,
                0.24169999361038208
              ],
              [
                -1.13100004196167,
                0.4562999904155731,
                0.46230000257492065,
                0.45500001311302185,
                0.4316999912261963,
                0.4268999993801117,
                0.42480000853538513,
                0.397599995136261,
                0.39410001039505005,
                0.36640000343322754,
                0.31610000133514404,
                0.3122999966144562
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            -0.04560000076889992,
            -0.01269999984651804,
            -0.06199999898672104,
            -0.009600000455975533,
            0.1704999953508377,
            -0.36579999327659607,
            -0.0020000000949949026
          ],
          "batch_channel_std": [
            1.059499979019165,
            0.5946999788284302,
            0.5917999744415283,
            0.5709999799728394,
            0.5871999859809875,
            0.9681000113487244,
            0.6819999814033508,
            0.7301999926567078
          ],
          "class_distribution": {
            "0": 22,
            "1": 22,
            "2": 38,
            "3": 34,
            "4": 39
          },
          "feature_range": [
            -9.981793547102113,
            31.866555053073082
          ],
          "feature_global_mean": 0.043367023845691036,
          "flattened_rows_head": [
            [
              -1.6202,
              -1.1741,
              -1.131,
              -1.1495,
              -1.1239,
              -1.459,
              -0.8317,
              -3.2039,
              -3.1735,
              -0.1408
            ],
            [
              -1.6202,
              -1.1741,
              -1.131,
              -1.1495,
              -1.1239,
              -1.459,
              -0.8317,
              -3.2039,
              -3.1735,
              -0.1408
            ],
            [
              -1.6202,
              -1.1741,
              -1.131,
              -1.1495,
              -1.1239,
              -1.459,
              -0.8317,
              -3.2039,
              -3.1735,
              -0.1408
            ]
          ]
        },
        "source_val": {
          "batch_shape": [
            8,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 0,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -1.1741000413894653,
                -0.04390000179409981,
                -0.06509999930858612,
                -0.11779999732971191,
                -0.15219999849796295,
                -0.17170000076293945,
                -0.19760000705718994,
                -0.21850000321865082,
                -0.22759999334812164,
                -0.2379000037908554,
                -0.2531999945640564,
                -0.2678999900817871
              ],
              [
                -1.13100004196167,
                -0.19740000367164612,
                -0.21279999613761902,
                -0.25780001282691956,
                -0.28760001063346863,
                -0.3043000102043152,
                -0.32760000228881836,
                -0.3458000123500824,
                -0.3540000021457672,
                -0.3650999963283539,
                -0.37959998846054077,
                -0.3926999866962433
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            -0.21899999678134918,
            -0.3481999933719635,
            -0.1915999948978424,
            -0.34689998626708984,
            1.118899941444397,
            -0.11599999666213989,
            0.016499999910593033
          ],
          "batch_channel_std": [
            1.059499979019165,
            0.21160000562667847,
            0.17630000412464142,
            0.2303999960422516,
            0.17829999327659607,
            0.9266999959945679,
            0.8331000208854675,
            0.7063000202178955
          ],
          "class_distribution": {
            "0": 5,
            "1": 5,
            "2": 1,
            "4": 1
          },
          "feature_range": [
            -3.203935665790699,
            5.1560300164083985
          ],
          "feature_global_mean": -0.010901597356338598,
          "flattened_rows_head": [
            [
              -1.6202,
              -1.1741,
              -1.131,
              -1.1495,
              -1.1239,
              -1.459,
              -0.8328,
              -3.2039,
              -3.1735,
              -0.1408
            ],
            [
              -1.6202,
              -1.1741,
              -1.131,
              -1.1495,
              -1.1239,
              -1.459,
              -0.8328,
              -3.2039,
              -3.1735,
              -0.1408
            ],
            [
              -1.6202,
              -1.1741,
              -1.131,
              -1.1495,
              -1.1239,
              -1.459,
              -0.8328,
              -3.2039,
              -3.1735,
              -0.1408
            ]
          ]
        },
        "target_val": {
          "batch_shape": [
            8,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 3,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -1.1741000413894653,
                -1.1741000413894653,
                -1.1741000413894653,
                -1.1741000413894653,
                -1.1741000413894653,
                -1.1741000413894653,
                -1.1741000413894653,
                -1.1741000413894653,
                -1.1741000413894653,
                -1.1741000413894653,
                -1.1741000413894653,
                -1.1741000413894653
              ],
              [
                -1.13100004196167,
                -1.13100004196167,
                -1.13100004196167,
                -1.13100004196167,
                -1.13100004196167,
                -1.13100004196167,
                -1.13100004196167,
                -1.13100004196167,
                -1.13100004196167,
                -1.13100004196167,
                -1.13100004196167,
                -1.13100004196167
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            0.27559998631477356,
            0.2630000114440918,
            0.1655000001192093,
            0.2653000056743622,
            0.005200000014156103,
            -0.3278999924659729,
            -0.6205999851226807
          ],
          "batch_channel_std": [
            1.059499979019165,
            0.4851999878883362,
            0.47620001435279846,
            0.46309998631477356,
            0.47749999165534973,
            0.9384999871253967,
            0.8022000193595886,
            0.9699000120162964
          ],
          "class_distribution": {
            "0": 9,
            "1": 10,
            "2": 19,
            "3": 17,
            "4": 19
          },
          "feature_range": [
            -3.426709644883315,
            32.206823553376644
          ],
          "feature_global_mean": 0.014365731412246173,
          "flattened_rows_head": [
            [
              -1.6202,
              -1.1741,
              -1.131,
              -1.1495,
              -1.1239,
              -1.459,
              -0.8317,
              -3.2039,
              -3.1735,
              -0.1408
            ],
            [
              -1.6202,
              -1.1741,
              -1.131,
              -1.1495,
              -1.1239,
              -1.459,
              -0.8317,
              -3.2039,
              -3.1735,
              -0.1408
            ],
            [
              -1.6202,
              -1.1741,
              -1.131,
              -1.1495,
              -1.1239,
              -1.459,
              -0.8317,
              -3.2039,
              -3.1735,
              -0.1408
            ]
          ]
        }
      },
      "dataset_variant": "argonne_battery",
      "feature_names": [
        "cycle_number",
        "energy_charge",
        "capacity_charge",
        "energy_discharge",
        "capacity_discharge",
        "cycle_start",
        "cycle_duration"
      ],
      "source_cathodes": [
        "5Vspinel"
      ],
      "target_cathodes": [
        "HE5050",
        "NMC111",
        "NMC532",
        "NMC622",
        "NMC811"
      ],
      "label_column": "eol_class",
      "split_used": "source_train",
      "batch_size_seen": 8,
      "channels": 21,
      "seq_len": 32
    },
    "text_context": "Dataset: Argonne National Laboratory battery aging time-series with partial cycle windows.\nSource cathodes: 5Vspinel; target cathodes: HE5050, NMC111, NMC532, NMC622, NMC811.\nLabel column 'eol_class' with ~None classes; sequence length 32; 21 channels covering cycle_number, energy_charge, capacity_charge, energy_discharge, capacity_discharge, cycle_start, cycle_duration.\nLiterature cues (Joule S2542-4351(22)00409-3, chemistry-sensitive ablations):\nJoule 2022 (S2542-4351(22)00409-3) key cues for chemistry-aware ablation:\n- Early-cycle capacity fade slopes and coulombic-efficiency stabilization highlight whether aging is lithium-inventory loss (graphite/anode-electrolyte limited) versus cathode structural decay (e.g., Ni-rich NMC cathodes with electrolyte oxidation risk).\n- High initial impedance growth, thick SEI signatures, or electrolyte oxidation markers flag chemistries that benefit from uncertainty-aware heads (SNGP/OpenMax) to avoid overconfident extrapolation on outlier cycles.\n- LFP/graphite pairs tend to show flatter voltage plateaus and slower early fade; Ni-rich NMC chemistries degrade faster under aggressive cycling and need stronger regularization or shorter cycle horizons in ablations.\n- Transfer between mismatched chemistries (e.g., NMC \u2192 LFP) should down-weight source loss and favor architectures that adapt quickly with self-attention or wider bottlenecks; closely matched chemistries can rely more on convolutional baselines.\nsource_train: class counts 0:19, 1:18, 2:2, 3:1, 4:1 (example label 1).\nsource_train sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -0.016899999231100082, 0.0012000000569969416, -0.030400000512599945, -0.03880000114440918, -0.04360000044107437, -0.05829999968409538, -0.0729999989271164, -0.074\u2026\nsource_train flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408]]\ntarget_train: class counts 0:22, 1:22, 2:38, 3:34, 4:39 (example label 1).\ntarget_train sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, 0.3743000030517578, 0.37630000710487366, 0.3709999918937683, 0.3490999937057495, 0.34459999203681946, 0.34619998931884766, 0.32109999656677246, 0.3179000020027160\u2026\ntarget_train flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408]]\nsource_val: class counts 0:5, 1:5, 2:1, 4:1 (example label 0).\nsource_val sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -0.04390000179409981, -0.06509999930858612, -0.11779999732971191, -0.15219999849796295, -0.17170000076293945, -0.19760000705718994, -0.21850000321865082, -0.22759\u2026\nsource_val flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408]]\ntarget_val: class counts 0:9, 1:10, 2:19, 3:17, 4:19 (example label 3).\ntarget_val sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.174100041389\u2026\ntarget_val flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408]]",
    "ablation": []
  },
  {
    "dataset": "Battery_inconsistent",
    "source_cathodes": [
      "5Vspinel"
    ],
    "target_cathodes": [
      "Li1.2Ni0.3Mn0.6O2",
      "Li1.35Ni0.33Mn0.67O2.35"
    ],
    "llm_cfg": {
      "architecture": "cnn_1d",
      "model_name": "cnn_features_1d",
      "self_attention": false,
      "sngp": true,
      "openmax": false,
      "use_unknown_head": false,
      "bottleneck": 256,
      "dropout": 0.35,
      "learning_rate": 0.0005,
      "batch_size": 8,
      "lambda_src": 1.5,
      "warmup_epochs": 10,
      "rationale": "The dataset has 21 channels and short sequence length (32), with significant domain shift between source and target chemistries. WideResNet_edited is tailored for Argonne battery data with physics-inspired feature edits, making it well suited for transfer learning across chemistries. The bottleneck of 256 balances capacity and regularization, while dropout at 0.35 mitigates overfitting given label inconsistency. Self-attention is avoided to reduce overfitting risk on a small source domain, and openmax/SNGP are not prioritized since the label inconsistency is moderate and unknown rejection is less critical than transfer adaptation. Target cathode: Li1.2Ni0.3Mn0.6O2. Source cathodes: 5Vspinel (high-voltage spinel (manganese rich)). Source/target chemistries differ \u2192 expect domain shift. Evaluated 21 channels \u00d7 32-step windows and matched them with cnn_1d capacity. Target fine-tune spans \u22486 cycles versus 41 source cycles, guiding lr=5.00e-04 and dropout=0.35.",
      "_provider": "openai",
      "_raw": "{\n  \"model_name\": \"WideResNet_edited\",\n  \"self_attention\": false,\n  \"sngp\": false,\n  \"openmax\": false,\n  \"use_unknown_head\": false,\n  \"bottleneck\": 256,\n  \"dropout\": 0.35,\n  \"learning_rate\": 0.0005,\n  \"batch_size\": 8,\n  \"lambda_src\": 1.0,\n  \"warmup_epochs\": 10,\n  \"rationale\": \"The dataset has 21 channels and short sequence length (32), with significant domain shift between source and target chemistries. WideResNet_edited is tailored for Argonne battery data with physics-inspired feature edits, making it well suited for transfer learning across chemistries. The bottleneck of 256 balances capacity and regularization, while dropout at 0.35 mitigates overfitting given label inconsistency. Self-attention is avoided to reduce overfitting risk on a small source domain, and openmax/SNGP are not prioritized since the label inconsistency is moderate and unknown rejection is less critical than transfer adaptation.\"\n}"
    },
    "numeric_summary": {
      "dataset": "Battery_inconsistent",
      "sequence_length_requested": 32,
      "notes": "label_inconsistent",
      "lr_hint": 0.0005,
      "dropout_hint": 0.35,
      "num_classes_hint": null,
      "splits": {
        "source_train": {
          "batch_shape": [
            8,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 2,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -2.6510000228881836,
                0.14630000293254852,
                0.07519999891519547,
                -2.6510000228881836,
                0.012799999676644802,
                -0.2791000008583069,
                -0.01119999960064888,
                -0.011500000022351742,
                0.0012000000569969416,
                0.0003000000142492354,
                -0.008899999782443047,
                -0.018300000578165054
              ],
              [
                -2.4202001094818115,
                0.0414000004529953,
                -0.011800000444054604,
                -2.420099973678589,
                -0.094200000166893,
                -0.3474000096321106,
                -0.09600000083446503,
                -0.09610000252723694,
                -0.0843999981880188,
                -0.0851999968290329,
                -0.09309999644756317,
                -0.10279999673366547
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            -0.10819999873638153,
            -0.17669999599456787,
            -0.01860000006854534,
            -0.12030000239610672,
            0.5947999954223633,
            -0.29600000381469727,
            0.32420000433921814
          ],
          "batch_channel_std": [
            1.059499979019165,
            0.5400000214576721,
            0.4787999987602234,
            0.5626999735832214,
            0.483599990606308,
            0.9283000230789185,
            0.7759000062942505,
            0.7864000201225281
          ],
          "class_distribution": {
            "0": 19,
            "1": 18,
            "2": 2,
            "3": 1,
            "4": 1
          },
          "feature_range": [
            -2.9057923445856524,
            5.202832943374929
          ],
          "feature_global_mean": -0.008143604364574682,
          "flattened_rows_head": [
            [
              -1.6202,
              -2.651,
              -2.4202,
              -2.7228,
              -2.4601,
              -1.489,
              -0.9406,
              -2.9058,
              -2.8748,
              -0.1784
            ],
            [
              -1.6202,
              -2.651,
              -2.4202,
              -2.7228,
              -2.4601,
              -1.489,
              -0.9417,
              -2.9058,
              -2.8748,
              -0.1784
            ],
            [
              -1.6202,
              -2.651,
              -2.4202,
              -2.7228,
              -2.4601,
              -1.489,
              -0.9417,
              -2.9058,
              -2.8748,
              -0.1784
            ]
          ]
        },
        "target_train": {
          "batch_shape": [
            8,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 0,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.896399974822998,
                -2.010499954223633,
                -1.5264999866485596,
                0.0,
                -0.8173999786376953,
                0.0,
                -0.06809999793767929,
                0.0,
                0.2856000065803528,
                0.34790000319480896,
                0.5138000249862671,
                0.696399986743927
              ],
              [
                -2.2899999618530273,
                3.247299909591675,
                3.219599962234497,
                0.0,
                2.822499990463257,
                0.0,
                1.9033000469207764,
                0.0,
                1.7319999933242798,
                1.4701999425888062,
                1.604599952697754,
                -0.8252999782562256
              ],
              [
                -2.7012999057769775,
                1.7355999946594238,
                1.8173999786376953,
                0.0,
                2.0676000118255615,
                0.0,
                1.989300012588501,
                0.0,
                1.4453999996185303,
                0.8960999846458435,
                0.3228999972343445,
                -1.125100016593933
              ]
            ]
          },
          "batch_channel_mean": [
            0.707099974155426,
            0.8895000219345093,
            1.1301000118255615,
            0.8313000202178955,
            1.0865999460220337,
            -0.09960000216960907,
            -0.017400000244379044,
            -0.5198000073432922
          ],
          "batch_channel_std": [
            1.030500054359436,
            1.198199987411499,
            1.2407000064849854,
            1.3655999898910522,
            1.382200002670288,
            1.2339999675750732,
            1.2590999603271484,
            0.8029000163078308
          ],
          "class_distribution": {
            "0": 6
          },
          "feature_range": [
            -3.6390493997246667,
            19.875169049014566
          ],
          "feature_global_mean": 0.4374359295879304,
          "flattened_rows_head": [
            [
              -1.6202,
              -2.651,
              -2.4202,
              -2.7228,
              -2.4601,
              -1.489,
              -0.9406,
              -2.9058,
              -2.8748,
              -0.1784
            ],
            [
              -1.6202,
              -2.651,
              -2.4202,
              -2.7228,
              -2.4601,
              -1.489,
              -0.9406,
              -2.9058,
              -2.8748,
              -0.1784
            ],
            [
              -1.6202,
              -2.651,
              -2.4202,
              -2.7228,
              -2.4601,
              -1.489,
              -0.9406,
              -2.9058,
              -2.8748,
              -0.1784
            ]
          ]
        },
        "source_val": {
          "batch_shape": [
            8,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 0,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -2.6510000228881836,
                0.3109000027179718,
                0.25519999861717224,
                0.11729999631643295,
                0.027000000700354576,
                -0.023900000378489494,
                -0.09200000017881393,
                -0.14669999480247498,
                -0.17059999704360962,
                -0.19750000536441803,
                -0.23759999871253967,
                -0.2761000096797943
              ],
              [
                -2.4202001094818115,
                0.210999995470047,
                0.16750000417232513,
                0.040699999779462814,
                -0.04349999874830246,
                -0.09049999713897705,
                -0.15610000491142273,
                -0.20749999582767487,
                -0.2303999960422516,
                -0.26170000433921814,
                -0.3025999963283539,
                -0.33959999680519104
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            -0.14800000190734863,
            -0.21410000324249268,
            -0.1005999967455864,
            -0.1704999953508377,
            0.7595000267028809,
            -0.25529998540878296,
            0.00139999995008111
          ],
          "batch_channel_std": [
            1.059499979019165,
            0.5544999837875366,
            0.4968999922275543,
            0.6308000087738037,
            0.5254999995231628,
            0.8083000183105469,
            0.7978000044822693,
            0.6376000046730042
          ],
          "class_distribution": {
            "0": 5,
            "1": 5,
            "2": 1,
            "4": 1
          },
          "feature_range": [
            -2.9057923445856524,
            5.219029621397489
          ],
          "feature_global_mean": -0.004320963409587972,
          "flattened_rows_head": [
            [
              -1.6202,
              -2.651,
              -2.4202,
              -2.7228,
              -2.4601,
              -1.489,
              -0.9417,
              -2.9058,
              -2.8748,
              -0.1784
            ],
            [
              -1.6202,
              -2.651,
              -2.4202,
              -2.7228,
              -2.4601,
              -1.489,
              -0.9417,
              -2.9058,
              -2.8748,
              -0.1784
            ],
            [
              -1.6202,
              -2.651,
              -2.4202,
              -2.7228,
              -2.4601,
              -1.489,
              -0.9417,
              -2.9058,
              -2.8748,
              -0.1784
            ]
          ]
        },
        "target_val": {
          "batch_shape": [
            4,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 0,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -2.6510000228881836,
                2.1417999267578125,
                2.015700101852417,
                1.9608999490737915,
                2.140199899673462,
                1.8382999897003174,
                1.805999994277954,
                3.2121999263763428,
                1.5262000560760498,
                1.5922000408172607,
                2.4560999870300293,
                0.5361999869346619
              ],
              [
                -2.4202001094818115,
                2.6226999759674072,
                2.5090999603271484,
                2.4544999599456787,
                2.5053000450134277,
                2.200200080871582,
                2.1552000045776367,
                3.31030011177063,
                1.7338000535964966,
                1.7655999660491943,
                2.470400094985962,
                0.6173999905586243
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            0.8479999899864197,
            1.1744999885559082,
            0.14030000567436218,
            0.7558000087738037,
            -0.8087999820709229,
            -0.2743000090122223,
            -0.7925999760627747
          ],
          "batch_channel_std": [
            1.059499979019165,
            1.2324999570846558,
            1.3095999956130981,
            1.6520999670028687,
            1.822100043296814,
            0.26759999990463257,
            0.8853999972343445,
            1.1957999467849731
          ],
          "class_distribution": {
            "0": 4
          },
          "feature_range": [
            -3.571829448600409,
            19.622460716154905
          ],
          "feature_global_mean": 0.28418790425941914,
          "flattened_rows_head": [
            [
              -1.6202,
              -2.651,
              -2.4202,
              -2.7228,
              -2.4601,
              -1.489,
              -0.9406,
              -2.9058,
              -2.8748,
              -0.1784
            ],
            [
              -1.6202,
              -2.651,
              -2.4202,
              -2.7228,
              -2.4601,
              -1.489,
              -0.9406,
              -2.9058,
              -2.8748,
              -0.1784
            ],
            [
              -1.6202,
              -2.651,
              -2.4202,
              -2.7228,
              -2.4601,
              -1.489,
              -0.9406,
              -2.9058,
              -2.8748,
              -0.1784
            ]
          ]
        }
      },
      "dataset_variant": "argonne_battery",
      "feature_names": [
        "cycle_number",
        "energy_charge",
        "capacity_charge",
        "energy_discharge",
        "capacity_discharge",
        "cycle_start",
        "cycle_duration"
      ],
      "source_cathodes": [
        "5Vspinel"
      ],
      "target_cathodes": [
        "Li1.2Ni0.3Mn0.6O2",
        "Li1.35Ni0.33Mn0.67O2.35"
      ],
      "label_column": "eol_class",
      "split_used": "source_train",
      "batch_size_seen": 8,
      "channels": 21,
      "seq_len": 32
    },
    "text_context": "Dataset: Argonne National Laboratory battery aging time-series with partial cycle windows.\nSource cathodes: 5Vspinel; target cathodes: Li1.2Ni0.3Mn0.6O2, Li1.35Ni0.33Mn0.67O2.35.\nLabel column 'eol_class' with ~None classes; sequence length 32; 21 channels covering cycle_number, energy_charge, capacity_charge, energy_discharge, capacity_discharge, cycle_start, cycle_duration.\nLiterature cues (Joule S2542-4351(22)00409-3, chemistry-sensitive ablations):\nJoule 2022 (S2542-4351(22)00409-3) key cues for chemistry-aware ablation:\n- Early-cycle capacity fade slopes and coulombic-efficiency stabilization highlight whether aging is lithium-inventory loss (graphite/anode-electrolyte limited) versus cathode structural decay (e.g., Ni-rich NMC cathodes with electrolyte oxidation risk).\n- High initial impedance growth, thick SEI signatures, or electrolyte oxidation markers flag chemistries that benefit from uncertainty-aware heads (SNGP/OpenMax) to avoid overconfident extrapolation on outlier cycles.\n- LFP/graphite pairs tend to show flatter voltage plateaus and slower early fade; Ni-rich NMC chemistries degrade faster under aggressive cycling and need stronger regularization or shorter cycle horizons in ablations.\n- Transfer between mismatched chemistries (e.g., NMC \u2192 LFP) should down-weight source loss and favor architectures that adapt quickly with self-attention or wider bottlenecks; closely matched chemistries can rely more on convolutional baselines.\nsource_train: class counts 0:19, 1:18, 2:2, 3:1, 4:1 (example label 2).\nsource_train sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.14630000293254852, 0.07519999891519547, -2.6510000228881836, 0.012799999676644802, -0.2791000008583069, -0.01119999960064888, -0.011500000022351742, 0.001200000\u2026\nsource_train flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]\ntarget_train: class counts 0:6 (example label 0).\ntarget_train sample window (first 3 ch \u00d7 12 steps): [[-1.896399974822998, -2.010499954223633, -1.5264999866485596, 0.0, -0.8173999786376953, 0.0, -0.06809999793767929, 0.0, 0.2856000065803528, 0.34790000319480896, 0.5138000249862671, 0.696399986743927], [-2.2899999618530273, 3.247299909591675, 3.219599962234497, 0.0, 2.822499990463257, 0.0, 1.9033000469207764, 0.0, 1.7319999933242798, 1.4701999425888062, 1.604599952697754, -0.8252999782562256], [-2.7012999057769775, 1\u2026\ntarget_train flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]\nsource_val: class counts 0:5, 1:5, 2:1, 4:1 (example label 0).\nsource_val sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.3109000027179718, 0.25519999861717224, 0.11729999631643295, 0.027000000700354576, -0.023900000378489494, -0.09200000017881393, -0.14669999480247498, -0.17059999\u2026\nsource_val flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]\ntarget_val: class counts 0:4 (example label 0).\ntarget_val sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 2.1417999267578125, 2.015700101852417, 1.9608999490737915, 2.140199899673462, 1.8382999897003174, 1.805999994277954, 3.2121999263763428, 1.5262000560760498, 1.592\u2026\ntarget_val flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]",
    "ablation": []
  },
  {
    "dataset": "Battery_inconsistent",
    "source_cathodes": [
      "FCG"
    ],
    "target_cathodes": [
      "HE5050",
      "NMC111",
      "NMC532",
      "NMC622",
      "NMC811"
    ],
    "llm_cfg": {
      "architecture": "cnn_1d_sa",
      "model_name": "cnn_features_1d_sa",
      "self_attention": true,
      "sngp": true,
      "openmax": false,
      "use_unknown_head": false,
      "bottleneck": 256,
      "dropout": 0.35,
      "learning_rate": 0.0005,
      "batch_size": 8,
      "lambda_src": 0.6,
      "warmup_epochs": 10,
      "rationale": "The dataset has 21 channels and short sequences (32 steps) with label inconsistency and domain shift between source and target cathodes. WideResNet with self-attention balances strong representation for multi-channel inputs and captures global context needed for chemistry-aware aging patterns. Using SNGP and an unknown head addresses uncertainty and outlier detection due to domain shift and label inconsistency. Dropout at 0.35 prevents overfitting on small source data, and moderate bottleneck size (256) balances capacity and regularization. Batch size 8 fits memory constraints while enabling stable training. Warmup epochs and lambda_src help gradual adaptation to target domain. Target cathode: HE5050 (high-energy experimental blend). Source cathodes: FCG (graphite focused). Source/target chemistries differ \u2192 expect domain shift. Evaluated 21 channels \u00d7 32-step windows and matched them with cnn_1d_sa capacity. Target fine-tune spans \u2248155 cycles versus 6 source cycles, guiding lr=5.00e-04 and dropout=0.35.",
      "_provider": "openai",
      "_raw": "{\n  \"model_name\": \"WideResNet_sa\",\n  \"self_attention\": true,\n  \"sngp\": true,\n  \"openmax\": false,\n  \"use_unknown_head\": true,\n  \"bottleneck\": 256,\n  \"dropout\": 0.35,\n  \"learning_rate\": 0.0005,\n  \"batch_size\": 8,\n  \"lambda_src\": 1.5,\n  \"warmup_epochs\": 10,\n  \"rationale\": \"The dataset has 21 channels and short sequences (32 steps) with label inconsistency and domain shift between source and target cathodes. WideResNet with self-attention balances strong representation for multi-channel inputs and captures global context needed for chemistry-aware aging patterns. Using SNGP and an unknown head addresses uncertainty and outlier detection due to domain shift and label inconsistency. Dropout at 0.35 prevents overfitting on small source data, and moderate bottleneck size (256) balances capacity and regularization. Batch size 8 fits memory constraints while enabling stable training. Warmup epochs and lambda_src help gradual adaptation to target domain.\"\n}"
    },
    "numeric_summary": {
      "dataset": "Battery_inconsistent",
      "sequence_length_requested": 32,
      "notes": "label_inconsistent",
      "lr_hint": 0.0005,
      "dropout_hint": 0.35,
      "num_classes_hint": null,
      "splits": {
        "source_train": {
          "batch_shape": [
            6,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 3,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -1.1403000354766846,
                0.6254000067710876,
                0.6679999828338623,
                0.6567999720573425,
                0.6449999809265137,
                0.6392999887466431,
                0.6205999851226807,
                0.6075000166893005,
                0.6062999963760376,
                0.589900016784668,
                0.5564000010490417,
                0.5540000200271606
              ],
              [
                -1.1371999979019165,
                0.6347000002861023,
                0.6883999705314636,
                0.6744999885559082,
                0.6610000133514404,
                0.6547999978065491,
                0.6324999928474426,
                0.6172999739646912,
                0.6164000034332275,
                0.595300018787384,
                0.5572999715805054,
                0.5551000237464905
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            0.48170000314712524,
            0.48350000381469727,
            0.5385000109672546,
            0.5008000135421753,
            0.8583999872207642,
            -0.19740000367164612,
            0.20200000703334808
          ],
          "batch_channel_std": [
            1.059499979019165,
            0.2962000072002411,
            0.29739999771118164,
            0.3061000108718872,
            0.2996000051498413,
            0.7976999878883362,
            0.7239000201225281,
            0.6255999803543091
          ],
          "class_distribution": {
            "3": 6
          },
          "feature_range": [
            -3.2106635401609402,
            3.5002185783545934
          ],
          "feature_global_mean": 0.19591510889964595,
          "flattened_rows_head": [
            [
              -1.6202,
              -1.1403,
              -1.1372,
              -1.1082,
              -1.132,
              -1.4587,
              -0.8036,
              -3.2107,
              -3.179,
              -0.1409
            ],
            [
              -1.6202,
              -1.1403,
              -1.1372,
              -1.1082,
              -1.132,
              -1.4587,
              -0.8036,
              -3.2107,
              -3.179,
              -0.1409
            ],
            [
              -1.6202,
              -1.1403,
              -1.1372,
              -1.1082,
              -1.132,
              -1.4587,
              -0.8036,
              -3.2107,
              -3.179,
              -0.1409
            ]
          ]
        },
        "target_train": {
          "batch_shape": [
            8,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 1,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -1.1403000354766846,
                -0.27320000529289246,
                -0.2777000069618225,
                -0.2948000133037567,
                -0.3199999928474426,
                -0.3249000012874603,
                -0.3255999982357025,
                -0.3427000045776367,
                -0.35010001063346863,
                -0.33809998631477356,
                -0.36039999127388,
                -0.3621000051498413
              ],
              [
                -1.1371999979019165,
                -0.24789999425411224,
                -0.24869999289512634,
                -0.2685999870300293,
                -0.2953999936580658,
                -0.3005000054836273,
                -0.3046000003814697,
                -0.3230000138282776,
                -0.3301999866962433,
                -0.323199987411499,
                -0.34610000252723694,
                -0.3479999899864197
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            0.22910000383853912,
            0.22540000081062317,
            0.23350000381469727,
            0.23589999973773956,
            0.2689000070095062,
            -0.2867000102996826,
            -0.015699999406933784
          ],
          "batch_channel_std": [
            1.059499979019165,
            1.6269999742507935,
            1.6416000127792358,
            1.6531000137329102,
            1.6542999744415283,
            1.1289000511169434,
            0.7103000283241272,
            0.619700014591217
          ],
          "class_distribution": {
            "0": 22,
            "1": 22,
            "2": 38,
            "3": 34,
            "4": 39
          },
          "feature_range": [
            -9.20385614937911,
            28.87870113204206
          ],
          "feature_global_mean": 0.026973963171381392,
          "flattened_rows_head": [
            [
              -1.6202,
              -1.1403,
              -1.1372,
              -1.1082,
              -1.132,
              -1.4587,
              -0.8036,
              -3.2107,
              -3.179,
              -0.1409
            ],
            [
              -1.6202,
              -1.1403,
              -1.1372,
              -1.1082,
              -1.132,
              -1.4587,
              -0.8036,
              -3.2107,
              -3.179,
              -0.1409
            ],
            [
              -1.6202,
              -1.1403,
              -1.1372,
              -1.1082,
              -1.132,
              -1.4587,
              -0.8036,
              -3.2107,
              -3.179,
              -0.1409
            ]
          ]
        },
        "source_val": {
          "batch_shape": [
            2,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 3,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -1.1403000354766846,
                0.6047000288963318,
                0.6389999985694885,
                0.6284000277519226,
                0.6177999973297119,
                0.6114000082015991,
                0.5934000015258789,
                0.5813999772071838,
                0.5791000127792358,
                0.5594000220298767,
                0.5275999903678894,
                0.5281000137329102
              ],
              [
                -1.1371999979019165,
                0.6155999898910522,
                0.6596999764442444,
                0.6460999846458435,
                0.6338000297546387,
                0.6272000074386597,
                0.6050000190734863,
                0.590399980545044,
                0.5888000130653381,
                0.5641999840736389,
                0.5278000235557556,
                0.5281000137329102
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            0.4747999906539917,
            0.4763000011444092,
            0.5282999873161316,
            0.49230000376701355,
            0.847100019454956,
            -0.2003999948501587,
            0.2013999968767166
          ],
          "batch_channel_std": [
            1.059499979019165,
            0.2944999933242798,
            0.2957000136375427,
            0.3041999936103821,
            0.2978000044822693,
            0.7935000061988831,
            0.7203999757766724,
            0.6255000233650208
          ],
          "class_distribution": {
            "3": 2
          },
          "feature_range": [
            -3.2106635401609402,
            3.44913117424402
          ],
          "feature_global_mean": 0.1921846091904075,
          "flattened_rows_head": [
            [
              -1.6202,
              -1.1403,
              -1.1372,
              -1.1082,
              -1.132,
              -1.4587,
              -0.8036,
              -3.2107,
              -3.179,
              -0.1409
            ],
            [
              -1.6202,
              -1.1403,
              -1.1372,
              -1.1082,
              -1.132,
              -1.4587,
              -0.8036,
              -3.2107,
              -3.179,
              -0.1409
            ]
          ]
        },
        "target_val": {
          "batch_shape": [
            8,
            21,
            32
          ],
          "channels": 21,
          "seq_len": 32,
          "example_label": 3,
          "preview": {
            "channels": 3,
            "timesteps": 12,
            "values": [
              [
                -1.6202000379562378,
                -1.388700008392334,
                -1.1572999954223633,
                -0.9258000254631042,
                -0.6944000124931335,
                -0.4629000127315521,
                -0.23149999976158142,
                0.0,
                0.23149999976158142,
                0.4629000127315521,
                0.6944000124931335,
                0.9258000254631042
              ],
              [
                -1.1403000354766846,
                -1.1403000354766846,
                -1.1403000354766846,
                -1.1403000354766846,
                -1.1403000354766846,
                -1.1403000354766846,
                -1.1403000354766846,
                -1.1403000354766846,
                -1.1403000354766846,
                -1.1403000354766846,
                -1.1403000354766846,
                -1.1403000354766846
              ],
              [
                -1.1371999979019165,
                -1.1371999979019165,
                -1.1371999979019165,
                -1.1371999979019165,
                -1.1371999979019165,
                -1.1371999979019165,
                -1.1371999979019165,
                -1.1371999979019165,
                -1.1371999979019165,
                -1.1371999979019165,
                -1.1371999979019165,
                -1.1371999979019165
              ]
            ]
          },
          "batch_channel_mean": [
            0.8607000112533569,
            0.18389999866485596,
            0.14309999346733093,
            0.08900000154972076,
            0.14380000531673431,
            0.11050000041723251,
            -0.2827000021934509,
            -0.5985999703407288
          ],
          "batch_channel_std": [
            1.059499979019165,
            0.4431999921798706,
            0.4374000132083893,
            0.42160001397132874,
            0.438400000333786,
            1.0058000087738037,
            0.8294000029563904,
            0.9807000160217285
          ],
          "class_distribution": {
            "0": 9,
            "1": 10,
            "2": 19,
            "3": 17,
            "4": 19
          },
          "feature_range": [
            -3.484281475443279,
            29.189441485357083
          ],
          "feature_global_mean": -0.0008096915043016523,
          "flattened_rows_head": [
            [
              -1.6202,
              -1.1403,
              -1.1372,
              -1.1082,
              -1.132,
              -1.4587,
              -0.8036,
              -3.2107,
              -3.179,
              -0.1409
            ],
            [
              -1.6202,
              -1.1403,
              -1.1372,
              -1.1082,
              -1.132,
              -1.4587,
              -0.8036,
              -3.2107,
              -3.179,
              -0.1409
            ],
            [
              -1.6202,
              -1.1403,
              -1.1372,
              -1.1082,
              -1.132,
              -1.4587,
              -0.8036,
              -3.2107,
              -3.179,
              -0.1409
            ]
          ]
        }
      },
      "dataset_variant": "argonne_battery",
      "feature_names": [
        "cycle_number",
        "energy_charge",
        "capacity_charge",
        "energy_discharge",
        "capacity_discharge",
        "cycle_start",
        "cycle_duration"
      ],
      "source_cathodes": [
        "FCG"
      ],
      "target_cathodes": [
        "HE5050",
        "NMC111",
        "NMC532",
        "NMC622",
        "NMC811"
      ],
      "label_column": "eol_class",
      "split_used": "source_train",
      "batch_size_seen": 6,
      "channels": 21,
      "seq_len": 32
    },
    "text_context": "Dataset: Argonne National Laboratory battery aging time-series with partial cycle windows.\nSource cathodes: FCG; target cathodes: HE5050, NMC111, NMC532, NMC622, NMC811.\nLabel column 'eol_class' with ~None classes; sequence length 32; 21 channels covering cycle_number, energy_charge, capacity_charge, energy_discharge, capacity_discharge, cycle_start, cycle_duration.\nLiterature cues (Joule S2542-4351(22)00409-3, chemistry-sensitive ablations):\nJoule 2022 (S2542-4351(22)00409-3) key cues for chemistry-aware ablation:\n- Early-cycle capacity fade slopes and coulombic-efficiency stabilization highlight whether aging is lithium-inventory loss (graphite/anode-electrolyte limited) versus cathode structural decay (e.g., Ni-rich NMC cathodes with electrolyte oxidation risk).\n- High initial impedance growth, thick SEI signatures, or electrolyte oxidation markers flag chemistries that benefit from uncertainty-aware heads (SNGP/OpenMax) to avoid overconfident extrapolation on outlier cycles.\n- LFP/graphite pairs tend to show flatter voltage plateaus and slower early fade; Ni-rich NMC chemistries degrade faster under aggressive cycling and need stronger regularization or shorter cycle horizons in ablations.\n- Transfer between mismatched chemistries (e.g., NMC \u2192 LFP) should down-weight source loss and favor architectures that adapt quickly with self-attention or wider bottlenecks; closely matched chemistries can rely more on convolutional baselines.\nsource_train: class counts 3:6 (example label 3).\nsource_train sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1403000354766846, 0.6254000067710876, 0.6679999828338623, 0.6567999720573425, 0.6449999809265137, 0.6392999887466431, 0.6205999851226807, 0.6075000166893005, 0.6062999963760376, 0.\u2026\nsource_train flattened row glimpses: [[-1.6202, -1.1403, -1.1372, -1.1082, -1.132, -1.4587, -0.8036, -3.2107, -3.179, -0.1409], [-1.6202, -1.1403, -1.1372, -1.1082, -1.132, -1.4587, -0.8036, -3.2107, -3.179, -0.1409], [-1.6202, -1.1403, -1.1372, -1.1082, -1.132, -1.4587, -0.8036, -3.2107, -3.179, -0.1409]]\ntarget_train: class counts 0:22, 1:22, 2:38, 3:34, 4:39 (example label 1).\ntarget_train sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1403000354766846, -0.27320000529289246, -0.2777000069618225, -0.2948000133037567, -0.3199999928474426, -0.3249000012874603, -0.3255999982357025, -0.3427000045776367, -0.35010001063\u2026\ntarget_train flattened row glimpses: [[-1.6202, -1.1403, -1.1372, -1.1082, -1.132, -1.4587, -0.8036, -3.2107, -3.179, -0.1409], [-1.6202, -1.1403, -1.1372, -1.1082, -1.132, -1.4587, -0.8036, -3.2107, -3.179, -0.1409], [-1.6202, -1.1403, -1.1372, -1.1082, -1.132, -1.4587, -0.8036, -3.2107, -3.179, -0.1409]]\nsource_val: class counts 3:2 (example label 3).\nsource_val sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1403000354766846, 0.6047000288963318, 0.6389999985694885, 0.6284000277519226, 0.6177999973297119, 0.6114000082015991, 0.5934000015258789, 0.5813999772071838, 0.5791000127792358, 0.\u2026\nsource_val flattened row glimpses: [[-1.6202, -1.1403, -1.1372, -1.1082, -1.132, -1.4587, -0.8036, -3.2107, -3.179, -0.1409], [-1.6202, -1.1403, -1.1372, -1.1082, -1.132, -1.4587, -0.8036, -3.2107, -3.179, -0.1409]]\ntarget_val: class counts 0:9, 1:10, 2:19, 3:17, 4:19 (example label 3).\ntarget_val sample window (first 3 ch \u00d7 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1403000354766846, -1.1403000354766846, -1.1403000354766846, -1.1403000354766846, -1.1403000354766846, -1.1403000354766846, -1.1403000354766846, -1.1403000354766846, -1.140300035476\u2026\ntarget_val flattened row glimpses: [[-1.6202, -1.1403, -1.1372, -1.1082, -1.132, -1.4587, -0.8036, -3.2107, -3.179, -0.1409], [-1.6202, -1.1403, -1.1372, -1.1082, -1.132, -1.4587, -0.8036, -3.2107, -3.179, -0.1409], [-1.6202, -1.1403, -1.1372, -1.1082, -1.132, -1.4587, -0.8036, -3.2107, -3.179, -0.1409]]",
    "ablation": []
  }
]