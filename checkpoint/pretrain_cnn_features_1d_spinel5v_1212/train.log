12-12 14:29:59 data_name: Battery_inconsistent
12-12 14:29:59 data_dir: ./my_datasets/Battery
12-12 14:29:59 csv: ./my_datasets/Battery/battery_cycles_labeled.csv
12-12 14:29:59 normlizetype: mean-std
12-12 14:29:59 method: sngp
12-12 14:29:59 gp_hidden_dim: 2048
12-12 14:29:59 spectral_norm_bound: 0.95
12-12 14:29:59 n_power_iterations: 1
12-12 14:29:59 nesterov: True
12-12 14:29:59 print_freq: 10
12-12 14:29:59 layers: 16
12-12 14:29:59 widen_factor: 1
12-12 14:29:59 droprate: 0.35
12-12 14:29:59 cuda_device: 0
12-12 14:29:59 checkpoint_dir: ./checkpoint
12-12 14:29:59 pretrained: False
12-12 14:29:59 batch_size: 8
12-12 14:29:59 warmup_epochs: 3
12-12 14:29:59 num_workers: 0
12-12 14:29:59 bottleneck: True
12-12 14:29:59 bottleneck_num: 256
12-12 14:29:59 last_batch: False
12-12 14:29:59 hidden_size: 1024
12-12 14:29:59 trade_off_adversarial: Step
12-12 14:29:59 lam_adversarial: 1
12-12 14:29:59 opt: adam
12-12 14:29:59 lr: 0.0005
12-12 14:29:59 momentum: 0.9
12-12 14:29:59 weight_decay: 1e-05
12-12 14:29:59 lr_scheduler: step
12-12 14:29:59 gamma: 0.1
12-12 14:29:59 steps: 150, 250
12-12 14:29:59 middle_epoch: 15
12-12 14:29:59 max_epoch: 50
12-12 14:29:59 print_step: 25
12-12 14:29:59 inconsistent: UAN
12-12 14:29:59 model_name: cnn_features_1d
12-12 14:29:59 th: 0.5
12-12 14:29:59 input_channels: 7
12-12 14:29:59 classification_label: eol_class
12-12 14:29:59 sequence_length: 32
12-12 14:29:59 cycles_per_file: 15
12-12 14:29:59 source_cycles_per_file: None
12-12 14:29:59 target_cycles_per_file: None
12-12 14:29:59 cycle_ablation: False
12-12 14:29:59 cycle_ablation_start: 5
12-12 14:29:59 cycle_ablation_step: 10
12-12 14:29:59 cycle_ablation_max: None
12-12 14:29:59 literature_context_file: ./references/joule_s2542-4351-22-00409-3.md
12-12 14:29:59 sample_random_state: 42
12-12 14:29:59 transfer_task: [[[0], [1]], [[0], [2]], [[0], [3]], [[1], [0]], [[1], [2]], [[1], [3]], [[2], [0]], [[2], [1]], [[2], [3]], [[3], [0]], [[3], [1]], [[3], [2]]]
12-12 14:29:59 source_cathode: ['5Vspinel']
12-12 14:29:59 target_cathode: []
12-12 14:29:59 num_classes: None
12-12 14:29:59 domain_temperature: 1.0
12-12 14:29:59 class_temperature: 10.0
12-12 14:29:59 lambda_src: 1.5
12-12 14:29:59 lambda_src_decay_patience: 5
12-12 14:29:59 lambda_src_decay_factor: 0.5
12-12 14:29:59 lambda_src_min: 0.0
12-12 14:29:59 lambda_src_warmup: 0
12-12 14:29:59 improvement_metric: accuracy
12-12 14:29:59 skip_retry: False
12-12 14:29:59 auto_select: True
12-12 14:29:59 llm_compare: True
12-12 14:29:59 llm_backend: openai
12-12 14:29:59 llm_model: None
12-12 14:29:59 llm_context: 
12-12 14:29:59 llm_ablation: False
12-12 14:29:59 llm_per_transfer: True
12-12 14:29:59 ablation_cycle_limits: 
12-12 14:29:59 llm_cfg_inputs: {'text_context': "Dataset: Argonne National Laboratory battery aging time-series with partial cycle windows.\nSource cathodes: 5Vspinel; target cathodes: Li1.2Ni0.3Mn0.6O2, Li1.35Ni0.33Mn0.67O2.35.\nLabel column 'eol_class' with ~None classes; sequence length 32; 21 channels covering cycle_number, energy_charge, capacity_charge, energy_discharge, capacity_discharge, cycle_start, cycle_duration.\nLiterature cues (Joule S2542-4351(22)00409-3, chemistry-sensitive ablations):\nJoule 2022 (S2542-4351(22)00409-3) key cues for chemistry-aware ablation:\n- Early-cycle capacity fade slopes and coulombic-efficiency stabilization highlight whether aging is lithium-inventory loss (graphite/anode-electrolyte limited) versus cathode structural decay (e.g., Ni-rich NMC cathodes with electrolyte oxidation risk).\n- High initial impedance growth, thick SEI signatures, or electrolyte oxidation markers flag chemistries that benefit from uncertainty-aware heads (SNGP/OpenMax) to avoid overconfident extrapolation on outlier cycles.\n- LFP/graphite pairs tend to show flatter voltage plateaus and slower early fade; Ni-rich NMC chemistries degrade faster under aggressive cycling and need stronger regularization or shorter cycle horizons in ablations.\n- Transfer between mismatched chemistries (e.g., NMC → LFP) should down-weight source loss and favor architectures that adapt quickly with self-attention or wider bottlenecks; closely matched chemistries can rely more on convolutional baselines.\nsource_train: class counts 0:19, 1:18, 2:2, 3:1, 4:1 (example label 0).\nsource_train sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.5073000192642212, 0.29750001430511475, 0.1597999930381775, 0.11580000072717667, 0.06870000064373016, -0.0215000007301569, -0.06700000166893005, -0.0939000025391…\nsource_train flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]\ntarget_train: class counts 0:6 (example label 0).\ntarget_train sample window (first 3 ch × 12 steps): [[-1.896399974822998, -1.9917000532150269, -1.5246000289916992, 0.0, -0.8306000232696533, 0.0, -0.16660000383853912, 0.0, 0.17499999701976776, 0.2815000116825104, 0.4404999911785126, 0.287200003862381], [-2.2899999618530273, 2.789099931716919, 3.0618999004364014, 0.0, 2.724100112915039, 0.0, 1.9648000001907349, 0.0, 0.5493000149726868, 0.6560999751091003, -2.791300058364868, 2.6998000144958496], [-2.7012999057769775,…\ntarget_train flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]\nsource_val: class counts 0:5, 1:5, 2:1, 4:1 (example label 0).\nsource_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.3109000027179718, 0.25519999861717224, 0.11729999631643295, 0.027000000700354576, -0.023900000378489494, -0.09200000017881393, -0.14669999480247498, -0.17059999…\nsource_val flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]\ntarget_val: class counts 0:4 (example label 0).\ntarget_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 2.1417999267578125, 2.015700101852417, 1.9608999490737915, 2.140199899673462, 1.8382999897003174, 1.805999994277954, 3.2121999263763428, 1.5262000560760498, 1.592…\ntarget_val flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]", 'numeric_summary': {'dataset': 'Battery_inconsistent', 'sequence_length_requested': 32, 'notes': 'label_inconsistent', 'lr_hint': 0.0005, 'dropout_hint': 0.35, 'num_classes_hint': None, 'splits': {'source_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.5073000192642212, 0.29750001430511475, 0.1597999930381775, 0.11580000072717667, 0.06870000064373016, -0.0215000007301569, -0.06700000166893005, -0.09390000253915787, -0.14229999482631683, -0.26440000534057617, -0.26820001006126404], [-2.4202001094818115, 0.3971000015735626, 0.20489999651908875, 0.07859999686479568, 0.03830000013113022, -0.0044999998062849045, -0.0908999964594841, -0.1347000002861023, -0.15940000116825104, -0.20960000157356262, -0.3246999979019165, -0.32820001244544983]]}, 'batch_channel_mean': [0.8607000112533569, -0.1421000063419342, -0.2084999978542328, -0.07079999893903732, -0.16120000183582306, 0.534600019454956, -0.3154999911785126, 0.24279999732971191], 'batch_channel_std': [1.059499979019165, 0.5717999935150146, 0.5095999836921692, 0.6176000237464905, 0.5239999890327454, 0.9284999966621399, 0.7612000107765198, 0.8140000104904175], 'class_distribution': {'0': 19, '1': 18, '2': 2, '3': 1, '4': 1}, 'feature_range': [-2.9057923445856524, 5.202832943374929], 'feature_global_mean': -0.008143604364574682, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]}, 'target_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.896399974822998, -1.9917000532150269, -1.5246000289916992, 0.0, -0.8306000232696533, 0.0, -0.16660000383853912, 0.0, 0.17499999701976776, 0.2815000116825104, 0.4404999911785126, 0.287200003862381], [-2.2899999618530273, 2.789099931716919, 3.0618999004364014, 0.0, 2.724100112915039, 0.0, 1.9648000001907349, 0.0, 0.5493000149726868, 0.6560999751091003, -2.791300058364868, 2.6998000144958496], [-2.7012999057769775, 1.3554999828338623, 1.62090003490448, 0.0, 1.8700000047683716, 0.0, 1.3710999488830566, 0.0, 0.1671999990940094, 0.0502999983727932, -2.187700033187866, 0.9710999727249146]]}, 'batch_channel_mean': [0.7294999957084656, 0.8521999716758728, 1.1779999732971191, 0.9107999801635742, 1.1938999891281128, -0.11500000208616257, -0.24160000681877136, -0.2093999981880188], 'batch_channel_std': [1.037600040435791, 1.1383999586105347, 1.261199951171875, 1.3704999685287476, 1.382200002670288, 1.318600058555603, 1.0240000486373901, 1.1060999631881714], 'class_distribution': {'0': 6}, 'feature_range': [-3.6390493997246667, 19.875169049014566], 'feature_global_mean': 0.4374359295879304, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]}, 'source_val': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.3109000027179718, 0.25519999861717224, 0.11729999631643295, 0.027000000700354576, -0.023900000378489494, -0.09200000017881393, -0.14669999480247498, -0.17059999704360962, -0.19750000536441803, -0.23759999871253967, -0.2761000096797943], [-2.4202001094818115, 0.210999995470047, 0.16750000417232513, 0.040699999779462814, -0.04349999874830246, -0.09049999713897705, -0.15610000491142273, -0.20749999582767487, -0.2303999960422516, -0.26170000433921814, -0.3025999963283539, -0.33959999680519104]]}, 'batch_channel_mean': [0.8607000112533569, -0.14800000190734863, -0.21410000324249268, -0.1005999967455864, -0.1704999953508377, 0.7595000267028809, -0.25529998540878296, 0.00139999995008111], 'batch_channel_std': [1.059499979019165, 0.5544999837875366, 0.4968999922275543, 0.6308000087738037, 0.5254999995231628, 0.8083000183105469, 0.7978000044822693, 0.6376000046730042], 'class_distribution': {'0': 5, '1': 5, '2': 1, '4': 1}, 'feature_range': [-2.9057923445856524, 5.219029621397489], 'feature_global_mean': -0.004320963409587972, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]}, 'target_val': {'batch_shape': [4, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 2.1417999267578125, 2.015700101852417, 1.9608999490737915, 2.140199899673462, 1.8382999897003174, 1.805999994277954, 3.2121999263763428, 1.5262000560760498, 1.5922000408172607, 2.4560999870300293, 0.5361999869346619], [-2.4202001094818115, 2.6226999759674072, 2.5090999603271484, 2.4544999599456787, 2.5053000450134277, 2.200200080871582, 2.1552000045776367, 3.31030011177063, 1.7338000535964966, 1.7655999660491943, 2.470400094985962, 0.6173999905586243]]}, 'batch_channel_mean': [0.8607000112533569, 0.8479999899864197, 1.1744999885559082, 0.14030000567436218, 0.7558000087738037, -0.8087999820709229, -0.2743000090122223, -0.7925999760627747], 'batch_channel_std': [1.059499979019165, 1.2324999570846558, 1.3095999956130981, 1.6520999670028687, 1.822100043296814, 0.26759999990463257, 0.8853999972343445, 1.1957999467849731], 'class_distribution': {'0': 4}, 'feature_range': [-3.571829448600409, 19.622460716154905], 'feature_global_mean': 0.28418790425941914, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]}}, 'dataset_variant': 'argonne_battery', 'feature_names': ['cycle_number', 'energy_charge', 'capacity_charge', 'energy_discharge', 'capacity_discharge', 'cycle_start', 'cycle_duration'], 'source_cathodes': ['5Vspinel'], 'target_cathodes': ['Li1.2Ni0.3Mn0.6O2', 'Li1.35Ni0.33Mn0.67O2.35'], 'label_column': 'eol_class', 'split_used': 'source_train', 'batch_size_seen': 8, 'channels': 21, 'seq_len': 32}}
12-12 14:29:59 llm_cfg: {'architecture': 'cnn_1d', 'model_name': 'cnn_features_1d', 'self_attention': False, 'sngp': True, 'openmax': False, 'use_unknown_head': False, 'bottleneck': 256, 'dropout': 0.35, 'learning_rate': 0.0005, 'batch_size': 8, 'lambda_src': 1.5, 'warmup_epochs': 10, 'rationale': 'The dataset has 21 channels and a short sequence length (32), with domain shift between source and target chemistries. WideResNet_edited is tailored for battery data and transfer tasks with chemistry mismatch, providing strong representation power. Enabling SNGP and use_unknown_head helps manage uncertainty and avoid overconfident extrapolation on outlier cycles, important given label inconsistency and domain gap. Dropout at 0.35 balances regularization, and batch size 8 matches seen data. Moderate bottleneck (256) supports capacity without overfitting, and warmup_epochs 10 stabilizes training. Target cathode: Li1.2Ni0.3Mn0.6O2. Source cathodes: 5Vspinel (high-voltage spinel (manganese rich)). Source/target chemistries differ → expect domain shift. Evaluated 21 channels × 32-step windows and matched them with cnn_1d capacity. Target fine-tune spans ≈6 cycles versus 41 source cycles, guiding lr=5.00e-04 and dropout=0.35.', '_provider': 'openai', '_raw': '{\n  "model_name": "WideResNet_edited",\n  "self_attention": false,\n  "sngp": true,\n  "openmax": false,\n  "use_unknown_head": true,\n  "bottleneck": 256,\n  "dropout": 0.35,\n  "learning_rate": 0.0005,\n  "batch_size": 8,\n  "lambda_src": 1.0,\n  "warmup_epochs": 10,\n  "rationale": "The dataset has 21 channels and a short sequence length (32), with domain shift between source and target chemistries. WideResNet_edited is tailored for battery data and transfer tasks with chemistry mismatch, providing strong representation power. Enabling SNGP and use_unknown_head helps manage uncertainty and avoid overconfident extrapolation on outlier cycles, important given label inconsistency and domain gap. Dropout at 0.35 balances regularization, and batch size 8 matches seen data. Moderate bottleneck (256) supports capacity without overfitting, and warmup_epochs 10 stabilizes training."\n}'}
12-12 14:29:59 llm_cfg_stamp: 20251212_131825
12-12 14:29:59 tag: no_sa_20251212_131825
12-12 14:29:59 pretrained_model_path: None
12-12 14:30:03 using 1 cpu
12-12 14:51:51 data_name: Battery_inconsistent
12-12 14:51:51 data_dir: ./my_datasets/Battery
12-12 14:51:51 csv: ./my_datasets/Battery/battery_cycles_labeled.csv
12-12 14:51:51 normlizetype: mean-std
12-12 14:51:51 method: sngp
12-12 14:51:51 gp_hidden_dim: 2048
12-12 14:51:51 spectral_norm_bound: 0.95
12-12 14:51:51 n_power_iterations: 1
12-12 14:51:51 nesterov: True
12-12 14:51:51 print_freq: 10
12-12 14:51:51 layers: 16
12-12 14:51:51 widen_factor: 1
12-12 14:51:51 droprate: 0.35
12-12 14:51:51 cuda_device: 0
12-12 14:51:51 checkpoint_dir: ./checkpoint
12-12 14:51:51 pretrained: False
12-12 14:51:51 batch_size: 8
12-12 14:51:51 warmup_epochs: 3
12-12 14:51:51 num_workers: 0
12-12 14:51:51 bottleneck: True
12-12 14:51:51 bottleneck_num: 256
12-12 14:51:51 last_batch: False
12-12 14:51:51 hidden_size: 1024
12-12 14:51:51 trade_off_adversarial: Step
12-12 14:51:51 lam_adversarial: 1
12-12 14:51:51 opt: adam
12-12 14:51:51 lr: 0.0005
12-12 14:51:51 momentum: 0.9
12-12 14:51:51 weight_decay: 1e-05
12-12 14:51:51 lr_scheduler: step
12-12 14:51:51 gamma: 0.1
12-12 14:51:51 steps: 150, 250
12-12 14:51:51 middle_epoch: 15
12-12 14:51:51 max_epoch: 50
12-12 14:51:51 print_step: 25
12-12 14:51:51 inconsistent: UAN
12-12 14:51:51 model_name: cnn_features_1d
12-12 14:51:51 th: 0.5
12-12 14:51:51 input_channels: 7
12-12 14:51:51 classification_label: eol_class
12-12 14:51:51 sequence_length: 32
12-12 14:51:51 cycles_per_file: 15
12-12 14:51:51 source_cycles_per_file: None
12-12 14:51:51 target_cycles_per_file: None
12-12 14:51:51 cycle_ablation: False
12-12 14:51:51 cycle_ablation_start: 5
12-12 14:51:51 cycle_ablation_step: 10
12-12 14:51:51 cycle_ablation_max: None
12-12 14:51:51 literature_context_file: ./references/joule_s2542-4351-22-00409-3.md
12-12 14:51:51 sample_random_state: 42
12-12 14:51:51 transfer_task: [[[0], [1]], [[0], [2]], [[0], [3]], [[1], [0]], [[1], [2]], [[1], [3]], [[2], [0]], [[2], [1]], [[2], [3]], [[3], [0]], [[3], [1]], [[3], [2]]]
12-12 14:51:51 source_cathode: ['5Vspinel']
12-12 14:51:51 target_cathode: []
12-12 14:51:51 num_classes: None
12-12 14:51:51 domain_temperature: 1.0
12-12 14:51:51 class_temperature: 10.0
12-12 14:51:51 lambda_src: 0.6
12-12 14:51:51 lambda_src_decay_patience: 5
12-12 14:51:51 lambda_src_decay_factor: 0.5
12-12 14:51:51 lambda_src_min: 0.0
12-12 14:51:51 lambda_src_warmup: 0
12-12 14:51:51 improvement_metric: accuracy
12-12 14:51:51 skip_retry: False
12-12 14:51:51 auto_select: True
12-12 14:51:51 llm_compare: True
12-12 14:51:51 llm_backend: openai
12-12 14:51:51 llm_model: None
12-12 14:51:51 llm_context: 
12-12 14:51:51 llm_ablation: False
12-12 14:51:51 llm_per_transfer: True
12-12 14:51:51 ablation_cycle_limits: 
12-12 14:51:51 llm_cfg_inputs: {'text_context': "Dataset: Argonne National Laboratory battery aging time-series with partial cycle windows.\nSource cathodes: 5Vspinel; target cathodes: HE5050, NMC111, NMC532, NMC622, NMC811.\nLabel column 'eol_class' with ~None classes; sequence length 32; 21 channels covering cycle_number, energy_charge, capacity_charge, energy_discharge, capacity_discharge, cycle_start, cycle_duration.\nLiterature cues (Joule S2542-4351(22)00409-3, chemistry-sensitive ablations):\nJoule 2022 (S2542-4351(22)00409-3) key cues for chemistry-aware ablation:\n- Early-cycle capacity fade slopes and coulombic-efficiency stabilization highlight whether aging is lithium-inventory loss (graphite/anode-electrolyte limited) versus cathode structural decay (e.g., Ni-rich NMC cathodes with electrolyte oxidation risk).\n- High initial impedance growth, thick SEI signatures, or electrolyte oxidation markers flag chemistries that benefit from uncertainty-aware heads (SNGP/OpenMax) to avoid overconfident extrapolation on outlier cycles.\n- LFP/graphite pairs tend to show flatter voltage plateaus and slower early fade; Ni-rich NMC chemistries degrade faster under aggressive cycling and need stronger regularization or shorter cycle horizons in ablations.\n- Transfer between mismatched chemistries (e.g., NMC → LFP) should down-weight source loss and favor architectures that adapt quickly with self-attention or wider bottlenecks; closely matched chemistries can rely more on convolutional baselines.\nsource_train: class counts 0:19, 1:18, 2:2, 3:1, 4:1 (example label 1).\nsource_train sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -0.016899999231100082, 0.0012000000569969416, -0.030400000512599945, -0.03880000114440918, -0.04360000044107437, -0.05829999968409538, -0.0729999989271164, -0.074…\nsource_train flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408]]\ntarget_train: class counts 0:22, 1:22, 2:38, 3:34, 4:39 (example label 1).\ntarget_train sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, 0.3743000030517578, 0.37630000710487366, 0.3709999918937683, 0.3490999937057495, 0.34459999203681946, 0.34619998931884766, 0.32109999656677246, 0.3179000020027160…\ntarget_train flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408]]\nsource_val: class counts 0:5, 1:5, 2:1, 4:1 (example label 0).\nsource_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -0.04390000179409981, -0.06509999930858612, -0.11779999732971191, -0.15219999849796295, -0.17170000076293945, -0.19760000705718994, -0.21850000321865082, -0.22759…\nsource_val flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408]]\ntarget_val: class counts 0:9, 1:10, 2:19, 3:17, 4:19 (example label 3).\ntarget_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.174100041389…\ntarget_val flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408]]", 'numeric_summary': {'dataset': 'Battery_inconsistent', 'sequence_length_requested': 32, 'notes': 'label_inconsistent', 'lr_hint': 0.0005, 'dropout_hint': 0.35, 'num_classes_hint': None, 'splits': {'source_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 1, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -0.016899999231100082, 0.0012000000569969416, -0.030400000512599945, -0.03880000114440918, -0.04360000044107437, -0.05829999968409538, -0.0729999989271164, -0.07419999688863754, -0.07940000295639038, -0.10239999741315842, -0.11169999837875366], [-1.13100004196167, -0.17839999496936798, -0.15639999508857727, -0.18359999358654022, -0.19140000641345978, -0.195700004696846, -0.20919999480247498, -0.22220000624656677, -0.22349999845027924, -0.22930000722408295, -0.2498999983072281, -0.25760000944137573]]}, 'batch_channel_mean': [0.8607000112533569, -0.19619999825954437, -0.3012000024318695, -0.15970000624656677, -0.301800012588501, 0.9627000093460083, -0.1062999963760376, 0.14169999957084656], 'batch_channel_std': [1.059499979019165, 0.24040000140666962, 0.17249999940395355, 0.25209999084472656, 0.17270000278949738, 1.1347999572753906, 0.824999988079071, 0.6575999855995178], 'class_distribution': {'0': 19, '1': 18, '2': 2, '3': 1, '4': 1}, 'feature_range': [-3.203935665790699, 5.1401425697203385], 'feature_global_mean': -0.016921664518018544, 'flattened_rows_head': [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408]]}, 'target_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 1, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, 0.3743000030517578, 0.37630000710487366, 0.3709999918937683, 0.3490999937057495, 0.34459999203681946, 0.34619998931884766, 0.32109999656677246, 0.31790000200271606, 0.29190000891685486, 0.24529999494552612, 0.24169999361038208], [-1.13100004196167, 0.4562999904155731, 0.46230000257492065, 0.45500001311302185, 0.4316999912261963, 0.4268999993801117, 0.42480000853538513, 0.397599995136261, 0.39410001039505005, 0.36640000343322754, 0.31610000133514404, 0.3122999966144562]]}, 'batch_channel_mean': [0.8607000112533569, -0.04560000076889992, -0.01269999984651804, -0.06199999898672104, -0.009600000455975533, 0.1704999953508377, -0.36579999327659607, -0.0020000000949949026], 'batch_channel_std': [1.059499979019165, 0.5946999788284302, 0.5917999744415283, 0.5709999799728394, 0.5871999859809875, 0.9681000113487244, 0.6819999814033508, 0.7301999926567078], 'class_distribution': {'0': 22, '1': 22, '2': 38, '3': 34, '4': 39}, 'feature_range': [-9.981793547102113, 31.866555053073082], 'feature_global_mean': 0.043367023845691036, 'flattened_rows_head': [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408]]}, 'source_val': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -0.04390000179409981, -0.06509999930858612, -0.11779999732971191, -0.15219999849796295, -0.17170000076293945, -0.19760000705718994, -0.21850000321865082, -0.22759999334812164, -0.2379000037908554, -0.2531999945640564, -0.2678999900817871], [-1.13100004196167, -0.19740000367164612, -0.21279999613761902, -0.25780001282691956, -0.28760001063346863, -0.3043000102043152, -0.32760000228881836, -0.3458000123500824, -0.3540000021457672, -0.3650999963283539, -0.37959998846054077, -0.3926999866962433]]}, 'batch_channel_mean': [0.8607000112533569, -0.21899999678134918, -0.3481999933719635, -0.1915999948978424, -0.34689998626708984, 1.118899941444397, -0.11599999666213989, 0.016499999910593033], 'batch_channel_std': [1.059499979019165, 0.21160000562667847, 0.17630000412464142, 0.2303999960422516, 0.17829999327659607, 0.9266999959945679, 0.8331000208854675, 0.7063000202178955], 'class_distribution': {'0': 5, '1': 5, '2': 1, '4': 1}, 'feature_range': [-3.203935665790699, 5.1560300164083985], 'feature_global_mean': -0.010901597356338598, 'flattened_rows_head': [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408]]}, 'target_val': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 3, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653], [-1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167]]}, 'batch_channel_mean': [0.8607000112533569, 0.27559998631477356, 0.2630000114440918, 0.1655000001192093, 0.2653000056743622, 0.005200000014156103, -0.3278999924659729, -0.6205999851226807], 'batch_channel_std': [1.059499979019165, 0.4851999878883362, 0.47620001435279846, 0.46309998631477356, 0.47749999165534973, 0.9384999871253967, 0.8022000193595886, 0.9699000120162964], 'class_distribution': {'0': 9, '1': 10, '2': 19, '3': 17, '4': 19}, 'feature_range': [-3.426709644883315, 32.206823553376644], 'feature_global_mean': 0.014365731412246173, 'flattened_rows_head': [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408]]}}, 'dataset_variant': 'argonne_battery', 'feature_names': ['cycle_number', 'energy_charge', 'capacity_charge', 'energy_discharge', 'capacity_discharge', 'cycle_start', 'cycle_duration'], 'source_cathodes': ['5Vspinel'], 'target_cathodes': ['HE5050', 'NMC111', 'NMC532', 'NMC622', 'NMC811'], 'label_column': 'eol_class', 'split_used': 'source_train', 'batch_size_seen': 8, 'channels': 21, 'seq_len': 32}}
12-12 14:51:51 llm_cfg: {'architecture': 'cnn_1d', 'model_name': 'cnn_features_1d', 'self_attention': False, 'sngp': True, 'openmax': False, 'use_unknown_head': False, 'bottleneck': 256, 'dropout': 0.35, 'learning_rate': 0.0005, 'batch_size': 8, 'lambda_src': 0.6, 'warmup_epochs': 10, 'rationale': 'The dataset has 21 channels and short sequences (32 steps) with domain shift between source and target chemistries, favoring a high-capacity model with transfer adaptation. WideResNet_edited is tuned for battery data and handles domain gaps well. SNGP and use_unknown_head improve uncertainty calibration for outlier cycles and label inconsistency. Dropout at 0.35 balances regularization without overfitting small source data. Batch size 8 matches seen data, and moderate lambda_src and warmup_epochs support stable transfer learning. Target cathode: HE5050 (high-energy experimental blend). Source cathodes: 5Vspinel (high-voltage spinel (manganese rich)). Source/target chemistries differ → expect domain shift. Evaluated 21 channels × 32-step windows and matched them with cnn_1d capacity. Target fine-tune spans ≈155 cycles versus 41 source cycles, guiding lr=5.00e-04 and dropout=0.35.', '_provider': 'openai', '_raw': '{\n  "model_name": "WideResNet_edited",\n  "self_attention": false,\n  "sngp": true,\n  "openmax": false,\n  "use_unknown_head": true,\n  "bottleneck": 256,\n  "dropout": 0.35,\n  "learning_rate": 0.0005,\n  "batch_size": 8,\n  "lambda_src": 1.5,\n  "warmup_epochs": 10,\n  "rationale": "The dataset has 21 channels and short sequences (32 steps) with domain shift between source and target chemistries, favoring a high-capacity model with transfer adaptation. WideResNet_edited is tuned for battery data and handles domain gaps well. SNGP and use_unknown_head improve uncertainty calibration for outlier cycles and label inconsistency. Dropout at 0.35 balances regularization without overfitting small source data. Batch size 8 matches seen data, and moderate lambda_src and warmup_epochs support stable transfer learning."\n}'}
12-12 14:51:51 llm_cfg_stamp: 20251212_131825
12-12 14:51:51 tag: no_sngp_20251212_131825
12-12 14:51:51 pretrained_model_path: None
12-12 14:51:54 using 1 cpu
12-12 15:30:54 data_name: Battery_inconsistent
12-12 15:30:54 data_dir: ./my_datasets/Battery
12-12 15:30:54 csv: ./my_datasets/Battery/battery_cycles_labeled.csv
12-12 15:30:54 normlizetype: mean-std
12-12 15:30:54 method: sngp
12-12 15:30:54 gp_hidden_dim: 2048
12-12 15:30:54 spectral_norm_bound: 0.95
12-12 15:30:54 n_power_iterations: 1
12-12 15:30:54 nesterov: True
12-12 15:30:54 print_freq: 10
12-12 15:30:54 layers: 16
12-12 15:30:54 widen_factor: 1
12-12 15:30:54 droprate: 0.35
12-12 15:30:54 cuda_device: 0
12-12 15:30:54 checkpoint_dir: ./checkpoint
12-12 15:30:54 pretrained: False
12-12 15:30:54 batch_size: 8
12-12 15:30:54 warmup_epochs: 3
12-12 15:30:54 num_workers: 0
12-12 15:30:54 bottleneck: True
12-12 15:30:54 bottleneck_num: 256
12-12 15:30:54 last_batch: False
12-12 15:30:54 hidden_size: 1024
12-12 15:30:54 trade_off_adversarial: Step
12-12 15:30:54 lam_adversarial: 1
12-12 15:30:54 opt: adam
12-12 15:30:54 lr: 0.0005
12-12 15:30:54 momentum: 0.9
12-12 15:30:54 weight_decay: 1e-05
12-12 15:30:54 lr_scheduler: step
12-12 15:30:54 gamma: 0.1
12-12 15:30:54 steps: 150, 250
12-12 15:30:54 middle_epoch: 15
12-12 15:30:54 max_epoch: 50
12-12 15:30:54 print_step: 25
12-12 15:30:54 inconsistent: UAN
12-12 15:30:54 model_name: cnn_features_1d
12-12 15:30:54 th: 0.5
12-12 15:30:54 input_channels: 7
12-12 15:30:54 classification_label: eol_class
12-12 15:30:54 sequence_length: 32
12-12 15:30:54 cycles_per_file: 15
12-12 15:30:54 source_cycles_per_file: None
12-12 15:30:54 target_cycles_per_file: None
12-12 15:30:54 cycle_ablation: False
12-12 15:30:54 cycle_ablation_start: 5
12-12 15:30:54 cycle_ablation_step: 10
12-12 15:30:54 cycle_ablation_max: None
12-12 15:30:54 literature_context_file: ./references/joule_s2542-4351-22-00409-3.md
12-12 15:30:54 sample_random_state: 42
12-12 15:30:54 transfer_task: [[[0], [1]], [[0], [2]], [[0], [3]], [[1], [0]], [[1], [2]], [[1], [3]], [[2], [0]], [[2], [1]], [[2], [3]], [[3], [0]], [[3], [1]], [[3], [2]]]
12-12 15:30:54 source_cathode: ['5Vspinel']
12-12 15:30:54 target_cathode: []
12-12 15:30:54 num_classes: None
12-12 15:30:54 domain_temperature: 1.0
12-12 15:30:54 class_temperature: 10.0
12-12 15:30:54 lambda_src: 1.5
12-12 15:30:54 lambda_src_decay_patience: 5
12-12 15:30:54 lambda_src_decay_factor: 0.5
12-12 15:30:54 lambda_src_min: 0.0
12-12 15:30:54 lambda_src_warmup: 0
12-12 15:30:54 improvement_metric: accuracy
12-12 15:30:54 skip_retry: False
12-12 15:30:54 auto_select: True
12-12 15:30:54 llm_compare: True
12-12 15:30:54 llm_backend: openai
12-12 15:30:54 llm_model: None
12-12 15:30:54 llm_context: 
12-12 15:30:54 llm_ablation: False
12-12 15:30:54 llm_per_transfer: True
12-12 15:30:54 ablation_cycle_limits: 
12-12 15:30:54 llm_cfg_inputs: {'text_context': "Dataset: Argonne National Laboratory battery aging time-series with partial cycle windows.\nSource cathodes: 5Vspinel; target cathodes: Li1.2Ni0.3Mn0.6O2, Li1.35Ni0.33Mn0.67O2.35.\nLabel column 'eol_class' with ~None classes; sequence length 32; 21 channels covering cycle_number, energy_charge, capacity_charge, energy_discharge, capacity_discharge, cycle_start, cycle_duration.\nLiterature cues (Joule S2542-4351(22)00409-3, chemistry-sensitive ablations):\nJoule 2022 (S2542-4351(22)00409-3) key cues for chemistry-aware ablation:\n- Early-cycle capacity fade slopes and coulombic-efficiency stabilization highlight whether aging is lithium-inventory loss (graphite/anode-electrolyte limited) versus cathode structural decay (e.g., Ni-rich NMC cathodes with electrolyte oxidation risk).\n- High initial impedance growth, thick SEI signatures, or electrolyte oxidation markers flag chemistries that benefit from uncertainty-aware heads (SNGP/OpenMax) to avoid overconfident extrapolation on outlier cycles.\n- LFP/graphite pairs tend to show flatter voltage plateaus and slower early fade; Ni-rich NMC chemistries degrade faster under aggressive cycling and need stronger regularization or shorter cycle horizons in ablations.\n- Transfer between mismatched chemistries (e.g., NMC → LFP) should down-weight source loss and favor architectures that adapt quickly with self-attention or wider bottlenecks; closely matched chemistries can rely more on convolutional baselines.\nsource_train: class counts 0:19, 1:18, 2:2, 3:1, 4:1 (example label 0).\nsource_train sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.5073000192642212, 0.29750001430511475, 0.1597999930381775, 0.11580000072717667, 0.06870000064373016, -0.0215000007301569, -0.06700000166893005, -0.0939000025391…\nsource_train flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]\ntarget_train: class counts 0:6 (example label 0).\ntarget_train sample window (first 3 ch × 12 steps): [[-1.896399974822998, -1.9917000532150269, -1.5246000289916992, 0.0, -0.8306000232696533, 0.0, -0.16660000383853912, 0.0, 0.17499999701976776, 0.2815000116825104, 0.4404999911785126, 0.287200003862381], [-2.2899999618530273, 2.789099931716919, 3.0618999004364014, 0.0, 2.724100112915039, 0.0, 1.9648000001907349, 0.0, 0.5493000149726868, 0.6560999751091003, -2.791300058364868, 2.6998000144958496], [-2.7012999057769775,…\ntarget_train flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]\nsource_val: class counts 0:5, 1:5, 2:1, 4:1 (example label 0).\nsource_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.3109000027179718, 0.25519999861717224, 0.11729999631643295, 0.027000000700354576, -0.023900000378489494, -0.09200000017881393, -0.14669999480247498, -0.17059999…\nsource_val flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]\ntarget_val: class counts 0:4 (example label 0).\ntarget_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 2.1417999267578125, 2.015700101852417, 1.9608999490737915, 2.140199899673462, 1.8382999897003174, 1.805999994277954, 3.2121999263763428, 1.5262000560760498, 1.592…\ntarget_val flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]", 'numeric_summary': {'dataset': 'Battery_inconsistent', 'sequence_length_requested': 32, 'notes': 'label_inconsistent', 'lr_hint': 0.0005, 'dropout_hint': 0.35, 'num_classes_hint': None, 'splits': {'source_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.5073000192642212, 0.29750001430511475, 0.1597999930381775, 0.11580000072717667, 0.06870000064373016, -0.0215000007301569, -0.06700000166893005, -0.09390000253915787, -0.14229999482631683, -0.26440000534057617, -0.26820001006126404], [-2.4202001094818115, 0.3971000015735626, 0.20489999651908875, 0.07859999686479568, 0.03830000013113022, -0.0044999998062849045, -0.0908999964594841, -0.1347000002861023, -0.15940000116825104, -0.20960000157356262, -0.3246999979019165, -0.32820001244544983]]}, 'batch_channel_mean': [0.8607000112533569, -0.1421000063419342, -0.2084999978542328, -0.07079999893903732, -0.16120000183582306, 0.534600019454956, -0.3154999911785126, 0.24279999732971191], 'batch_channel_std': [1.059499979019165, 0.5717999935150146, 0.5095999836921692, 0.6176000237464905, 0.5239999890327454, 0.9284999966621399, 0.7612000107765198, 0.8140000104904175], 'class_distribution': {'0': 19, '1': 18, '2': 2, '3': 1, '4': 1}, 'feature_range': [-2.9057923445856524, 5.202832943374929], 'feature_global_mean': -0.008143604364574682, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]}, 'target_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.896399974822998, -1.9917000532150269, -1.5246000289916992, 0.0, -0.8306000232696533, 0.0, -0.16660000383853912, 0.0, 0.17499999701976776, 0.2815000116825104, 0.4404999911785126, 0.287200003862381], [-2.2899999618530273, 2.789099931716919, 3.0618999004364014, 0.0, 2.724100112915039, 0.0, 1.9648000001907349, 0.0, 0.5493000149726868, 0.6560999751091003, -2.791300058364868, 2.6998000144958496], [-2.7012999057769775, 1.3554999828338623, 1.62090003490448, 0.0, 1.8700000047683716, 0.0, 1.3710999488830566, 0.0, 0.1671999990940094, 0.0502999983727932, -2.187700033187866, 0.9710999727249146]]}, 'batch_channel_mean': [0.7294999957084656, 0.8521999716758728, 1.1779999732971191, 0.9107999801635742, 1.1938999891281128, -0.11500000208616257, -0.24160000681877136, -0.2093999981880188], 'batch_channel_std': [1.037600040435791, 1.1383999586105347, 1.261199951171875, 1.3704999685287476, 1.382200002670288, 1.318600058555603, 1.0240000486373901, 1.1060999631881714], 'class_distribution': {'0': 6}, 'feature_range': [-3.6390493997246667, 19.875169049014566], 'feature_global_mean': 0.4374359295879304, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]}, 'source_val': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.3109000027179718, 0.25519999861717224, 0.11729999631643295, 0.027000000700354576, -0.023900000378489494, -0.09200000017881393, -0.14669999480247498, -0.17059999704360962, -0.19750000536441803, -0.23759999871253967, -0.2761000096797943], [-2.4202001094818115, 0.210999995470047, 0.16750000417232513, 0.040699999779462814, -0.04349999874830246, -0.09049999713897705, -0.15610000491142273, -0.20749999582767487, -0.2303999960422516, -0.26170000433921814, -0.3025999963283539, -0.33959999680519104]]}, 'batch_channel_mean': [0.8607000112533569, -0.14800000190734863, -0.21410000324249268, -0.1005999967455864, -0.1704999953508377, 0.7595000267028809, -0.25529998540878296, 0.00139999995008111], 'batch_channel_std': [1.059499979019165, 0.5544999837875366, 0.4968999922275543, 0.6308000087738037, 0.5254999995231628, 0.8083000183105469, 0.7978000044822693, 0.6376000046730042], 'class_distribution': {'0': 5, '1': 5, '2': 1, '4': 1}, 'feature_range': [-2.9057923445856524, 5.219029621397489], 'feature_global_mean': -0.004320963409587972, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]}, 'target_val': {'batch_shape': [4, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 2.1417999267578125, 2.015700101852417, 1.9608999490737915, 2.140199899673462, 1.8382999897003174, 1.805999994277954, 3.2121999263763428, 1.5262000560760498, 1.5922000408172607, 2.4560999870300293, 0.5361999869346619], [-2.4202001094818115, 2.6226999759674072, 2.5090999603271484, 2.4544999599456787, 2.5053000450134277, 2.200200080871582, 2.1552000045776367, 3.31030011177063, 1.7338000535964966, 1.7655999660491943, 2.470400094985962, 0.6173999905586243]]}, 'batch_channel_mean': [0.8607000112533569, 0.8479999899864197, 1.1744999885559082, 0.14030000567436218, 0.7558000087738037, -0.8087999820709229, -0.2743000090122223, -0.7925999760627747], 'batch_channel_std': [1.059499979019165, 1.2324999570846558, 1.3095999956130981, 1.6520999670028687, 1.822100043296814, 0.26759999990463257, 0.8853999972343445, 1.1957999467849731], 'class_distribution': {'0': 4}, 'feature_range': [-3.571829448600409, 19.622460716154905], 'feature_global_mean': 0.28418790425941914, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]}}, 'dataset_variant': 'argonne_battery', 'feature_names': ['cycle_number', 'energy_charge', 'capacity_charge', 'energy_discharge', 'capacity_discharge', 'cycle_start', 'cycle_duration'], 'source_cathodes': ['5Vspinel'], 'target_cathodes': ['Li1.2Ni0.3Mn0.6O2', 'Li1.35Ni0.33Mn0.67O2.35'], 'label_column': 'eol_class', 'split_used': 'source_train', 'batch_size_seen': 8, 'channels': 21, 'seq_len': 32}}
12-12 15:30:54 llm_cfg: {'architecture': 'cnn_1d', 'model_name': 'cnn_features_1d', 'self_attention': False, 'sngp': True, 'openmax': False, 'use_unknown_head': False, 'bottleneck': 256, 'dropout': 0.35, 'learning_rate': 0.0005, 'batch_size': 8, 'lambda_src': 1.5, 'warmup_epochs': 10, 'rationale': 'The dataset has 21 channels and short sequences (32 steps) with label inconsistency and domain shift between source and target cathodes. WideResNet_edited is tuned for battery data and handles domain gaps well. Using SNGP and an unknown head helps manage uncertainty and avoid overconfident extrapolation on outlier cycles. A moderate bottleneck (256) balances capacity and regularization, with dropout at 0.35 to prevent overfitting. Batch size 8 matches seen data, learning rate 0.0005 is stable, and warmup_epochs 10 aids smooth adaptation. Target cathode: Li1.2Ni0.3Mn0.6O2. Source cathodes: 5Vspinel (high-voltage spinel (manganese rich)). Source/target chemistries differ → expect domain shift. Evaluated 21 channels × 32-step windows and matched them with cnn_1d capacity. Target fine-tune spans ≈6 cycles versus 41 source cycles, guiding lr=5.00e-04 and dropout=0.35.', '_provider': 'openai', '_raw': '{\n  "model_name": "WideResNet_edited",\n  "self_attention": false,\n  "sngp": true,\n  "openmax": false,\n  "use_unknown_head": true,\n  "bottleneck": 256,\n  "dropout": 0.35,\n  "learning_rate": 0.0005,\n  "batch_size": 8,\n  "lambda_src": 1.0,\n  "warmup_epochs": 10,\n  "rationale": "The dataset has 21 channels and short sequences (32 steps) with label inconsistency and domain shift between source and target cathodes. WideResNet_edited is tuned for battery data and handles domain gaps well. Using SNGP and an unknown head helps manage uncertainty and avoid overconfident extrapolation on outlier cycles. A moderate bottleneck (256) balances capacity and regularization, with dropout at 0.35 to prevent overfitting. Batch size 8 matches seen data, learning rate 0.0005 is stable, and warmup_epochs 10 aids smooth adaptation."\n}'}
12-12 15:30:54 llm_cfg_stamp: 20251212_131825
12-12 15:30:54 tag: detcnn_20251212_131825
12-12 15:30:54 pretrained_model_path: None
12-12 15:30:57 using 1 cpu
12-12 16:17:19 data_name: Battery_inconsistent
12-12 16:17:19 data_dir: ./my_datasets/Battery
12-12 16:17:19 csv: ./my_datasets/Battery/battery_cycles_labeled.csv
12-12 16:17:19 normlizetype: mean-std
12-12 16:17:19 method: sngp
12-12 16:17:19 gp_hidden_dim: 2048
12-12 16:17:19 spectral_norm_bound: 0.95
12-12 16:17:19 n_power_iterations: 1
12-12 16:17:19 nesterov: True
12-12 16:17:19 print_freq: 10
12-12 16:17:19 layers: 16
12-12 16:17:19 widen_factor: 1
12-12 16:17:19 droprate: 0.35
12-12 16:17:19 cuda_device: 0
12-12 16:17:19 checkpoint_dir: ./checkpoint
12-12 16:17:19 pretrained: False
12-12 16:17:19 batch_size: 8
12-12 16:17:19 warmup_epochs: 3
12-12 16:17:19 num_workers: 0
12-12 16:17:19 bottleneck: True
12-12 16:17:19 bottleneck_num: 256
12-12 16:17:19 last_batch: False
12-12 16:17:19 hidden_size: 1024
12-12 16:17:19 trade_off_adversarial: Step
12-12 16:17:19 lam_adversarial: 1
12-12 16:17:19 opt: adam
12-12 16:17:19 lr: 0.0005
12-12 16:17:19 momentum: 0.9
12-12 16:17:19 weight_decay: 1e-05
12-12 16:17:19 lr_scheduler: step
12-12 16:17:19 gamma: 0.1
12-12 16:17:19 steps: 150, 250
12-12 16:17:19 middle_epoch: 15
12-12 16:17:19 max_epoch: 50
12-12 16:17:19 print_step: 25
12-12 16:17:19 inconsistent: UAN
12-12 16:17:19 model_name: cnn_features_1d
12-12 16:17:19 th: 0.5
12-12 16:17:19 input_channels: 7
12-12 16:17:19 classification_label: eol_class
12-12 16:17:19 sequence_length: 32
12-12 16:17:19 cycles_per_file: 15
12-12 16:17:19 source_cycles_per_file: None
12-12 16:17:19 target_cycles_per_file: None
12-12 16:17:19 cycle_ablation: False
12-12 16:17:19 cycle_ablation_start: 5
12-12 16:17:19 cycle_ablation_step: 10
12-12 16:17:19 cycle_ablation_max: None
12-12 16:17:19 literature_context_file: ./references/joule_s2542-4351-22-00409-3.md
12-12 16:17:19 sample_random_state: 42
12-12 16:17:19 transfer_task: [[[0], [1]], [[0], [2]], [[0], [3]], [[1], [0]], [[1], [2]], [[1], [3]], [[2], [0]], [[2], [1]], [[2], [3]], [[3], [0]], [[3], [1]], [[3], [2]]]
12-12 16:17:19 source_cathode: ['5Vspinel']
12-12 16:17:19 target_cathode: []
12-12 16:17:19 num_classes: None
12-12 16:17:19 domain_temperature: 1.0
12-12 16:17:19 class_temperature: 10.0
12-12 16:17:19 lambda_src: 0.6
12-12 16:17:19 lambda_src_decay_patience: 5
12-12 16:17:19 lambda_src_decay_factor: 0.5
12-12 16:17:19 lambda_src_min: 0.0
12-12 16:17:19 lambda_src_warmup: 0
12-12 16:17:19 improvement_metric: accuracy
12-12 16:17:19 skip_retry: False
12-12 16:17:19 auto_select: True
12-12 16:17:19 llm_compare: True
12-12 16:17:19 llm_backend: openai
12-12 16:17:19 llm_model: None
12-12 16:17:19 llm_context: 
12-12 16:17:19 llm_ablation: False
12-12 16:17:19 llm_per_transfer: True
12-12 16:17:19 ablation_cycle_limits: 
12-12 16:17:19 llm_cfg_inputs: {'text_context': "Dataset: Argonne National Laboratory battery aging time-series with partial cycle windows.\nSource cathodes: 5Vspinel; target cathodes: HE5050, NMC111, NMC532, NMC622, NMC811.\nLabel column 'eol_class' with ~None classes; sequence length 32; 21 channels covering cycle_number, energy_charge, capacity_charge, energy_discharge, capacity_discharge, cycle_start, cycle_duration.\nLiterature cues (Joule S2542-4351(22)00409-3, chemistry-sensitive ablations):\nJoule 2022 (S2542-4351(22)00409-3) key cues for chemistry-aware ablation:\n- Early-cycle capacity fade slopes and coulombic-efficiency stabilization highlight whether aging is lithium-inventory loss (graphite/anode-electrolyte limited) versus cathode structural decay (e.g., Ni-rich NMC cathodes with electrolyte oxidation risk).\n- High initial impedance growth, thick SEI signatures, or electrolyte oxidation markers flag chemistries that benefit from uncertainty-aware heads (SNGP/OpenMax) to avoid overconfident extrapolation on outlier cycles.\n- LFP/graphite pairs tend to show flatter voltage plateaus and slower early fade; Ni-rich NMC chemistries degrade faster under aggressive cycling and need stronger regularization or shorter cycle horizons in ablations.\n- Transfer between mismatched chemistries (e.g., NMC → LFP) should down-weight source loss and favor architectures that adapt quickly with self-attention or wider bottlenecks; closely matched chemistries can rely more on convolutional baselines.\nsource_train: class counts 0:19, 1:18, 2:2, 3:1, 4:1 (example label 1).\nsource_train sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -0.016899999231100082, 0.0012000000569969416, -0.030400000512599945, -0.03880000114440918, -0.04360000044107437, -0.05829999968409538, -0.0729999989271164, -0.074…\nsource_train flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408]]\ntarget_train: class counts 0:22, 1:22, 2:38, 3:34, 4:39 (example label 1).\ntarget_train sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, 0.3743000030517578, 0.37630000710487366, 0.3709999918937683, 0.3490999937057495, 0.34459999203681946, 0.34619998931884766, 0.32109999656677246, 0.3179000020027160…\ntarget_train flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408]]\nsource_val: class counts 0:5, 1:5, 2:1, 4:1 (example label 0).\nsource_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -0.04390000179409981, -0.06509999930858612, -0.11779999732971191, -0.15219999849796295, -0.17170000076293945, -0.19760000705718994, -0.21850000321865082, -0.22759…\nsource_val flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408]]\ntarget_val: class counts 0:9, 1:10, 2:19, 3:17, 4:19 (example label 3).\ntarget_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.174100041389…\ntarget_val flattened row glimpses: [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408]]", 'numeric_summary': {'dataset': 'Battery_inconsistent', 'sequence_length_requested': 32, 'notes': 'label_inconsistent', 'lr_hint': 0.0005, 'dropout_hint': 0.35, 'num_classes_hint': None, 'splits': {'source_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 1, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -0.016899999231100082, 0.0012000000569969416, -0.030400000512599945, -0.03880000114440918, -0.04360000044107437, -0.05829999968409538, -0.0729999989271164, -0.07419999688863754, -0.07940000295639038, -0.10239999741315842, -0.11169999837875366], [-1.13100004196167, -0.17839999496936798, -0.15639999508857727, -0.18359999358654022, -0.19140000641345978, -0.195700004696846, -0.20919999480247498, -0.22220000624656677, -0.22349999845027924, -0.22930000722408295, -0.2498999983072281, -0.25760000944137573]]}, 'batch_channel_mean': [0.8607000112533569, -0.19619999825954437, -0.3012000024318695, -0.15970000624656677, -0.301800012588501, 0.9627000093460083, -0.1062999963760376, 0.14169999957084656], 'batch_channel_std': [1.059499979019165, 0.24040000140666962, 0.17249999940395355, 0.25209999084472656, 0.17270000278949738, 1.1347999572753906, 0.824999988079071, 0.6575999855995178], 'class_distribution': {'0': 19, '1': 18, '2': 2, '3': 1, '4': 1}, 'feature_range': [-3.203935665790699, 5.1401425697203385], 'feature_global_mean': -0.016921664518018544, 'flattened_rows_head': [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408]]}, 'target_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 1, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, 0.3743000030517578, 0.37630000710487366, 0.3709999918937683, 0.3490999937057495, 0.34459999203681946, 0.34619998931884766, 0.32109999656677246, 0.31790000200271606, 0.29190000891685486, 0.24529999494552612, 0.24169999361038208], [-1.13100004196167, 0.4562999904155731, 0.46230000257492065, 0.45500001311302185, 0.4316999912261963, 0.4268999993801117, 0.42480000853538513, 0.397599995136261, 0.39410001039505005, 0.36640000343322754, 0.31610000133514404, 0.3122999966144562]]}, 'batch_channel_mean': [0.8607000112533569, -0.04560000076889992, -0.01269999984651804, -0.06199999898672104, -0.009600000455975533, 0.1704999953508377, -0.36579999327659607, -0.0020000000949949026], 'batch_channel_std': [1.059499979019165, 0.5946999788284302, 0.5917999744415283, 0.5709999799728394, 0.5871999859809875, 0.9681000113487244, 0.6819999814033508, 0.7301999926567078], 'class_distribution': {'0': 22, '1': 22, '2': 38, '3': 34, '4': 39}, 'feature_range': [-9.981793547102113, 31.866555053073082], 'feature_global_mean': 0.043367023845691036, 'flattened_rows_head': [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408]]}, 'source_val': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -0.04390000179409981, -0.06509999930858612, -0.11779999732971191, -0.15219999849796295, -0.17170000076293945, -0.19760000705718994, -0.21850000321865082, -0.22759999334812164, -0.2379000037908554, -0.2531999945640564, -0.2678999900817871], [-1.13100004196167, -0.19740000367164612, -0.21279999613761902, -0.25780001282691956, -0.28760001063346863, -0.3043000102043152, -0.32760000228881836, -0.3458000123500824, -0.3540000021457672, -0.3650999963283539, -0.37959998846054077, -0.3926999866962433]]}, 'batch_channel_mean': [0.8607000112533569, -0.21899999678134918, -0.3481999933719635, -0.1915999948978424, -0.34689998626708984, 1.118899941444397, -0.11599999666213989, 0.016499999910593033], 'batch_channel_std': [1.059499979019165, 0.21160000562667847, 0.17630000412464142, 0.2303999960422516, 0.17829999327659607, 0.9266999959945679, 0.8331000208854675, 0.7063000202178955], 'class_distribution': {'0': 5, '1': 5, '2': 1, '4': 1}, 'feature_range': [-3.203935665790699, 5.1560300164083985], 'feature_global_mean': -0.010901597356338598, 'flattened_rows_head': [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8328, -3.2039, -3.1735, -0.1408]]}, 'target_val': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 3, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653, -1.1741000413894653], [-1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167, -1.13100004196167]]}, 'batch_channel_mean': [0.8607000112533569, 0.27559998631477356, 0.2630000114440918, 0.1655000001192093, 0.2653000056743622, 0.005200000014156103, -0.3278999924659729, -0.6205999851226807], 'batch_channel_std': [1.059499979019165, 0.4851999878883362, 0.47620001435279846, 0.46309998631477356, 0.47749999165534973, 0.9384999871253967, 0.8022000193595886, 0.9699000120162964], 'class_distribution': {'0': 9, '1': 10, '2': 19, '3': 17, '4': 19}, 'feature_range': [-3.426709644883315, 32.206823553376644], 'feature_global_mean': 0.014365731412246173, 'flattened_rows_head': [[-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408], [-1.6202, -1.1741, -1.131, -1.1495, -1.1239, -1.459, -0.8317, -3.2039, -3.1735, -0.1408]]}}, 'dataset_variant': 'argonne_battery', 'feature_names': ['cycle_number', 'energy_charge', 'capacity_charge', 'energy_discharge', 'capacity_discharge', 'cycle_start', 'cycle_duration'], 'source_cathodes': ['5Vspinel'], 'target_cathodes': ['HE5050', 'NMC111', 'NMC532', 'NMC622', 'NMC811'], 'label_column': 'eol_class', 'split_used': 'source_train', 'batch_size_seen': 8, 'channels': 21, 'seq_len': 32}}
12-12 16:17:19 llm_cfg: {'architecture': 'cnn_1d', 'model_name': 'cnn_features_1d', 'self_attention': False, 'sngp': True, 'openmax': False, 'use_unknown_head': False, 'bottleneck': 256, 'dropout': 0.35, 'learning_rate': 0.0005, 'batch_size': 8, 'lambda_src': 0.6, 'warmup_epochs': 10, 'rationale': 'The dataset has 21 channels and short sequences (32 steps) with label inconsistency and domain shift between source and target chemistries. WideResNet_edited is tailored for battery data with domain gaps and benefits from physics-inspired feature edits. Using SNGP and an unknown head helps manage uncertainty and outlier cycles due to chemistry mismatch. Dropout at 0.35 balances regularization for small source data, and a moderate bottleneck of 256 supports capacity without overfitting. Batch size 8 matches seen data, and warmup epochs help stabilize transfer learning. Target cathode: HE5050 (high-energy experimental blend). Source cathodes: 5Vspinel (high-voltage spinel (manganese rich)). Source/target chemistries differ → expect domain shift. Evaluated 21 channels × 32-step windows and matched them with cnn_1d capacity. Target fine-tune spans ≈155 cycles versus 41 source cycles, guiding lr=5.00e-04 and dropout=0.35.', '_provider': 'openai', '_raw': '{\n  "model_name": "WideResNet_edited",\n  "self_attention": false,\n  "sngp": true,\n  "openmax": false,\n  "use_unknown_head": true,\n  "bottleneck": 256,\n  "dropout": 0.35,\n  "learning_rate": 0.0005,\n  "batch_size": 8,\n  "lambda_src": 1.0,\n  "warmup_epochs": 10,\n  "rationale": "The dataset has 21 channels and short sequences (32 steps) with label inconsistency and domain shift between source and target chemistries. WideResNet_edited is tailored for battery data with domain gaps and benefits from physics-inspired feature edits. Using SNGP and an unknown head helps manage uncertainty and outlier cycles due to chemistry mismatch. Dropout at 0.35 balances regularization for small source data, and a moderate bottleneck of 256 supports capacity without overfitting. Batch size 8 matches seen data, and warmup epochs help stabilize transfer learning."\n}'}
12-12 16:17:19 llm_cfg_stamp: 20251212_131825
12-12 16:17:19 tag: sngp_wrn_sa_20251212_131825
12-12 16:17:19 pretrained_model_path: None
12-12 16:17:22 using 1 cpu
12-12 16:42:58 data_name: Battery_inconsistent
12-12 16:42:58 data_dir: ./my_datasets/Battery
12-12 16:42:58 csv: ./my_datasets/Battery/battery_cycles_labeled.csv
12-12 16:42:58 normlizetype: mean-std
12-12 16:42:58 method: sngp
12-12 16:42:58 gp_hidden_dim: 2048
12-12 16:42:58 spectral_norm_bound: 0.95
12-12 16:42:58 n_power_iterations: 1
12-12 16:42:58 nesterov: True
12-12 16:42:58 print_freq: 10
12-12 16:42:58 layers: 16
12-12 16:42:58 widen_factor: 1
12-12 16:42:58 droprate: 0.35
12-12 16:42:58 cuda_device: 0
12-12 16:42:58 checkpoint_dir: ./checkpoint
12-12 16:42:58 pretrained: False
12-12 16:42:58 batch_size: 8
12-12 16:42:58 warmup_epochs: 3
12-12 16:42:58 num_workers: 0
12-12 16:42:58 bottleneck: True
12-12 16:42:58 bottleneck_num: 256
12-12 16:42:58 last_batch: False
12-12 16:42:58 hidden_size: 1024
12-12 16:42:58 trade_off_adversarial: Step
12-12 16:42:58 lam_adversarial: 1
12-12 16:42:58 opt: adam
12-12 16:42:58 lr: 0.0005
12-12 16:42:58 momentum: 0.9
12-12 16:42:58 weight_decay: 1e-05
12-12 16:42:58 lr_scheduler: step
12-12 16:42:58 gamma: 0.1
12-12 16:42:58 steps: 150, 250
12-12 16:42:58 middle_epoch: 15
12-12 16:42:58 max_epoch: 50
12-12 16:42:58 print_step: 25
12-12 16:42:58 inconsistent: UAN
12-12 16:42:58 model_name: cnn_features_1d
12-12 16:42:58 th: 0.5
12-12 16:42:58 input_channels: 7
12-12 16:42:58 classification_label: eol_class
12-12 16:42:58 sequence_length: 32
12-12 16:42:58 cycles_per_file: 15
12-12 16:42:58 source_cycles_per_file: None
12-12 16:42:58 target_cycles_per_file: None
12-12 16:42:58 cycle_ablation: False
12-12 16:42:58 cycle_ablation_start: 5
12-12 16:42:58 cycle_ablation_step: 10
12-12 16:42:58 cycle_ablation_max: None
12-12 16:42:58 literature_context_file: ./references/joule_s2542-4351-22-00409-3.md
12-12 16:42:58 sample_random_state: 42
12-12 16:42:58 transfer_task: [[[0], [1]], [[0], [2]], [[0], [3]], [[1], [0]], [[1], [2]], [[1], [3]], [[2], [0]], [[2], [1]], [[2], [3]], [[3], [0]], [[3], [1]], [[3], [2]]]
12-12 16:42:58 source_cathode: ['5Vspinel']
12-12 16:42:58 target_cathode: []
12-12 16:42:58 num_classes: None
12-12 16:42:58 domain_temperature: 1.0
12-12 16:42:58 class_temperature: 10.0
12-12 16:42:58 lambda_src: 1.5
12-12 16:42:58 lambda_src_decay_patience: 5
12-12 16:42:58 lambda_src_decay_factor: 0.5
12-12 16:42:58 lambda_src_min: 0.0
12-12 16:42:58 lambda_src_warmup: 0
12-12 16:42:58 improvement_metric: accuracy
12-12 16:42:58 skip_retry: False
12-12 16:42:58 auto_select: True
12-12 16:42:58 llm_compare: True
12-12 16:42:58 llm_backend: openai
12-12 16:42:58 llm_model: None
12-12 16:42:58 llm_context: 
12-12 16:42:58 llm_ablation: False
12-12 16:42:58 llm_per_transfer: True
12-12 16:42:58 ablation_cycle_limits: 
12-12 16:42:58 llm_cfg_inputs: {'text_context': "Dataset: Argonne National Laboratory battery aging time-series with partial cycle windows.\nSource cathodes: 5Vspinel; target cathodes: Li1.2Ni0.3Mn0.6O2, Li1.35Ni0.33Mn0.67O2.35.\nLabel column 'eol_class' with ~None classes; sequence length 32; 21 channels covering cycle_number, energy_charge, capacity_charge, energy_discharge, capacity_discharge, cycle_start, cycle_duration.\nLiterature cues (Joule S2542-4351(22)00409-3, chemistry-sensitive ablations):\nJoule 2022 (S2542-4351(22)00409-3) key cues for chemistry-aware ablation:\n- Early-cycle capacity fade slopes and coulombic-efficiency stabilization highlight whether aging is lithium-inventory loss (graphite/anode-electrolyte limited) versus cathode structural decay (e.g., Ni-rich NMC cathodes with electrolyte oxidation risk).\n- High initial impedance growth, thick SEI signatures, or electrolyte oxidation markers flag chemistries that benefit from uncertainty-aware heads (SNGP/OpenMax) to avoid overconfident extrapolation on outlier cycles.\n- LFP/graphite pairs tend to show flatter voltage plateaus and slower early fade; Ni-rich NMC chemistries degrade faster under aggressive cycling and need stronger regularization or shorter cycle horizons in ablations.\n- Transfer between mismatched chemistries (e.g., NMC → LFP) should down-weight source loss and favor architectures that adapt quickly with self-attention or wider bottlenecks; closely matched chemistries can rely more on convolutional baselines.\nsource_train: class counts 0:19, 1:18, 2:2, 3:1, 4:1 (example label 2).\nsource_train sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.14630000293254852, 0.07519999891519547, -2.6510000228881836, 0.012799999676644802, -0.2791000008583069, -0.01119999960064888, -0.011500000022351742, 0.001200000…\nsource_train flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]\ntarget_train: class counts 0:6 (example label 0).\ntarget_train sample window (first 3 ch × 12 steps): [[-1.896399974822998, -2.010499954223633, -1.5264999866485596, 0.0, -0.8173999786376953, 0.0, -0.06809999793767929, 0.0, 0.2856000065803528, 0.34790000319480896, 0.5138000249862671, 0.696399986743927], [-2.2899999618530273, 3.247299909591675, 3.219599962234497, 0.0, 2.822499990463257, 0.0, 1.9033000469207764, 0.0, 1.7319999933242798, 1.4701999425888062, 1.604599952697754, -0.8252999782562256], [-2.7012999057769775, 1…\ntarget_train flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]\nsource_val: class counts 0:5, 1:5, 2:1, 4:1 (example label 0).\nsource_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.3109000027179718, 0.25519999861717224, 0.11729999631643295, 0.027000000700354576, -0.023900000378489494, -0.09200000017881393, -0.14669999480247498, -0.17059999…\nsource_val flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]\ntarget_val: class counts 0:4 (example label 0).\ntarget_val sample window (first 3 ch × 12 steps): [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 2.1417999267578125, 2.015700101852417, 1.9608999490737915, 2.140199899673462, 1.8382999897003174, 1.805999994277954, 3.2121999263763428, 1.5262000560760498, 1.592…\ntarget_val flattened row glimpses: [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]", 'numeric_summary': {'dataset': 'Battery_inconsistent', 'sequence_length_requested': 32, 'notes': 'label_inconsistent', 'lr_hint': 0.0005, 'dropout_hint': 0.35, 'num_classes_hint': None, 'splits': {'source_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 2, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.14630000293254852, 0.07519999891519547, -2.6510000228881836, 0.012799999676644802, -0.2791000008583069, -0.01119999960064888, -0.011500000022351742, 0.0012000000569969416, 0.0003000000142492354, -0.008899999782443047, -0.018300000578165054], [-2.4202001094818115, 0.0414000004529953, -0.011800000444054604, -2.420099973678589, -0.094200000166893, -0.3474000096321106, -0.09600000083446503, -0.09610000252723694, -0.0843999981880188, -0.0851999968290329, -0.09309999644756317, -0.10279999673366547]]}, 'batch_channel_mean': [0.8607000112533569, -0.10819999873638153, -0.17669999599456787, -0.01860000006854534, -0.12030000239610672, 0.5947999954223633, -0.29600000381469727, 0.32420000433921814], 'batch_channel_std': [1.059499979019165, 0.5400000214576721, 0.4787999987602234, 0.5626999735832214, 0.483599990606308, 0.9283000230789185, 0.7759000062942505, 0.7864000201225281], 'class_distribution': {'0': 19, '1': 18, '2': 2, '3': 1, '4': 1}, 'feature_range': [-2.9057923445856524, 5.202832943374929], 'feature_global_mean': -0.008143604364574682, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]}, 'target_train': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.896399974822998, -2.010499954223633, -1.5264999866485596, 0.0, -0.8173999786376953, 0.0, -0.06809999793767929, 0.0, 0.2856000065803528, 0.34790000319480896, 0.5138000249862671, 0.696399986743927], [-2.2899999618530273, 3.247299909591675, 3.219599962234497, 0.0, 2.822499990463257, 0.0, 1.9033000469207764, 0.0, 1.7319999933242798, 1.4701999425888062, 1.604599952697754, -0.8252999782562256], [-2.7012999057769775, 1.7355999946594238, 1.8173999786376953, 0.0, 2.0676000118255615, 0.0, 1.989300012588501, 0.0, 1.4453999996185303, 0.8960999846458435, 0.3228999972343445, -1.125100016593933]]}, 'batch_channel_mean': [0.707099974155426, 0.8895000219345093, 1.1301000118255615, 0.8313000202178955, 1.0865999460220337, -0.09960000216960907, -0.017400000244379044, -0.5198000073432922], 'batch_channel_std': [1.030500054359436, 1.198199987411499, 1.2407000064849854, 1.3655999898910522, 1.382200002670288, 1.2339999675750732, 1.2590999603271484, 0.8029000163078308], 'class_distribution': {'0': 6}, 'feature_range': [-3.6390493997246667, 19.875169049014566], 'feature_global_mean': 0.4374359295879304, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]}, 'source_val': {'batch_shape': [8, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 0.3109000027179718, 0.25519999861717224, 0.11729999631643295, 0.027000000700354576, -0.023900000378489494, -0.09200000017881393, -0.14669999480247498, -0.17059999704360962, -0.19750000536441803, -0.23759999871253967, -0.2761000096797943], [-2.4202001094818115, 0.210999995470047, 0.16750000417232513, 0.040699999779462814, -0.04349999874830246, -0.09049999713897705, -0.15610000491142273, -0.20749999582767487, -0.2303999960422516, -0.26170000433921814, -0.3025999963283539, -0.33959999680519104]]}, 'batch_channel_mean': [0.8607000112533569, -0.14800000190734863, -0.21410000324249268, -0.1005999967455864, -0.1704999953508377, 0.7595000267028809, -0.25529998540878296, 0.00139999995008111], 'batch_channel_std': [1.059499979019165, 0.5544999837875366, 0.4968999922275543, 0.6308000087738037, 0.5254999995231628, 0.8083000183105469, 0.7978000044822693, 0.6376000046730042], 'class_distribution': {'0': 5, '1': 5, '2': 1, '4': 1}, 'feature_range': [-2.9057923445856524, 5.219029621397489], 'feature_global_mean': -0.004320963409587972, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9417, -2.9058, -2.8748, -0.1784]]}, 'target_val': {'batch_shape': [4, 21, 32], 'channels': 21, 'seq_len': 32, 'example_label': 0, 'preview': {'channels': 3, 'timesteps': 12, 'values': [[-1.6202000379562378, -1.388700008392334, -1.1572999954223633, -0.9258000254631042, -0.6944000124931335, -0.4629000127315521, -0.23149999976158142, 0.0, 0.23149999976158142, 0.4629000127315521, 0.6944000124931335, 0.9258000254631042], [-2.6510000228881836, 2.1417999267578125, 2.015700101852417, 1.9608999490737915, 2.140199899673462, 1.8382999897003174, 1.805999994277954, 3.2121999263763428, 1.5262000560760498, 1.5922000408172607, 2.4560999870300293, 0.5361999869346619], [-2.4202001094818115, 2.6226999759674072, 2.5090999603271484, 2.4544999599456787, 2.5053000450134277, 2.200200080871582, 2.1552000045776367, 3.31030011177063, 1.7338000535964966, 1.7655999660491943, 2.470400094985962, 0.6173999905586243]]}, 'batch_channel_mean': [0.8607000112533569, 0.8479999899864197, 1.1744999885559082, 0.14030000567436218, 0.7558000087738037, -0.8087999820709229, -0.2743000090122223, -0.7925999760627747], 'batch_channel_std': [1.059499979019165, 1.2324999570846558, 1.3095999956130981, 1.6520999670028687, 1.822100043296814, 0.26759999990463257, 0.8853999972343445, 1.1957999467849731], 'class_distribution': {'0': 4}, 'feature_range': [-3.571829448600409, 19.622460716154905], 'feature_global_mean': 0.28418790425941914, 'flattened_rows_head': [[-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784], [-1.6202, -2.651, -2.4202, -2.7228, -2.4601, -1.489, -0.9406, -2.9058, -2.8748, -0.1784]]}}, 'dataset_variant': 'argonne_battery', 'feature_names': ['cycle_number', 'energy_charge', 'capacity_charge', 'energy_discharge', 'capacity_discharge', 'cycle_start', 'cycle_duration'], 'source_cathodes': ['5Vspinel'], 'target_cathodes': ['Li1.2Ni0.3Mn0.6O2', 'Li1.35Ni0.33Mn0.67O2.35'], 'label_column': 'eol_class', 'split_used': 'source_train', 'batch_size_seen': 8, 'channels': 21, 'seq_len': 32}}
12-12 16:42:58 llm_cfg: {'architecture': 'cnn_1d', 'model_name': 'cnn_features_1d', 'self_attention': False, 'sngp': True, 'openmax': False, 'use_unknown_head': False, 'bottleneck': 256, 'dropout': 0.35, 'learning_rate': 0.0005, 'batch_size': 8, 'lambda_src': 1.5, 'warmup_epochs': 10, 'rationale': 'The dataset has 21 channels and short sequence length (32), with significant domain shift between source and target chemistries. WideResNet_edited is tailored for Argonne battery data with physics-inspired feature edits, making it well suited for transfer learning across chemistries. The bottleneck of 256 balances capacity and regularization, while dropout at 0.35 mitigates overfitting given label inconsistency. Self-attention is avoided to reduce overfitting risk on a small source domain, and openmax/SNGP are not prioritized since the label inconsistency is moderate and unknown rejection is less critical than transfer adaptation. Target cathode: Li1.2Ni0.3Mn0.6O2. Source cathodes: 5Vspinel (high-voltage spinel (manganese rich)). Source/target chemistries differ → expect domain shift. Evaluated 21 channels × 32-step windows and matched them with cnn_1d capacity. Target fine-tune spans ≈6 cycles versus 41 source cycles, guiding lr=5.00e-04 and dropout=0.35.', '_provider': 'openai', '_raw': '{\n  "model_name": "WideResNet_edited",\n  "self_attention": false,\n  "sngp": false,\n  "openmax": false,\n  "use_unknown_head": false,\n  "bottleneck": 256,\n  "dropout": 0.35,\n  "learning_rate": 0.0005,\n  "batch_size": 8,\n  "lambda_src": 1.0,\n  "warmup_epochs": 10,\n  "rationale": "The dataset has 21 channels and short sequence length (32), with significant domain shift between source and target chemistries. WideResNet_edited is tailored for Argonne battery data with physics-inspired feature edits, making it well suited for transfer learning across chemistries. The bottleneck of 256 balances capacity and regularization, while dropout at 0.35 mitigates overfitting given label inconsistency. Self-attention is avoided to reduce overfitting risk on a small source domain, and openmax/SNGP are not prioritized since the label inconsistency is moderate and unknown rejection is less critical than transfer adaptation."\n}'}
12-12 16:42:58 llm_cfg_stamp: 20251212_131825
12-12 16:42:58 tag: sngp_wrn_sa_20251212_131825
12-12 16:42:58 pretrained_model_path: None
12-12 16:43:00 using 1 cpu
